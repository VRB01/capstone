{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tranformer_librispeech.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOe6M9l9R9xXnjxLe4Vjw4M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VRB01/capstone/blob/main/Tranformer_librispeech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "la_pE8SZtRHO",
        "outputId": "a1ebf170-c512-4511-f220-81b5e5618b8d"
      },
      "source": [
        "import IPython.display as ipd\n",
        "# % pylab inline\n",
        "import os\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import glob \n",
        "import librosa.display\n",
        "import random\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn import metrics \n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout \n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from keras import regularizers\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "import os\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.datasets import imdb\n",
        "from keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import os\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from sklearn.metrics import label_ranking_average_precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import zipfile\n",
        "\n",
        "tqdm.pandas()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tUYi9u-tXnw",
        "outputId": "3e92b8ee-46db-48c0-a489-dfe9e487569f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFFrVhQLtdQk"
      },
      "source": [
        "Directory = 'gdrive/MyDrive/Capstone Data/LibriSpeech/train-clean-100'\n",
        "Dataset = os.listdir(Directory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mjz8VWmRtdbI"
      },
      "source": [
        "audio_list = []\n",
        "speakers = []\n",
        "for speaker in Dataset:\n",
        "  chapters = os.listdir(Directory+'/'+speaker)\n",
        "  for chapter in chapters:\n",
        "    audios = os.listdir(Directory+'/'+speaker+'/'+chapter)\n",
        "    for audio in audios:\n",
        "      if(audio.endswith('.flac')):\n",
        "        audio_list.append(Directory+'/'+speaker+'/'+chapter+'/'+audio)\n",
        "        speakers.append(audio.split('-')[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TK_u_tXNtdj3",
        "outputId": "10f7723e-af85-462a-8cfb-67623f8c8d25"
      },
      "source": [
        "audio_list = pd.DataFrame(audio_list)\n",
        "audio_list = audio_list.rename(columns={0:'file'})\n",
        "#len(audio_list)\n",
        "len(speakers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28549"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "OO896Lzttdrs",
        "outputId": "33a45834-b4d9-4639-fcc4-2b12b5f398fe"
      },
      "source": [
        "audio_list['speaker'] = speakers\n",
        "df = audio_list.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "df = df[:12000]\n",
        "df_train = df[:8000] #19984:\n",
        "df_validation = df[8000:11000] #19984:25694\n",
        "df_test = df[11000:12000] #25694:\n",
        "labels = df['speaker']\n",
        "Counter = 1\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>speaker</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gdrive/MyDrive/Capstone Data/LibriSpeech/train...</td>\n",
              "      <td>6836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gdrive/MyDrive/Capstone Data/LibriSpeech/train...</td>\n",
              "      <td>3168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gdrive/MyDrive/Capstone Data/LibriSpeech/train...</td>\n",
              "      <td>4830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gdrive/MyDrive/Capstone Data/LibriSpeech/train...</td>\n",
              "      <td>8226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gdrive/MyDrive/Capstone Data/LibriSpeech/train...</td>\n",
              "      <td>909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11995</th>\n",
              "      <td>gdrive/MyDrive/Capstone Data/LibriSpeech/train...</td>\n",
              "      <td>8580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11996</th>\n",
              "      <td>gdrive/MyDrive/Capstone Data/LibriSpeech/train...</td>\n",
              "      <td>1040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11997</th>\n",
              "      <td>gdrive/MyDrive/Capstone Data/LibriSpeech/train...</td>\n",
              "      <td>2136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11998</th>\n",
              "      <td>gdrive/MyDrive/Capstone Data/LibriSpeech/train...</td>\n",
              "      <td>7794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11999</th>\n",
              "      <td>gdrive/MyDrive/Capstone Data/LibriSpeech/train...</td>\n",
              "      <td>8838</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    file speaker\n",
              "0      gdrive/MyDrive/Capstone Data/LibriSpeech/train...    6836\n",
              "1      gdrive/MyDrive/Capstone Data/LibriSpeech/train...    3168\n",
              "2      gdrive/MyDrive/Capstone Data/LibriSpeech/train...    4830\n",
              "3      gdrive/MyDrive/Capstone Data/LibriSpeech/train...    8226\n",
              "4      gdrive/MyDrive/Capstone Data/LibriSpeech/train...     909\n",
              "...                                                  ...     ...\n",
              "11995  gdrive/MyDrive/Capstone Data/LibriSpeech/train...    8580\n",
              "11996  gdrive/MyDrive/Capstone Data/LibriSpeech/train...    1040\n",
              "11997  gdrive/MyDrive/Capstone Data/LibriSpeech/train...    2136\n",
              "11998  gdrive/MyDrive/Capstone Data/LibriSpeech/train...    7794\n",
              "11999  gdrive/MyDrive/Capstone Data/LibriSpeech/train...    8838\n",
              "\n",
              "[12000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-7hFvf9vHX9"
      },
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # add the mask zero out padding tokens.\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  return tf.matmul(attention_weights, value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6aq_FFsvHt7"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # linear layers\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kmbAMQsvHzX"
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "    # apply sin to even index in the array\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # apply cos to odd index in the array\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OdY44ExvH31"
      },
      "source": [
        "# This allows to the transformer to know where there is real data and where it is padded\n",
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "  \n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tcr0t0ivH9C"
      },
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout,name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,d_model ), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmymY4MmvboM"
      },
      "source": [
        "def encoder(time_steps,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            projection,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "  \n",
        "  if projection=='linear':\n",
        "    ## We implement a linear projection based on Very Deep Self-Attention Networks for End-to-End Speech Recognition. Retrieved from https://arxiv.org/abs/1904.13377\n",
        "    projection=tf.keras.layers.Dense( d_model,use_bias=True, activation='linear')(inputs)\n",
        "    print('linear')\n",
        "  \n",
        "  else:\n",
        "    projection=tf.identity(inputs)\n",
        "    print('none')\n",
        "   \n",
        "  projection *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  projection = PositionalEncoding(time_steps, d_model)(projection)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(projection)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        " \n",
        " \n",
        "  \n",
        "\n",
        " \n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xER6o2uIvbq6"
      },
      "source": [
        "def transformer(time_steps,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                output_size,\n",
        "                projection,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,d_model), name=\"inputs\")\n",
        "  \n",
        "  \n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(tf.dtypes.cast(\n",
        "          \n",
        "    #Like our input has a dimension of length X d_model but the masking is applied to a vector\n",
        "    # We get the sum for each row and result is a vector. So, if result is 0 it is because in that position was masked      \n",
        "    tf.math.reduce_sum(\n",
        "    inputs,\n",
        "    axis=2,\n",
        "    keepdims=False,\n",
        "    name=None\n",
        "), tf.int32))\n",
        "  \n",
        "\n",
        "  enc_outputs = encoder(\n",
        "      time_steps=time_steps,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "      projection=projection,\n",
        "      name='encoder'\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  #We reshape for feeding our FC in the next step\n",
        "  outputs=tf.reshape(enc_outputs,(-1,time_steps*d_model))\n",
        "  \n",
        "  #We predict our class\n",
        "  outputs = tf.keras.layers.Dense(units=output_size,use_bias=True,activation='softmax', name=\"outputs\")(outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs], outputs=outputs, name='audio_class')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsO8XZFKtdzB"
      },
      "source": [
        "def extract_features(files):\n",
        "    \n",
        "    # Sets the name to be the path to where the file is in my computer\n",
        "    file_name = os.path.join(str(files.file))\n",
        "    global Counter\n",
        "    if(Counter%10==0):\n",
        "      print(Counter)\n",
        "    Counter+=1\n",
        "\n",
        "    # Loads the audio file as a floating point time series and assigns the default sample rate\n",
        "    # Sample rate is set to 22050 by default\n",
        "    X, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
        "\n",
        "    # Generate Mel-frequency cepstral coefficients (MFCCs) from a time series \n",
        "    #mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
        "\n",
        "    # Generates a Short-time Fourier transform (STFT) to use in the chroma_stft\n",
        "    #stft = np.abs(librosa.stft(X))\n",
        "\n",
        "    # Computes a chromagram from a waveform or power spectrogram.\n",
        "    #chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "\n",
        "    # Computes a mel-scaled spectrogram.\n",
        "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
        "\n",
        "    # Computes spectral contrast\n",
        "    #contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
        "\n",
        "    # Computes the tonal centroid features (tonnetz)\n",
        "    #tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n",
        "    #sr=sample_rate).T,axis=0)\n",
        "        \n",
        "    \n",
        "    # We add also the classes of each file as a label at the end\n",
        "    #label = files.label\n",
        "\n",
        "    return mel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXrv2HkXtd5n",
        "outputId": "8745e3fc-85ef-49f5-c7c2-d8781d3fbdd7"
      },
      "source": [
        "startTime = datetime.now()\n",
        "# Applying the function to the train data by accessing each row of the dataframe\n",
        "features_label = df.apply(extract_features, axis=1)\n",
        "print(datetime.now() - startTime)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n",
            "100\n",
            "110\n",
            "120\n",
            "130\n",
            "140\n",
            "150\n",
            "160\n",
            "170\n",
            "180\n",
            "190\n",
            "200\n",
            "210\n",
            "220\n",
            "230\n",
            "240\n",
            "250\n",
            "260\n",
            "270\n",
            "280\n",
            "290\n",
            "300\n",
            "310\n",
            "320\n",
            "330\n",
            "340\n",
            "350\n",
            "360\n",
            "370\n",
            "380\n",
            "390\n",
            "400\n",
            "410\n",
            "420\n",
            "430\n",
            "440\n",
            "450\n",
            "460\n",
            "470\n",
            "480\n",
            "490\n",
            "500\n",
            "510\n",
            "520\n",
            "530\n",
            "540\n",
            "550\n",
            "560\n",
            "570\n",
            "580\n",
            "590\n",
            "600\n",
            "610\n",
            "620\n",
            "630\n",
            "640\n",
            "650\n",
            "660\n",
            "670\n",
            "680\n",
            "690\n",
            "700\n",
            "710\n",
            "720\n",
            "730\n",
            "740\n",
            "750\n",
            "760\n",
            "770\n",
            "780\n",
            "790\n",
            "800\n",
            "810\n",
            "820\n",
            "830\n",
            "840\n",
            "850\n",
            "860\n",
            "870\n",
            "880\n",
            "890\n",
            "900\n",
            "910\n",
            "920\n",
            "930\n",
            "940\n",
            "950\n",
            "960\n",
            "970\n",
            "980\n",
            "990\n",
            "1000\n",
            "1010\n",
            "1020\n",
            "1030\n",
            "1040\n",
            "1050\n",
            "1060\n",
            "1070\n",
            "1080\n",
            "1090\n",
            "1100\n",
            "1110\n",
            "1120\n",
            "1130\n",
            "1140\n",
            "1150\n",
            "1160\n",
            "1170\n",
            "1180\n",
            "1190\n",
            "1200\n",
            "1210\n",
            "1220\n",
            "1230\n",
            "1240\n",
            "1250\n",
            "1260\n",
            "1270\n",
            "1280\n",
            "1290\n",
            "1300\n",
            "1310\n",
            "1320\n",
            "1330\n",
            "1340\n",
            "1350\n",
            "1360\n",
            "1370\n",
            "1380\n",
            "1390\n",
            "1400\n",
            "1410\n",
            "1420\n",
            "1430\n",
            "1440\n",
            "1450\n",
            "1460\n",
            "1470\n",
            "1480\n",
            "1490\n",
            "1500\n",
            "1510\n",
            "1520\n",
            "1530\n",
            "1540\n",
            "1550\n",
            "1560\n",
            "1570\n",
            "1580\n",
            "1590\n",
            "1600\n",
            "1610\n",
            "1620\n",
            "1630\n",
            "1640\n",
            "1650\n",
            "1660\n",
            "1670\n",
            "1680\n",
            "1690\n",
            "1700\n",
            "1710\n",
            "1720\n",
            "1730\n",
            "1740\n",
            "1750\n",
            "1760\n",
            "1770\n",
            "1780\n",
            "1790\n",
            "1800\n",
            "1810\n",
            "1820\n",
            "1830\n",
            "1840\n",
            "1850\n",
            "1860\n",
            "1870\n",
            "1880\n",
            "1890\n",
            "1900\n",
            "1910\n",
            "1920\n",
            "1930\n",
            "1940\n",
            "1950\n",
            "1960\n",
            "1970\n",
            "1980\n",
            "1990\n",
            "2000\n",
            "2010\n",
            "2020\n",
            "2030\n",
            "2040\n",
            "2050\n",
            "2060\n",
            "2070\n",
            "2080\n",
            "2090\n",
            "2100\n",
            "2110\n",
            "2120\n",
            "2130\n",
            "2140\n",
            "2150\n",
            "2160\n",
            "2170\n",
            "2180\n",
            "2190\n",
            "2200\n",
            "2210\n",
            "2220\n",
            "2230\n",
            "2240\n",
            "2250\n",
            "2260\n",
            "2270\n",
            "2280\n",
            "2290\n",
            "2300\n",
            "2310\n",
            "2320\n",
            "2330\n",
            "2340\n",
            "2350\n",
            "2360\n",
            "2370\n",
            "2380\n",
            "2390\n",
            "2400\n",
            "2410\n",
            "2420\n",
            "2430\n",
            "2440\n",
            "2450\n",
            "2460\n",
            "2470\n",
            "2480\n",
            "2490\n",
            "2500\n",
            "2510\n",
            "2520\n",
            "2530\n",
            "2540\n",
            "2550\n",
            "2560\n",
            "2570\n",
            "2580\n",
            "2590\n",
            "2600\n",
            "2610\n",
            "2620\n",
            "2630\n",
            "2640\n",
            "2650\n",
            "2660\n",
            "2670\n",
            "2680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Quhf-QKGtyoW"
      },
      "source": [
        "# Saving the numpy array because it takes a long time to extract the features\n",
        "np.save('features_label_libri', features_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt9_9gomtyrG",
        "outputId": "45276829-3cda-4c14-bdc6-cc24fa931d39"
      },
      "source": [
        "# loading the features\n",
        "features_label = np.load('features_label_libri.npy', allow_pickle=True)\n",
        "features_label.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Moh4UluKtyth",
        "outputId": "d9fafe59-d739-4f93-c730-77161dfff59b"
      },
      "source": [
        "trial_features=[]\n",
        "for i in range(0,len(features_label)):\n",
        "  a=[]\n",
        "  a.append(features_label[i])\n",
        "  #a.append(features_label[i][1])\n",
        "  trial_features.append(a)\n",
        "xxx = np.array(trial_features)\n",
        "xxx.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12000, 1, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Zzm3hHktyvj",
        "outputId": "67e62651-3774-494c-8394-c151535b21ba"
      },
      "source": [
        "X = xxx\n",
        "y = np.array(labels)\n",
        "lb = LabelEncoder()\n",
        "y = to_categorical(lb.fit_transform(y))\n",
        "X.shape\n",
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12000, 251)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upbVoetAzjd5"
      },
      "source": [
        "limit_1 = int(X.shape[0]*0.7)\n",
        "limit_2 = int(X.shape[0]*0.85)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5edl7tbzmIu"
      },
      "source": [
        "X_train = X[:limit_1]\n",
        "Y_train = y[:limit_1]\n",
        "\n",
        "X_val = X[limit_1:limit_2]\n",
        "Y_val = y[limit_1:limit_2]\n",
        "\n",
        "X_test = X[limit_2:]\n",
        "Y_test = y[limit_2:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuaiS22vtyyt"
      },
      "source": [
        "# #We get our train and test set\n",
        "# X_train,X_test, Y_train, Y_test =train_test_split(X,y, test_size=0.2, random_state=27)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNv05hSI1_mP"
      },
      "source": [
        "projection=['linear','none']\n",
        "accuracy=[]\n",
        "proj_implemented=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djj5V3UBuMQs",
        "outputId": "535ff063-2f00-417a-f117-fbd75342a1ca"
      },
      "source": [
        "for i in projection:\n",
        "  NUM_LAYERS = 2\n",
        "  D_MODEL = X.shape[2]\n",
        "  NUM_HEADS = 4\n",
        "  UNITS = 1024\n",
        "  DROPOUT = 0.1\n",
        "  TIME_STEPS= X.shape[1]\n",
        "  OUTPUT_SIZE=251\n",
        "  EPOCHS = 100\n",
        "  EXPERIMENTS=1\n",
        "\n",
        "  \n",
        "  for j in range(EXPERIMENTS):\n",
        "    \n",
        "    \n",
        "    model = transformer(time_steps=TIME_STEPS,\n",
        "      num_layers=NUM_LAYERS,\n",
        "      units=UNITS,\n",
        "      d_model=D_MODEL,\n",
        "      num_heads=NUM_HEADS,\n",
        "      dropout=DROPOUT,\n",
        "      output_size=OUTPUT_SIZE,  \n",
        "      projection=i)\n",
        "    \n",
        "    #model.compile(optimizer=tf.keras.optimizers.Adam(0.000001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "    early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')\n",
        "    #history=model.fit(X_train,Y_train, epochs=EPOCHS, validation_data=(X_test, Y_test))\n",
        "    history = model.fit(X_train, Y_train, batch_size=64, epochs=100, validation_data=(X_val, Y_val),callbacks=[early_stop])\n",
        "    \n",
        "    \n",
        "    accuracy.append(sum(history.history['val_accuracy'])/len(history.history['val_accuracy']))\n",
        "      \n",
        "    proj_implemented.append(i)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "linear\n",
            "Epoch 1/100\n",
            "132/132 [==============================] - 6s 22ms/step - loss: 4.8455 - accuracy: 0.0781 - val_loss: 2.9428 - val_accuracy: 0.3161\n",
            "Epoch 2/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 2.7140 - accuracy: 0.3695 - val_loss: 1.8750 - val_accuracy: 0.5422\n",
            "Epoch 3/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 1.8521 - accuracy: 0.5424 - val_loss: 1.3713 - val_accuracy: 0.6444\n",
            "Epoch 4/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 1.4018 - accuracy: 0.6480 - val_loss: 1.2148 - val_accuracy: 0.6717\n",
            "Epoch 5/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 1.1571 - accuracy: 0.6874 - val_loss: 1.0328 - val_accuracy: 0.7183\n",
            "Epoch 6/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 1.0229 - accuracy: 0.7191 - val_loss: 0.9360 - val_accuracy: 0.7461\n",
            "Epoch 7/100\n",
            "132/132 [==============================] - 2s 17ms/step - loss: 0.8704 - accuracy: 0.7548 - val_loss: 0.8492 - val_accuracy: 0.7650\n",
            "Epoch 8/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.7440 - accuracy: 0.7914 - val_loss: 0.8110 - val_accuracy: 0.7739\n",
            "Epoch 9/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.6556 - accuracy: 0.8048 - val_loss: 0.7202 - val_accuracy: 0.7906\n",
            "Epoch 10/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.5798 - accuracy: 0.8313 - val_loss: 0.8110 - val_accuracy: 0.7750\n",
            "Epoch 11/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.5771 - accuracy: 0.8289 - val_loss: 0.7683 - val_accuracy: 0.7811\n",
            "Epoch 12/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.5570 - accuracy: 0.8245 - val_loss: 0.6585 - val_accuracy: 0.8150\n",
            "Epoch 13/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.4777 - accuracy: 0.8562 - val_loss: 0.7419 - val_accuracy: 0.7933\n",
            "Epoch 14/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.4538 - accuracy: 0.8570 - val_loss: 0.7103 - val_accuracy: 0.8044\n",
            "Epoch 15/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.4520 - accuracy: 0.8614 - val_loss: 0.6962 - val_accuracy: 0.8033\n",
            "Epoch 16/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.4184 - accuracy: 0.8631 - val_loss: 0.6866 - val_accuracy: 0.8122\n",
            "Epoch 17/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.3831 - accuracy: 0.8786 - val_loss: 0.6559 - val_accuracy: 0.8311\n",
            "Epoch 18/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.3252 - accuracy: 0.9008 - val_loss: 0.7489 - val_accuracy: 0.7961\n",
            "Epoch 19/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.3541 - accuracy: 0.8939 - val_loss: 0.7950 - val_accuracy: 0.7950\n",
            "Epoch 20/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.3313 - accuracy: 0.8970 - val_loss: 0.7187 - val_accuracy: 0.8028\n",
            "Epoch 21/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.3543 - accuracy: 0.8872 - val_loss: 0.7109 - val_accuracy: 0.8217\n",
            "Epoch 22/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2956 - accuracy: 0.9108 - val_loss: 0.8206 - val_accuracy: 0.7856\n",
            "Epoch 23/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.3106 - accuracy: 0.9000 - val_loss: 0.7584 - val_accuracy: 0.8061\n",
            "Epoch 24/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2423 - accuracy: 0.9228 - val_loss: 0.6907 - val_accuracy: 0.8244\n",
            "Epoch 25/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2651 - accuracy: 0.9183 - val_loss: 0.7692 - val_accuracy: 0.8094\n",
            "Epoch 26/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2765 - accuracy: 0.9111 - val_loss: 0.7401 - val_accuracy: 0.8133\n",
            "Epoch 27/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2514 - accuracy: 0.9184 - val_loss: 0.7297 - val_accuracy: 0.8222\n",
            "Epoch 28/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2437 - accuracy: 0.9222 - val_loss: 0.8924 - val_accuracy: 0.7822\n",
            "Epoch 29/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2770 - accuracy: 0.9105 - val_loss: 0.7733 - val_accuracy: 0.8211\n",
            "Epoch 30/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2237 - accuracy: 0.9303 - val_loss: 0.7396 - val_accuracy: 0.8211\n",
            "Epoch 31/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2424 - accuracy: 0.9220 - val_loss: 0.7768 - val_accuracy: 0.8111\n",
            "Epoch 32/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2455 - accuracy: 0.9224 - val_loss: 0.7093 - val_accuracy: 0.8172\n",
            "Epoch 33/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1998 - accuracy: 0.9442 - val_loss: 0.7491 - val_accuracy: 0.8256\n",
            "Epoch 34/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2134 - accuracy: 0.9303 - val_loss: 0.9013 - val_accuracy: 0.7872\n",
            "Epoch 35/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2443 - accuracy: 0.9167 - val_loss: 0.7683 - val_accuracy: 0.8189\n",
            "Epoch 36/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2452 - accuracy: 0.9195 - val_loss: 0.7610 - val_accuracy: 0.8300\n",
            "Epoch 37/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1866 - accuracy: 0.9397 - val_loss: 0.7727 - val_accuracy: 0.8139\n",
            "Epoch 38/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2023 - accuracy: 0.9333 - val_loss: 0.7860 - val_accuracy: 0.8256\n",
            "Epoch 39/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1962 - accuracy: 0.9377 - val_loss: 0.7429 - val_accuracy: 0.8256\n",
            "Epoch 40/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2007 - accuracy: 0.9337 - val_loss: 0.7880 - val_accuracy: 0.8167\n",
            "Epoch 41/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2328 - accuracy: 0.9260 - val_loss: 0.7359 - val_accuracy: 0.8261\n",
            "Epoch 42/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1843 - accuracy: 0.9387 - val_loss: 0.8955 - val_accuracy: 0.7900\n",
            "Epoch 43/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2403 - accuracy: 0.9236 - val_loss: 0.7488 - val_accuracy: 0.8228\n",
            "Epoch 44/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2007 - accuracy: 0.9389 - val_loss: 0.8617 - val_accuracy: 0.8117\n",
            "Epoch 45/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2050 - accuracy: 0.9343 - val_loss: 0.7854 - val_accuracy: 0.8250\n",
            "Epoch 46/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.1827 - accuracy: 0.9417 - val_loss: 0.8236 - val_accuracy: 0.8183\n",
            "Epoch 47/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1517 - accuracy: 0.9517 - val_loss: 0.7856 - val_accuracy: 0.8206\n",
            "Epoch 48/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1800 - accuracy: 0.9441 - val_loss: 0.8231 - val_accuracy: 0.8228\n",
            "Epoch 49/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1623 - accuracy: 0.9467 - val_loss: 0.8813 - val_accuracy: 0.8144\n",
            "Epoch 50/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1683 - accuracy: 0.9482 - val_loss: 0.8488 - val_accuracy: 0.8150\n",
            "Epoch 51/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1691 - accuracy: 0.9460 - val_loss: 0.9480 - val_accuracy: 0.7956\n",
            "Epoch 52/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2381 - accuracy: 0.9237 - val_loss: 0.9664 - val_accuracy: 0.7972\n",
            "Epoch 53/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1854 - accuracy: 0.9382 - val_loss: 0.8772 - val_accuracy: 0.8056\n",
            "Epoch 54/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1850 - accuracy: 0.9408 - val_loss: 0.9049 - val_accuracy: 0.8100\n",
            "Epoch 55/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1854 - accuracy: 0.9430 - val_loss: 0.8121 - val_accuracy: 0.8261\n",
            "Epoch 56/100\n",
            "132/132 [==============================] - 2s 17ms/step - loss: 0.1605 - accuracy: 0.9469 - val_loss: 0.7862 - val_accuracy: 0.8167\n",
            "Epoch 57/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1519 - accuracy: 0.9508 - val_loss: 0.8173 - val_accuracy: 0.8194\n",
            "Epoch 58/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1401 - accuracy: 0.9553 - val_loss: 0.8291 - val_accuracy: 0.8194\n",
            "Epoch 59/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1694 - accuracy: 0.9424 - val_loss: 0.9036 - val_accuracy: 0.8072\n",
            "Epoch 60/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1533 - accuracy: 0.9485 - val_loss: 0.8355 - val_accuracy: 0.8167\n",
            "Epoch 61/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.1750 - accuracy: 0.9449 - val_loss: 0.8567 - val_accuracy: 0.8133\n",
            "Epoch 62/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1808 - accuracy: 0.9403 - val_loss: 0.9194 - val_accuracy: 0.8111\n",
            "Epoch 63/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.1443 - accuracy: 0.9572 - val_loss: 0.9375 - val_accuracy: 0.7989\n",
            "Epoch 64/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1720 - accuracy: 0.9427 - val_loss: 0.8276 - val_accuracy: 0.8289\n",
            "Epoch 65/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.1802 - accuracy: 0.9430 - val_loss: 0.9028 - val_accuracy: 0.8222\n",
            "Epoch 66/100\n",
            "132/132 [==============================] - 3s 19ms/step - loss: 0.1722 - accuracy: 0.9437 - val_loss: 0.8011 - val_accuracy: 0.8383\n",
            "Epoch 67/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.1047 - accuracy: 0.9641 - val_loss: 0.8548 - val_accuracy: 0.8144\n",
            "Epoch 68/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.1381 - accuracy: 0.9524 - val_loss: 0.8582 - val_accuracy: 0.8250\n",
            "Epoch 69/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.1484 - accuracy: 0.9468 - val_loss: 0.8644 - val_accuracy: 0.8333\n",
            "Epoch 70/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.1134 - accuracy: 0.9623 - val_loss: 0.7688 - val_accuracy: 0.8344\n",
            "Epoch 71/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.1383 - accuracy: 0.9544 - val_loss: 0.8558 - val_accuracy: 0.8300\n",
            "Epoch 72/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1887 - accuracy: 0.9436 - val_loss: 0.8080 - val_accuracy: 0.8361\n",
            "Epoch 73/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.1213 - accuracy: 0.9599 - val_loss: 0.9942 - val_accuracy: 0.8128\n",
            "Epoch 74/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.1306 - accuracy: 0.9594 - val_loss: 0.8454 - val_accuracy: 0.8261\n",
            "Epoch 75/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.1212 - accuracy: 0.9609 - val_loss: 0.8359 - val_accuracy: 0.8261\n",
            "Epoch 76/100\n",
            "132/132 [==============================] - 3s 19ms/step - loss: 0.1463 - accuracy: 0.9483 - val_loss: 0.9228 - val_accuracy: 0.8189\n",
            "Epoch 77/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1102 - accuracy: 0.9640 - val_loss: 0.8861 - val_accuracy: 0.8289\n",
            "Epoch 78/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.1241 - accuracy: 0.9619 - val_loss: 0.8519 - val_accuracy: 0.8317\n",
            "Epoch 79/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.1329 - accuracy: 0.9559 - val_loss: 0.8393 - val_accuracy: 0.8256\n",
            "Epoch 80/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.1313 - accuracy: 0.9560 - val_loss: 0.9059 - val_accuracy: 0.8172\n",
            "Epoch 81/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1308 - accuracy: 0.9565 - val_loss: 0.8844 - val_accuracy: 0.8250\n",
            "Epoch 82/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.1307 - accuracy: 0.9558 - val_loss: 0.8035 - val_accuracy: 0.8322\n",
            "Epoch 83/100\n",
            "132/132 [==============================] - 3s 19ms/step - loss: 0.1463 - accuracy: 0.9535 - val_loss: 0.8682 - val_accuracy: 0.8289\n",
            "Epoch 84/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.1159 - accuracy: 0.9623 - val_loss: 0.8754 - val_accuracy: 0.8117\n",
            "Epoch 85/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1201 - accuracy: 0.9622 - val_loss: 0.8686 - val_accuracy: 0.8244\n",
            "Epoch 86/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.0959 - accuracy: 0.9689 - val_loss: 0.9308 - val_accuracy: 0.8228\n",
            "Epoch 87/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.1237 - accuracy: 0.9602 - val_loss: 0.9020 - val_accuracy: 0.8206\n",
            "Epoch 88/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1034 - accuracy: 0.9675 - val_loss: 0.8965 - val_accuracy: 0.8239\n",
            "Epoch 89/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.0867 - accuracy: 0.9734 - val_loss: 0.8882 - val_accuracy: 0.8339\n",
            "Epoch 90/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1104 - accuracy: 0.9664 - val_loss: 0.8294 - val_accuracy: 0.8417\n",
            "Epoch 91/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.0967 - accuracy: 0.9660 - val_loss: 0.8227 - val_accuracy: 0.8339\n",
            "Epoch 92/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.1288 - accuracy: 0.9604 - val_loss: 0.9676 - val_accuracy: 0.8200\n",
            "Epoch 93/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.1479 - accuracy: 0.9540 - val_loss: 0.8641 - val_accuracy: 0.8294\n",
            "Epoch 94/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.1354 - accuracy: 0.9559 - val_loss: 0.8306 - val_accuracy: 0.8417\n",
            "Epoch 95/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.1140 - accuracy: 0.9650 - val_loss: 0.9555 - val_accuracy: 0.8150\n",
            "Epoch 96/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.0842 - accuracy: 0.9739 - val_loss: 0.8891 - val_accuracy: 0.8300\n",
            "Epoch 97/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1083 - accuracy: 0.9672 - val_loss: 0.8790 - val_accuracy: 0.8239\n",
            "Epoch 98/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1173 - accuracy: 0.9634 - val_loss: 0.9254 - val_accuracy: 0.8300\n",
            "Epoch 99/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.0952 - accuracy: 0.9706 - val_loss: 0.8215 - val_accuracy: 0.8328\n",
            "Epoch 100/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.1500 - accuracy: 0.9523 - val_loss: 0.8894 - val_accuracy: 0.8222\n",
            "none\n",
            "Epoch 1/100\n",
            "132/132 [==============================] - 6s 25ms/step - loss: 4.8855 - accuracy: 0.0772 - val_loss: 2.9260 - val_accuracy: 0.3461\n",
            "Epoch 2/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 2.9581 - accuracy: 0.3213 - val_loss: 1.9932 - val_accuracy: 0.5450\n",
            "Epoch 3/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 2.1457 - accuracy: 0.4780 - val_loss: 1.4570 - val_accuracy: 0.6356\n",
            "Epoch 4/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 1.7143 - accuracy: 0.5580 - val_loss: 1.2393 - val_accuracy: 0.6733\n",
            "Epoch 5/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 1.4473 - accuracy: 0.6218 - val_loss: 1.0643 - val_accuracy: 0.7194\n",
            "Epoch 6/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 1.2834 - accuracy: 0.6439 - val_loss: 0.9645 - val_accuracy: 0.7522\n",
            "Epoch 7/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 1.1575 - accuracy: 0.6785 - val_loss: 0.8082 - val_accuracy: 0.7883\n",
            "Epoch 8/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 1.0333 - accuracy: 0.7041 - val_loss: 0.8616 - val_accuracy: 0.7622\n",
            "Epoch 9/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.9169 - accuracy: 0.7473 - val_loss: 0.8123 - val_accuracy: 0.7750\n",
            "Epoch 10/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.9167 - accuracy: 0.7367 - val_loss: 0.7556 - val_accuracy: 0.7817\n",
            "Epoch 11/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.8644 - accuracy: 0.7524 - val_loss: 0.6612 - val_accuracy: 0.8139\n",
            "Epoch 12/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.7934 - accuracy: 0.7761 - val_loss: 0.6748 - val_accuracy: 0.8117\n",
            "Epoch 13/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.7336 - accuracy: 0.7913 - val_loss: 0.6668 - val_accuracy: 0.8172\n",
            "Epoch 14/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.7323 - accuracy: 0.7829 - val_loss: 0.6160 - val_accuracy: 0.8378\n",
            "Epoch 15/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.6565 - accuracy: 0.8059 - val_loss: 0.6324 - val_accuracy: 0.8144\n",
            "Epoch 16/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.6492 - accuracy: 0.8171 - val_loss: 0.6159 - val_accuracy: 0.8328\n",
            "Epoch 17/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.6312 - accuracy: 0.8136 - val_loss: 0.5908 - val_accuracy: 0.8322\n",
            "Epoch 18/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.5681 - accuracy: 0.8283 - val_loss: 0.6089 - val_accuracy: 0.8361\n",
            "Epoch 19/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.5522 - accuracy: 0.8334 - val_loss: 0.6645 - val_accuracy: 0.8156\n",
            "Epoch 20/100\n",
            "132/132 [==============================] - 2s 17ms/step - loss: 0.5701 - accuracy: 0.8289 - val_loss: 0.6319 - val_accuracy: 0.8233\n",
            "Epoch 21/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.5371 - accuracy: 0.8403 - val_loss: 0.6651 - val_accuracy: 0.8211\n",
            "Epoch 22/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.5098 - accuracy: 0.8397 - val_loss: 0.6127 - val_accuracy: 0.8317\n",
            "Epoch 23/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.4856 - accuracy: 0.8554 - val_loss: 0.5891 - val_accuracy: 0.8439\n",
            "Epoch 24/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.4601 - accuracy: 0.8615 - val_loss: 0.5547 - val_accuracy: 0.8544\n",
            "Epoch 25/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.4718 - accuracy: 0.8590 - val_loss: 0.5637 - val_accuracy: 0.8400\n",
            "Epoch 26/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.4085 - accuracy: 0.8727 - val_loss: 0.5811 - val_accuracy: 0.8394\n",
            "Epoch 27/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.4304 - accuracy: 0.8735 - val_loss: 0.5479 - val_accuracy: 0.8494\n",
            "Epoch 28/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.4395 - accuracy: 0.8663 - val_loss: 0.5440 - val_accuracy: 0.8467\n",
            "Epoch 29/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.4307 - accuracy: 0.8725 - val_loss: 0.5596 - val_accuracy: 0.8439\n",
            "Epoch 30/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.4311 - accuracy: 0.8651 - val_loss: 0.5281 - val_accuracy: 0.8528\n",
            "Epoch 31/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.4386 - accuracy: 0.8723 - val_loss: 0.5479 - val_accuracy: 0.8528\n",
            "Epoch 32/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.4113 - accuracy: 0.8686 - val_loss: 0.5361 - val_accuracy: 0.8567\n",
            "Epoch 33/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.3959 - accuracy: 0.8796 - val_loss: 0.5387 - val_accuracy: 0.8622\n",
            "Epoch 34/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.3911 - accuracy: 0.8782 - val_loss: 0.4901 - val_accuracy: 0.8706\n",
            "Epoch 35/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.3397 - accuracy: 0.8955 - val_loss: 0.5571 - val_accuracy: 0.8494\n",
            "Epoch 36/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.3841 - accuracy: 0.8803 - val_loss: 0.5625 - val_accuracy: 0.8594\n",
            "Epoch 37/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.3564 - accuracy: 0.8885 - val_loss: 0.5716 - val_accuracy: 0.8422\n",
            "Epoch 38/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.4113 - accuracy: 0.8759 - val_loss: 0.5696 - val_accuracy: 0.8461\n",
            "Epoch 39/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.3628 - accuracy: 0.8857 - val_loss: 0.5211 - val_accuracy: 0.8589\n",
            "Epoch 40/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.3327 - accuracy: 0.8969 - val_loss: 0.5424 - val_accuracy: 0.8622\n",
            "Epoch 41/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.3340 - accuracy: 0.9019 - val_loss: 0.5492 - val_accuracy: 0.8572\n",
            "Epoch 42/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.3199 - accuracy: 0.9037 - val_loss: 0.5510 - val_accuracy: 0.8633\n",
            "Epoch 43/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.3687 - accuracy: 0.8919 - val_loss: 0.5033 - val_accuracy: 0.8694\n",
            "Epoch 44/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.3310 - accuracy: 0.9023 - val_loss: 0.5614 - val_accuracy: 0.8606\n",
            "Epoch 45/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.3399 - accuracy: 0.8946 - val_loss: 0.5677 - val_accuracy: 0.8506\n",
            "Epoch 46/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.3140 - accuracy: 0.9013 - val_loss: 0.4967 - val_accuracy: 0.8744\n",
            "Epoch 47/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2778 - accuracy: 0.9121 - val_loss: 0.5538 - val_accuracy: 0.8572\n",
            "Epoch 48/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.3036 - accuracy: 0.9089 - val_loss: 0.5605 - val_accuracy: 0.8522\n",
            "Epoch 49/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.3257 - accuracy: 0.8993 - val_loss: 0.5159 - val_accuracy: 0.8706\n",
            "Epoch 50/100\n",
            "132/132 [==============================] - 3s 19ms/step - loss: 0.3162 - accuracy: 0.9000 - val_loss: 0.5413 - val_accuracy: 0.8661\n",
            "Epoch 51/100\n",
            "132/132 [==============================] - 3s 19ms/step - loss: 0.3066 - accuracy: 0.9043 - val_loss: 0.5910 - val_accuracy: 0.8478\n",
            "Epoch 52/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2923 - accuracy: 0.9041 - val_loss: 0.5634 - val_accuracy: 0.8478\n",
            "Epoch 53/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2821 - accuracy: 0.9140 - val_loss: 0.5207 - val_accuracy: 0.8672\n",
            "Epoch 54/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.3006 - accuracy: 0.9066 - val_loss: 0.6349 - val_accuracy: 0.8461\n",
            "Epoch 55/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2795 - accuracy: 0.9174 - val_loss: 0.5307 - val_accuracy: 0.8644\n",
            "Epoch 56/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2701 - accuracy: 0.9171 - val_loss: 0.5650 - val_accuracy: 0.8628\n",
            "Epoch 57/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2948 - accuracy: 0.9111 - val_loss: 0.5276 - val_accuracy: 0.8589\n",
            "Epoch 58/100\n",
            "132/132 [==============================] - 3s 19ms/step - loss: 0.2749 - accuracy: 0.9124 - val_loss: 0.5607 - val_accuracy: 0.8528\n",
            "Epoch 59/100\n",
            "132/132 [==============================] - 3s 19ms/step - loss: 0.2757 - accuracy: 0.9157 - val_loss: 0.5436 - val_accuracy: 0.8606\n",
            "Epoch 60/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2936 - accuracy: 0.9106 - val_loss: 0.5222 - val_accuracy: 0.8717\n",
            "Epoch 61/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2664 - accuracy: 0.9206 - val_loss: 0.6016 - val_accuracy: 0.8533\n",
            "Epoch 62/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.3295 - accuracy: 0.9005 - val_loss: 0.5363 - val_accuracy: 0.8633\n",
            "Epoch 63/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2512 - accuracy: 0.9250 - val_loss: 0.5101 - val_accuracy: 0.8644\n",
            "Epoch 64/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2679 - accuracy: 0.9149 - val_loss: 0.5263 - val_accuracy: 0.8650\n",
            "Epoch 65/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2412 - accuracy: 0.9262 - val_loss: 0.4766 - val_accuracy: 0.8678\n",
            "Epoch 66/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2538 - accuracy: 0.9259 - val_loss: 0.5107 - val_accuracy: 0.8722\n",
            "Epoch 67/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2565 - accuracy: 0.9242 - val_loss: 0.5320 - val_accuracy: 0.8644\n",
            "Epoch 68/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2356 - accuracy: 0.9276 - val_loss: 0.6057 - val_accuracy: 0.8489\n",
            "Epoch 69/100\n",
            "132/132 [==============================] - 3s 19ms/step - loss: 0.2312 - accuracy: 0.9278 - val_loss: 0.5606 - val_accuracy: 0.8600\n",
            "Epoch 70/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2213 - accuracy: 0.9320 - val_loss: 0.5961 - val_accuracy: 0.8600\n",
            "Epoch 71/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2479 - accuracy: 0.9255 - val_loss: 0.5579 - val_accuracy: 0.8628\n",
            "Epoch 72/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2462 - accuracy: 0.9216 - val_loss: 0.5648 - val_accuracy: 0.8656\n",
            "Epoch 73/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2305 - accuracy: 0.9324 - val_loss: 0.5288 - val_accuracy: 0.8661\n",
            "Epoch 74/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2559 - accuracy: 0.9227 - val_loss: 0.5753 - val_accuracy: 0.8611\n",
            "Epoch 75/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2329 - accuracy: 0.9259 - val_loss: 0.5182 - val_accuracy: 0.8767\n",
            "Epoch 76/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2384 - accuracy: 0.9261 - val_loss: 0.5836 - val_accuracy: 0.8661\n",
            "Epoch 77/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2563 - accuracy: 0.9241 - val_loss: 0.5325 - val_accuracy: 0.8667\n",
            "Epoch 78/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2614 - accuracy: 0.9255 - val_loss: 0.6201 - val_accuracy: 0.8417\n",
            "Epoch 79/100\n",
            "132/132 [==============================] - 3s 19ms/step - loss: 0.2444 - accuracy: 0.9214 - val_loss: 0.5769 - val_accuracy: 0.8656\n",
            "Epoch 80/100\n",
            "132/132 [==============================] - 3s 19ms/step - loss: 0.2184 - accuracy: 0.9326 - val_loss: 0.5065 - val_accuracy: 0.8711\n",
            "Epoch 81/100\n",
            "132/132 [==============================] - 3s 19ms/step - loss: 0.2384 - accuracy: 0.9264 - val_loss: 0.5523 - val_accuracy: 0.8628\n",
            "Epoch 82/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2346 - accuracy: 0.9299 - val_loss: 0.5678 - val_accuracy: 0.8639\n",
            "Epoch 83/100\n",
            "132/132 [==============================] - 3s 19ms/step - loss: 0.2694 - accuracy: 0.9220 - val_loss: 0.5469 - val_accuracy: 0.8578\n",
            "Epoch 84/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2098 - accuracy: 0.9305 - val_loss: 0.5520 - val_accuracy: 0.8628\n",
            "Epoch 85/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2459 - accuracy: 0.9271 - val_loss: 0.5672 - val_accuracy: 0.8583\n",
            "Epoch 86/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2483 - accuracy: 0.9262 - val_loss: 0.6077 - val_accuracy: 0.8494\n",
            "Epoch 87/100\n",
            "132/132 [==============================] - 3s 19ms/step - loss: 0.2232 - accuracy: 0.9294 - val_loss: 0.6494 - val_accuracy: 0.8467\n",
            "Epoch 88/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2190 - accuracy: 0.9351 - val_loss: 0.6562 - val_accuracy: 0.8400\n",
            "Epoch 89/100\n",
            "132/132 [==============================] - 3s 19ms/step - loss: 0.2395 - accuracy: 0.9302 - val_loss: 0.5531 - val_accuracy: 0.8689\n",
            "Epoch 90/100\n",
            "132/132 [==============================] - 3s 19ms/step - loss: 0.2183 - accuracy: 0.9322 - val_loss: 0.5629 - val_accuracy: 0.8650\n",
            "Epoch 91/100\n",
            "132/132 [==============================] - 3s 19ms/step - loss: 0.2309 - accuracy: 0.9250 - val_loss: 0.5682 - val_accuracy: 0.8561\n",
            "Epoch 92/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2286 - accuracy: 0.9297 - val_loss: 0.5734 - val_accuracy: 0.8728\n",
            "Epoch 93/100\n",
            "132/132 [==============================] - 3s 19ms/step - loss: 0.2003 - accuracy: 0.9422 - val_loss: 0.5538 - val_accuracy: 0.8628\n",
            "Epoch 94/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2036 - accuracy: 0.9354 - val_loss: 0.5850 - val_accuracy: 0.8567\n",
            "Epoch 95/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2016 - accuracy: 0.9372 - val_loss: 0.5641 - val_accuracy: 0.8672\n",
            "Epoch 96/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2174 - accuracy: 0.9330 - val_loss: 0.5581 - val_accuracy: 0.8694\n",
            "Epoch 97/100\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2200 - accuracy: 0.9346 - val_loss: 0.5727 - val_accuracy: 0.8661\n",
            "Epoch 98/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2033 - accuracy: 0.9392 - val_loss: 0.5561 - val_accuracy: 0.8661\n",
            "Epoch 99/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1930 - accuracy: 0.9445 - val_loss: 0.5580 - val_accuracy: 0.8600\n",
            "Epoch 100/100\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2037 - accuracy: 0.9400 - val_loss: 0.5918 - val_accuracy: 0.8567\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "4A1ouHsfzFZz",
        "outputId": "3c461da8-ab2e-418f-8d00-731e59ea4cc0"
      },
      "source": [
        "# Check out our train accuracy and validation accuracy over epochs.\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "import matplotlib.pyplot as plt\n",
        "# Set figure size.\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Generate line plot of training, testing loss over epochs.\n",
        "plt.plot(train_accuracy, label='Training Accuracy', color='#185fad')\n",
        "plt.plot(val_accuracy, label='Validation Accuracy', color='orange')\n",
        "\n",
        "# Set title\n",
        "plt.title('Training and Validation Accuracy by Epoch', fontsize = 25)\n",
        "plt.xlabel('Epoch', fontsize = 18)\n",
        "plt.ylabel('Categorical Crossentropy', fontsize = 18)\n",
        "plt.xticks(range(0,100,5), range(0,100,5))\n",
        "\n",
        "plt.legend(fontsize = 18);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtgAAAIBCAYAAABz4sjiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3wUx/XAv6MuoQaS6KIjegdTbcC44l7iFsd2XBPXxCVOHNcUl7gn/jnuJTa4GzdsAwbTi+m9CRAggYR6b3c3vz9mD51Od6c7FSTgfT+f+9zd7szs7Ozs7ps3771RWmsEQRAEQRAEQWgaglq6AoIgCIIgCIJwIiECtiAIgiAIgiA0ISJgC4IgCIIgCEITIgK2IAiCIAiCIDQhImALgiAIgiAIQhMiArYgCIIgCIIgNCEiYAstjlJqilJKK6WaPGakUuoGq+y0pi77ZEcp9bjVtgtbui7+4quvNbYfNmc/9vP40teFVktL3x9CbZRSadb1uKGl63KiIgL2SYLzwdbAzw0tXX/hxEAp9abVp3KVUuEB5Ntt5fumOevXGlFK9bAGM4+3dF2OFUqpT1yeP/9s6foIJzYug1N/Pz1aus5C6yekpSsgHDOyvGyPBtrUk6a86atTizJgZzOVXWiVndFM5QuB8TZwM9AOuAj4tL4MSqnJQB+X/M1Fc/bDxtADeMz6/biPdCdEX1dKJQAXu2y6Xin1qNba3lJ1Ek4qcoD6+pr0RaFeRMA+SdBad/S03dKKPeYrTXOjtf4F6N9MZc8CZjVH2ULgaK1XKqW2AQOB3+KHgG2lAzMAnN2MdWu2fngsOIH6+rVAGPA90A/oDZxt/ReE5maM1jqtpSshHP+IiYggCMcapxb6LKVUF18JlVIxwOXW3/9prW3NWjOhNXCT9f0/4AO3bYIgCMcFImALPnGxOZuilGqvlHpBKbVLKVXm6qyilIpSSl2tlPqfUmqDUipbKVWplDqklPpKKXWuj2P4cjyr5billBqllPpUKXXYKn+vVae2Xsr26vjl7qSnlJqmlJpt1b1CKbVdKfWYUiqinja6SCm1QClVoJQqUUptVEr9SSkV2hhHQKVUW6XUTdb5blZK5Vn12q+UmqmUGucjb1Od27lKqXmezi3Q83HhA6Aa8/y5oZ60V1JjwvSOVacG9zVf+OqHLmn6K6VmKKUyrXbcq5T6j1KqQz1lhyqlLlRKvaGUWmP13yql1BGl1BzrfJSHfGnAzy7/3W1B33PZV6+To1Kqt1Lqv8rYtJcrpYqUUuuUUo8qpWL9aRelVB+l1DtKqYNWu6crY1vvc7DkD0qpMcAQjLnL1xghWwMXKKWS/MifrJT6l9UvCq1z3KOU+lopdZ23/q6UGquUelcplarMs61IKbXNOs+z3dL60849lBd7Xff8SqmpVr89rJSyu13TnkqpB5VSPyrz3C217sNtSqmXlFLdmqpNlFLnWPWyKaU611PmEvf+FyhKqdFKqc+t866w2v5ZpVS8h7QfW8fzOYth9U2HlXZKQ+sWKEqphdYxH1dKhSml/qyU2mRdr3xlnqH1PpeUUpcqpb5TSmVZz4cs6/8lfuRNsO7jVarmXZGmlJqrlPq9UirOR94wpdQDyjzfS61+skApdU6gbSG4oLWWz0n8wdh0atMVPO7X1udmINP6XQ4UuebBCErOtA6gACh12aaB57wcY4q3OriUmwZcA1RZ/wswdnDOsrcA0b7y+zj3hcADVr0dQL717Sx7ARDspe7PuZ1jPkZ41MAi4J/OYzTm2gA2IA+ocGvnu+vJ25hzcz2+p3N7shHn9rmVd3c96ZZZ6ZYdg77mdZ+1/xy39i/G3AsaOIQxZam3bOtTiHUPuXw+BYLc8q22rrszTabb52V/+rq1/wq3+he5/T8ADKin7lOt83bmr3bZlwF0aeTz6DWrrDdcti2ytt1bT97fuFwPDVRi7Gld6zjcLU8w8LLbdSix2tx5nxT4+0xxSdPDpbwe3vID97geB/N8e88l7UIP5+P63CsAJjVFmwAK2Gtte9hHmf1d8k4I4Nq69qOLrLo474VKl31pHtrMmdcOdPNxjKetdDsD7Hc34OV6+ZnfeZ2eBBZbv6sxz0zXvvW4l/xhwMcu6exWH3S91jOBUC/5z6L2c6Laus5VLtsudsuTZm2/E1hp/a6i5v52Pl9vbMw9fTJ/WrwC8mnhDuC/gF0M7ABOxxICgBSXdBcBzwITgSiX7Z2AR11u9As9HGOKtzq4PPhKMcLAm0CytS8KuMOl7L/5yJ/m49zzrQfZk0CitS8WeMLl/Os8ZICrXPbPwBIugAjgFsyLzfnQW9iAa3OrVcdRQJi1TQE9gZesh58NGNEM53ahy/5PXdo8Ergd80J0vjwacm7nupR/mpc0/TzVsRn7mq99XTGCgAY2AqdY24MwgvdBl/bwlP8UjPB4BhDrsr0dcLdL2XUGTL7qFUBfH+nSLkuBIS71vwAzQNBAKm4DVWoLRnkYzXJ/a18YRnB3Dhb+F2hfcDlOlEs7THLZfqO1bYuPvOdRI6guBSZR85wKs/6/AQx0y/eMy7m9Te1nWpzV1z72t51d0vRwKbeHl/zlmPv3XWrur2Cgt0valzD3W1+X8wmx+tMP1AxsIpuiTYAHrfT7AOXl3J630mwO8Pq69qMCzMzMAJdzuoKa5+UvuA38gW3Wvie8lB9KjRLovgDrdgNerpef+Re6nFcFcBsQYe1LBj5zKd/Tc8mpqHEAfwPire1tqVHSaOBpD3lHUDOI2oJ5toa69KdRVvnT3PKlUXNPp2P6ujNfP2AFNe/+uIbe1yfzp8UrIJ8W7gD+C9iFQNdGHOd+q5yfPOyb4q0Obg++97yU7Xzg19GG4p+ArfGuWfjC2j/PbbsCdlv75uLhZeRW94XNcO1escp+qynPzdq31Vlv3LSq1v7bGnNuGMHuYD3X1Sn8FONhdqIZ+pqvfa9a+3KA9h72D8ZFW9SA9rjcypsaSL0C6OtOYWw3LoMSl/0jqNFq3u/t+JgZD0/94S5rfxkQ0sD+fJ2nNgBirHI1MNZDvhBqNK9LsAajfhwvhRoN4TMB1NNrO7uk6eHSZj285NfAFw1pK6ucYMxgTwPXNlGbJFGjTT7bw/5wINvaf1eA9XXtRzvxPCg4wyXNr9z23WNtP4iHWTfgMmt/BZYyoQHXVFvn5z5T5Pr50kP+hS75PSksgqiZidnitq+Ly733pJf6Od9xVUAnt31LrH27CEAQpkbArsAaMHvoC07B/dcN7acn80dssAV/+UBrnd6I/M7oD+OVUsENLOMfXrZ/bX33UUpFNaDcSswI31fZQ922D6cmdNyT2noiufE+Ztq9uXC26SQfaQI+N6XUUEyUD4B/aK0dHvK+SSPCwVllvmf9vVwpFe1Wh2DM9DbAp1rrkgCKb4q+5loXhbEFB3hNa33EPY3WegvG7KWhOOvcWynVpNF8LJtWpx3xs1rrMvc0Wuv1wJfW36t9FPekl/7g7EuRGG1rQ3A6Mn7gulFrXUxNdBRPzo5TMbM6AH/UWlf5ebzrMYJPLjVhEI81TzU0ozZhC3+0/ro/AxrUJlrrbMzAG8wMmjuXAIkYwesDD/v95VmtdZ3wr1rrn4Dl1t+r3Ha/jxlodQWmeyjzFuv7S611TiPqlgh08PFp5yPvQcyMRC2se8b5/hqklBrisvsyzICoAmPi4ol/YJ7lodQ4faOU6kvNtX9Ia13o68S88LnWeoeHOmdjtNhQ9/0n+IEI2IK/LKsvgVKqg1LqCaXUCmUWErGpGueobVayKMy0V6Dkaa1Tvew75PK7IWVv9SHAOct2f6iOtL6rqXkh1MISuhc1oD5HUUr1Uko9p5Raq4yjod2lTZ0OP119FNGQcxttfdsw2pE6WC+MhfWfgU/exWhH2lAjwDo5F2PyAR5iXzdzX3OnJzVttMBHOl/7UErFWI5Ei5RxbqxyqbOr0OvrejaEkZgZF4CffKSbZ30PVd6dWFd52e56D/oSQDyilOoDnIrpD54Et/et76s8DKInWN+ZWus1ARzWmW+e1roigHxNRTmwrr5ESqlTlVLvKaV2WA6O2qXf/MlK5t5nGtomYEyZwDiWujvvOoXYT7XWBQGW64o/99Fo143W8T5xqwcASqnuwJnW3zcaUS+Anlpr5eMzxUfehV6ULWCepc4oSK7n5vy9Wmtd5Cmj1jofWOOWHmqusx0zS9UQvN3T4P0dIfiBxMEW/KWO1s4VpdR4jMDn6gFeQs3UbjBGMwBGoApUw1DsY59r6LaGRLfwp2z3e8UZ0SC3Hu1Qg7W8luf4R5hpWSeujmlhGAGyTd3cR2nIubW3vnO01pU+8jdmRgOt9V5lopxMxdjZugrSN1rfO7TWtQYwx6CvudPe5bev6+m1PZRSKcB8agtCZRibTadG2CnM+LqeDSHQ+odgXqh1Fp6ytMl10FrbVE0QlIbcgzdiBgFLtdZ7Pez/CcuJEvgVNQI3gFPjvz/AYzY0X1OR62U24ChKqWeoEaLBCFL5GFMBqFkozL3PNPjctNaLVe1Y9U9bdemDuVcBXg+0XDd89UPnvvYe9r1m1Wm6UqqL1tqZ9maMwnCn1nphI+vWGLyel9a6QimVi7nPXc/N+bu+d4Xz/nTN67zOOVrr0kAq6oI/74jGRI06aRENtuAvXleuUkqFYATBeGADZvouVmsdo7XuoM0CNq4h5eqEIzuO8aataBTKrGb3Hka4XoCxX4zSWse5tOmvmuPYxxinUD3BEkJRJhzb+db2d1wTH8d97V2McJ2GuW4JWus2Wuv2Vp1dQ9y1ljofEywznuutv5NU3VCEGvP8cbaRu5lIQ+/BZrl3A8DnaoBKqTOpEa5fxYQvDNdat9Nad7T6zYvO5G7ZG3tuTi32zapm5HSzdZwtWusVnrM1L9osBrUOM4i+CY72H+diVG+2RL1akJbuw4IPRMAWmoLxQHfMC+N8rfUPHjRdLbJKZDOSbX0nKqXCfKRraGzg6ZhoH/nABVrrRR5sFpurTZ2zFc11bq58gdHiQo3W+lqMxsSGiYPsSkv0NdfZG1/n7HGfUiqZmqncq7XWn2ut89ySNef94Vp/X+Ynzn3OkJDHinMBn3GX3TjVsj11kml9dw/wuA3N59Tq+Yoh7zXmcAA4bZDnaK3v0Fpv0XWXi/fWbxp6bk7+h5lh6Q2cbpkM3WDta6z2Gvy7j7zNmjqF/xuVUkGYZ2UXjI3y+17yHCu8npdSKhxIsP66npvzd32mYc79rnmd1zlRKdXUM19CIxEBW2gKkq3vbJcpO3fOOFaVOUY4bSdDqRGeamFpfk5rYPnONt3pySnNorna1GnrF4Kxi62D9WKb0tgDWbavM62/17lpo77TWrubKbREX9tHjcA51Ue6071sT3b5vd5LGl91PmpG4KJNDIR1LmVM85HOWYeNWuvqBhynoTg10rMwEUN8fZz33Y0u+Z0mRB2VUrXsduvBme9MVc+CS27kW9/tLaHJE2MDKM8bzn7jsc9YfcFbn2tomwBgOct9ZP29FRPKsQPGbvzDQMvzgK/7yLnPm+34TIypXHeM825TOTc2BZN93KOnUmOO53puR22rvS0GYzkqH7XVdtnlvM7BmIGq0IoQAVtoCpyeyx08OMWglOqKifV7IrEBEzMY4M9eHqrX0nANkrNNUzy9/JVSwzEL7zQ5WutNwHbr718tYdqdG2k6ZzynmUgn4BHMVDi4mYdYHPO+ZjktfWr9/Z1SKtE9jVJqIC7e/W64evYP85A3BnjYRxVcHZ/qrHJXH5Zz2Bzr7wOeIu0opYZhohlAjWDV7FjX0GkO9InWusTXBxNPGOB6lwgxP2NC0gG8WM+siyvvYWZCEjBx4f1lo7P6mKga7ucUCfwxgPK84ew3dfqMxe+AXl72NbRNXHFqii+mxlSlsc6NTu738lybiolvDzUOjbWwbI2djrAPUxNRpLHOjU1BN2rMnY5iPUMfsv5u01pvdtn9BWZWJAITh9wTD2HMBaupifKC5fi/2Pr7pPKyGqvQMoiALTQFSzELwSjgUxdb2mBllhleyAlmK2YJXc7QXmcD7ytreWGlVIRS6ibMVGq+lyLqYy5G69gOmKGsZaiVWdL2Cmu/L+eUxvJX63sqMNMSXJ3n9jtMDO6meNGitV6HGbCAEbABDlMTJcWVluprT2HaOxGY59QKKsNZGA9+bzMN26kJ1/iOUmqUc4flsLkQ39FOdlHj1OZqExsID2Nezn2AOcoKE6aUClJKTce0dQiwh6YxAfCX66zjlgPf+ZHeOdDphCVYWWYTd2Ku+yRgvlJqknNgaN0zU5RSH1oDIax8qZgFiwD+pJR6y9X0RCkVq5S6UinlDBHozJeO6YcALyilznAK+9a1/QnPDnqB4gzBd65S6hGnCYBSKl4p9RDwH0yIwTo0tE3cylgDrMU4Uzs18k3VNzoBs5VS/az6hCilLqcm1OU6asJGesIp/E/AaG9b2rnRSSHwX6XULapmCfpkzKDVqZmvNZi2ZuJetv7+WZnoSPFW3nil1N8xq/ECvKC1Pux2zHswju99gWXKLHkfauUPVkqNUUq9ppQ60WaRWz/eAmTL5+T44P9CM1PqKed3Lmk1tZeRzsZMMXpbeGGKtzrQhMsS+zj3hT7K9lo3a/+LLsd2YEwJnAuOzKdmOfEfG3BtnqZ2mxa4lL0Xo8H21m5NcW7/cDt+HjULIiymEUulezjWnW7HeqoF+lp97XEedZcad0YuqW+p9POpvTx1KTXLu5dgTDe83mvAW25592McJp9zSeO1r1v7r6T2ktSF1F5Gu96l0uu5hn49K9zybLfyfB5AnrVWnllu269zuz4V+LdU+isu+539yetS6Va+4dSsOqmtdiyxfmdihP+An0lu6UKpWXbb9fniXBznO+Dv+LgHG9ImbvlvckkX0MqNvvoRZtVA57OswK2O+zGh8uorb4lLnoBWbvRQ1g0uZdW30EwmcKVb/oVW3idd6lVF7eXLNfB3L8cPw2jsnekaslR6gUvaKvxfKv0GH+3ynpXmvca078n6EQ220CRorV/DCCALMS+aEEzYof9gpjg3e818HKO1/iNwKea8izHTeNsxGoezqQmfFbC2V2v9Z8wL8hfMCzwUY5byJGblvUPeczcerfXDGMFwAUaYdJ7bnzECob8LevjDDMxL1okn8xBnvVqkr2mtZ2NiSn+McTQKw4SyewVzPfb5yPsdxh5/NqYvhGBegO8Co7TW8+s5/B2YQZPz3LphzI/qmKv4qMMnwCCMFnIP5nraMLMHjwGDtdbbvZfQtCilJgL9rb+f+krrhjPt+a5mQlrr/1nlvYSJhW7DLHyzH/gKs3BRrfPTWtu11nditLwzMIOMUMwMyTaM+dJluKG13oDR6jr7QhDmev4fRvje5p4nULSxgz8LY76yCyMUK8zz4PfAhdQTiaQhbeLG53B0RqjJZja01l9jtM9fYO57hbl/nscI/F7vJRec5kJN7dxY30IzHTBt6IkqzLPxIcxqleGYgdh84Dyt9SOeMmmtq7TWV2LMzH7AzEzEWN8/AJdqra/RXnwjtNZzMRrsf2Js9ssx754MjHnYbdQTp19oepQ1ShEEoRlQSi3DvEge1Vr/vaXrIwiC4C9KqcswQnY50Fk3jf11k6CU+hajAPhIa90s/igB1GUhMBl4Qmv9eEvWRWg9iAZbEJoJpdRkaiKM/OgrrSAIQivkLuv7o1YmXPeixrnxvy1ZF0HwhgjYgtAIlFL/p5S6QSnV0el8Zjmm3AZ8bSVboLVe7b0UQRCE1oVS6laMVtYBvNDC1TmKFSnjvxj5ZZXWekkLV0kQPCJLpQtC45gI3G79rlRKlWFCqTkjPWzD2FELgiC0apRS4zB25XHUhIR8VWu9teVqZVBKPYdZBbUjxv/BBvyhRSslCD4QDbYgNI5HMY5q2zAOdzGY0HxLMLFwx2jvC6IIgiC0JiIwzrMxmEhFj9E0Mb2bgkSMc28VsAI4R2u9smWrJAjeESdHQRAEQRAEQWhCTjgTkcTERN2jR4+WroYgCIIgCIJwgrN27docrXWS+/YTTsDu0aMHa9asaelqCIIgCIIgCCc4Sqn9nraLDbYgCIIgCIIgNCEiYAuCIAiCIAhCEyICtiAIgiAIgiA0ISJgC4IgCIIgCEITIgK2IAiCIAiCIDQhImALgiAIgiAIQhMiArYgCIIgCIIgNCEiYAuCIAiCIAhCEyICtiAIgiAIgiA0ISJgC4IgCIIgCEITIgK2IAiCIAiCIDQhImALgiAIgiAIQhMiArYgCIIgCIIgNCEiYAuCIAiCIAhCEyICtiAIgiAIgiA0ISJgC4IgCIIgCEITIgK2IAiCIAiCUAuHQ7d0FY5rQlq6AoIgCIIgCELrYPehYh58fz1r9+Qxsnc7Th2YxMQBSYzo1Y6wkObTy1bbHOzMKGL9vnyyCyuorHZQWW2nyuY4+jskWJEYG0FiTDiJceEkxoab37HhdIiPQCnVbPULFBGwBUEQBEEQTnIqq+28MnsX//5uJ1HhwVx1anfW783nua+28+ys7USGBTM2JYFTUhJJjA0nPiqU+Ogw4qJCiW8TRlR4MEcKK8nILeNQXjnp1ndWQQXRESG0j4ugQ3wESXFGGE6MieBgTinr9+Wzfm8+m/cXUFFlP1qfkGBFWEgQ4SHBhIcGERYaRLXNQW5xFVU2R626KwUH376E4NYjX4uALQiCIAiCcDKzcmcOD7y3ntTDxVwyritPXD2UpLgIAPJLqlixM5tl27JZuj2bf325za8yQ4IVndpG0jE+ggPFlaxJzSO3uLJOuojQIIb0aMt1U3syomdbRvRqR9fEKIKDPEvLWmuKy23kFFWSU1xJTlEFRWXVXtO3FErrE8vGZvTo0XrNmjUtXQ1BEARBEFqIL5YfYP6mTM4d2ZmzR3ZuVtOGY0lxeTWH8so5nF9OWaWNqmrLfMJmp7LaQbXNQWJcOL06RNOjfTQJMWFezSYqquxkFVTwyvc7+XBhGl0Tonj6+uFMG9rRZx3KKm0UlFZRWFpNQVk1haVVFJRWUVphp31cOF0SoujcLpKkuIg6Qm+1zUFOcSVZBRXkFFbQoW0k/bvEEnocXx+l1Fqt9Wj37aLBFgRBEIQTmLJKGxGhwQS1Mg1fc1BZbeeRGZv4YOE+IsOCmbUynXYxYVwxsTu/ntyDPp1iWrR+WmsyCyrYlVHE7sPF7MooZtehIjLzK4gKD6ZNRAhR4SFER4TQJiKE0GBFVkEFGXnlHMotp6i8OqDjxUaG0rNjG3p1iAYURworzKeggsIyU1aQgt+d05cHLhlAVHj9YmFUuKlj53aBn39oSBCd2kbSqW1k4JmPM0SDLQiCIAgnEFprdh0qZu76w8zbmMna1FxSusTyp0sGcs7ITgE7gmmtycgrZ2d6EWGhQZw6sL1f+Sqr7czbkEm7mDD6d42lXXR4Q07Hb9Jzy7jllVVs2JfPndNTeODSgSzddoQZi9KYu+EwNrtmbEoCl4xLJjI8GJtNU213YLObbzQkWhrYLu0i6dg2so7mW2tNWaWdvOJK8kqrCFKK2MhQoiNDiI0MPaqJdTg06bll7D5kBOhdh4qP/i4utx0tL75NKH07x9I1IZLyKjtllXZKK2yUVtoorbBRZXOQFBdOl3amTk7tcKd2kbQJDyE81Ngnh4cGERYSbATywgr2ZZawN6uUfVkl7M0qYV9WCUpBh7gIko7aQkfQIS6CUX3a0a9LbLNemxMZbxpsEbAFQRAE4ThBa03akVLKKm1U2zU2u+Pod0m5jaXbjjBvYyYHc8oAGNI9nkkDkpi74TB7MksY3rMtD142kMmD2nsUtCuq7GzaX8DmtAJ2ZBSyI72IHelFlFTUCIW/ntyDf147jPDQYK/1PJRnhN11e/OPbusQH0G/LrH07xrLgK6xnDe6CzGRoU3SLgu3ZHH7a6ux2R28fPNozh3Vudb+7MIKPl12gJmL0tibVeJXmUpB+7gIOrWNpMrmMEJ1SV0HO1ciwoKJiQihpMJGuYvDXlJsOCldYunbKYaUzjGkdIklpXMMibHhrSryhRA4ImALgiAIQgux/WAhucWVjO+f1CBnrGqbg+/WZPDaj7vZlFbgNV1EWDCTB7XnjGEdmTas49GpeJvdwefLD/D8VztIzy1jbEoCf75sEH06xbAmNZfVu81nY1rBUQEyvk0o/bvGMaBr7FHBeP6mTP7z3S6G92zLW3eOpUtCVJ06LN+eza2v/kJFtZ2nrxtOQkw4O9OLjMCeUcTOjGIqqux0bhfJizeN4rRB/mnEPeFwaF76dgfPfbWdfl1iefvOcfTqGO01vXOAAhASHERosDr6rZQxoXBGwTiUV05GbhmH88sJDw2mXXQY7WLCaRcdRlvro7Wxiy4qr6a43EZxmfkdFR5yVJDu2ymGttFhDT5HoXUjArYgCIIgHGPKKm08/cU23pqXitbQPi6cS8d34/IJyQzqFl9v/uLyamYsSuOtealk5JbTu2M0N0zrRae2kYQGBxESrAgNCSIkOIiI0CD6d40jMsy7Zrmy2s7MRWm89O0OjhTWRHQIDVYM69mWMX0SGNM3gRG92nqNK/z92gzueXMt4aHBvPb7MUyyTEa01rz+Yyr/+GwLPTtE8/ZdY0npXNf0wO7QrN6dy/3vrmNPZgm/mdKTR68cTHQA2uz8kipmrTzIzEVpbD1YyGXjk/nXDSP8siEWhKZEBGxBEARBaALKq+zc/cYaOrSN4OpTu3sVlH/enMWD76/nYE4Z15/ek4n9k/hixUHmb8rEZtcM6BrL5RO6cdqg9tjsDsqq7JRX2SmvtFNRbWfrgUJmLNpHcbmN8f0S+d05fTljWMcmcVYsq7TxyZL9lFbaGNM3gWE92hLhQzB3J/VwMTf+ZyV7Dhfz8BWDuW5qL+59Zy3f/JLB9FGdefnmUfUKzOVVdp79chuvzdlNl3ZRvHjTyKPCuiccDs2SbUf4eMl+flh7iEqbg8Hd47jlzD78amI3MbUQWgQRsAVBEIQmJyO3jHV78pg+uotfpg+V1XYWbMqiW1IUA7rGHZeRLR77aBNvzEklLCSIKpuDoT3iufrU7lw8Lpn4NmHklVTy2MzNfL78AL07RpLvQpkAACAASURBVPPcb0cyrl/i0fy5xZV8syqdz5cfqGWj7E5wkOKCMV247Zy+DO/Z9licWkCUlFfzx7fX8d2aDOKiQikur+Yvlw/ijukpAQm7v+zO5Y9vrWVvVgk3nN6L6aM7mxBwpVUUllVTUFJFfmkVC7dkkZFbTnybUC4dl8xVp/VgSPf6ZwEEoTkRAVsQBEFoUg5ml3LJ04vJyC1nVO92PH/jSJ/RCFwXswCIiwplTN8ExvVLZGxKAkN7tG22eMV2h+b7NRms2pVLn07RDEiOY2ByXMBOdst3ZHP5M0u4fmovHrh0ALNWpPPRYmOmEB4SxJnDO7FiZw6FZVXcMT2FP1zQ36dmeE9mMdsPFhERGkRkeAgRocFEhgcTGRZM2+gw4tu0bttdrTWv/bibmYv38+RvhvkdYcQdd1MaV0KDFXFtwhjULY6rT+3B2SM6BaRtF4TmRARsQRAEoclIzy3j0qcWU1RWzZ3npfDqD7spKa/m7vP7cdf5/WpFmCgsreIfn23hw4VpJCdG8eiVQ6iotrNyZw6rduUeFbgjw4K5+aze3HfRAJ8RKpxk5pdTXG6jT6dorxrTymo7ny07wKs/7GJfVulRrbMTpyZ9ZO923HJWH5/2yyXl1Zz+yHyCgxTz/z7tqL2v1prN+wv4eMl+Zq08SK8O0Tz725EMTI7zqy2FGnZmFJFbXEl8mzDi25gluCPDgsX8Q2i1iIAtCIIgNAmH8sq49Kkl5JdU8cmfJjG8Z1tyiip5dOYmZq08SErnGJ6/cSSjerfju9UZPDxjIzlFldx2dl/u97CYRU5RBat25TJ7zSFmrTxIvy6xvHzLKIb18GwWUVRWzcvf7uCteXuosjlIjA1nfL9EJvRPZHz/JFI6x1BaYeODhft4fU4qWQUVDO0Rz13n9ePcUZ3JzC9n+8FCth4sZNvBQrYdLCL1cDHj+iXy/j3jiY3yrNV+4L11zFiUxlcPTeaUvgke02itRRgUhJMIEbAFQRCERpOZX86lTy8mu7CSTx6YxMjetZdz+2nDYR783wYO55czuFs8m/cXMLRHPM/eMIKhXgRmV+ZvyuT+d9aRXVTJ3ef34w8X9j9qNmKzO5ixKI1nZ20nt7iSKyZ245SUBFbuzGX5jmwO5ZUDkBATjs3uoLCsmlMHJnHnef04dWCST8F31sqD3P3mGgZ0jWPmfRNJjK29KMqCTZn8+oXl3H5uXx65ckigzSYIwgmKCNiCIAjHOTa7g7QjpXRuF9ki4ciOFFRw6dOLySyo4KP7JjLGixa3pLyapz7fyqxV6dxzQT9uOqM3IcH+21YXlFbx2MxNfLrsAAOT43j55lHkFFfy+Eeb2ZlRxLh+iTx+9ZBaGm6tNQeyy1i+I5vlO3JwaM3NZ/ZmRC//13OevzGTm19ZSZeEKD5+YBJdrRjPBaVVTP3rT8S1CePHx6aK/a8gCEdplQK2Uuoc4GUgGHhLa/202/7uwDtAEpAHXKu1TvdVpgjYgiCcaFTbHHyx4gD//m4n+7LMIhldEiLp3TGGPh2j6d0phn5dYjmlb8LRpZqbmqyCcn71r6Vk5JYx876JjE1JrDdPY80l5q4/zAPvGW221tA9qQ2PXDmY6aM6N5sZxsqdOVz30nJiIkP55IFJ9OkUwx2vr+abX9L57pEpXs1WBEE4OWl1ArZSKhjYBZwJpAOrgau11ttc0nwGfKe1fl8pdTrwW631b3yVKwK2IAitjYVbsohvExZwqLXKajufLN3PK7N3cTCnjMHd47h2ck/ySqpIPVzMnsxiUg+XUGotY90h3sRlvmZyT5IT666wFyi5xZX8uO4Qs9ccYsm2I4QEBzHj3glM6J/U6LL9Jb+kiudmbSM5qQ2/ndbLL+fHxrJ5fwFXP7cMgBvP6MWzs7Zz/8UDuO/iAc1+bEEQji9ao4A9Hnhca3229f8vAFrrp1zSbAXO0VofVEZdUai19h4DChGwBUFoHrTWbEwr4OMlaczbkMlDlw/isgnd6s3304bDXP/yCoKDFC/cNIrL/chTUWVn5uI0/u/7XRzKK2dkr7b88cL+TBvWsY7mVmtNVkEF6/bmMXNRGgs2ZwFw+pAOXDe1F6cP7VDLPMPh0JRU2Cgur6bK5sChNQ4H1rfG5tCs25PH7DUZLN+Rg92h6ZYUxfmju3DFpO4+w/CdSOzJLObKZ5eSkVvO0B7xfPfwlGabHRAE4fjFm4DdkmuKdgEOuvxPB8a6pdkIXIoxI7kEiFFKJWitc49NFQVBONnJLa7ki+UH+XhJGtvTTbziTu0iueettcRFhXLG8E5e8247WMjvXlvNoG7xxEaFctcbaziQXcofL+zv1cRh1a4c7nvHLCF9SkoCz984ksmD2ntNr5SiY9tIpo/qwvRRXTiYU8bMRfv4aMl+rn95BR3iI4hvE0ZxeTVFZdWUWNru+ujdMZo7z0vhvNFdGNwt7qSLjNG7Ywzf/HUyz3+1ndunp4hwLQhCQLSkBvtyjHb6Zuv/b4CxWus7XdJ0Bl4BegKLgcuAwVrrAreybgVuBejWrduo/fv3H5uTEAThhKSs0saCTVl8vSqdOesPUW3XDO/ZlqtP687FY5MJUnDZM0vYdaiYTx+Y5NHZL6ugnOl/W4jDofn+sakkxIRz/7vr+GzZAa6Y2I1nfzuy1qIqpRU2nvxsC+8u2EvXhCievm44U4d0aLBgW21zMG/jYb5amY7doYmNCiU6IoTYqFBiIkOJiQwhLCSYIGVWDAwKUgQpRVCQES5TOsecdEK1IAhCoByXJiJu6aOBHVrrrr7KFRMRQRAaQnF5NT9tzGT2mgzmb8qiospOQkw4l01I5qpJ3RngtmhITlElFz+5iJyiSr566DT6d63ZX1Zp47Knl7Azo4ivHjrtaHg6rTUvfrODZ2dtZ+KAJN66cyzxbcJYtCWL+99dT0ZeGTee0Zu/XDaINhEtOcEoCIIg+ENrFLBDME6O04AMjJPjNVrrrS5pEoE8rbVDKfVPwK61ftRXuSJgC4IQCBvT8nnx6x0s3JxFpc1Bh/gIpo/qzHmjuzA2JcFneLmD2aVc+M9FAHzz18kkJ7XB4dDc9uovzF6bwTt3jeOckZ3r5Pt8+QHufXst3dtHM7JXWz5ddoDeHaN54aZRXhcwEQRBEFofrU7ABlBKTQdewoTpe0dr/U+l1N+ANVrrbywzkqcAjTERuUNrXemrTBGwBeH4o6LKzgcL93HW8E50b9/mmBxTa8278/fyxMebiYsK5eJxyZw/pguje7cjKMh/04gd6YVc/ORiEmLC+fqvp/HWvD28/O1OHr1yML8/N8VrvuU7srnpPyspLrdx+/S+3HvhAImvLAiCcJzRKgXs5kAEbEE4vtBac89ba/ls2QEiQoO46/x+3H5uSrMKm4WlVdz7zjq+X3uIM4d15KVbRtEuOrz+jF74ZXcuVz67lMSYcNJzy7jmtB4899sR9dowZ+SWUV5lp0+nmAYfWxAEQWg5vAnY4hYtCEKL8vqcVD5bdoDbzu7DWSM68eys7Ux9+CcWbMpsluNt2JfPWY8vYO6Gwzx25RDe/8P4RgnXAKf0TeDN20/hcH45kwYk8fR1w/1yEOySECXCtSAIwgmIaLAFQWgxFm7J4tfPL+PcUZ154/axBAUpFm89wkMfbGBPZgnTR3XmiWuG0jUhimqbgyOFFWTmV3A4v5wjhRX07xLL+P6JfgmzWmve/mkPf/t4M+3jI3j992MZ1cf/ZbT9Yf+RUjq2jTgmi6EIgiAILY+YiAiC0KrYm1nC9L/9TOd2kXz78JRaUTMqq+28PieVF7/ZAUBsZMjR5bLdGZQcxy1n9eHicV09CrY5RRXMWpnOp8v2s2V/IWeP6MSLN42ibXRYs52bIAiCcHIgArYgCK2G4vJqzvv7QnKKKvnxsal0S/Ls2Hgwp4xXZu/EZnfQsW0kHdtG0ik+go5tI0mMDWfBpizemJvKzowikmLDuWFaL66b2os2ESHMWXeIz5cfYOGWI9gdmiHd47n+9J5cc1oPie8sCIIgNAkiYAuCcMzQ2izHHRMZWmefw6H57b9XMH9TFp88MImJA5IafazFW4/wxtxUFmzKIjwkiNCQIEoqbHRuF8ml45O5fEK3k2aJb0EQBOHY0RqXShcE4TigrNLGDS+v4HB+BRed0oWLxibTt7Nnx7y9mSV8vvwAX6w4wIHsMjrGRzCwWxwDk+MYlBzHgOQ4vlhxgLkbMvnntcMaLVyDWSp88uAOTB7cgV2Hinhv/l4qq+1cMi6Z8f2TCA4g5J4gCE2IvRIOfgldLoDQ6JaujSAcU0SDLQiCVyqq7Fz/8gqWbjvCqD4JrEnNRWtj93zxuK5cdEpX2kSG8M2qdD5ffpC1e/IIUjBpYHvG9Utkb2YJ2w4WsvtQEdX2mmeNv2HsTlqqi6E0DeKHtHRNBKHhrLoV9rwJbYfD5G8hyudCzIJwXCImIoIgBES1zcEt/7eKOesP8/LNo7hiUneyCsr5dnUGX61MZ+2ePABCghU2u2ZA11h+NbEbl4xLpmPbyFplVdkc7D5UxLaDRZRV2rjq1O4SacMXiy6CQ7PhzKWQOK6layM0JxU5YC+HNsktXZOmJfUN+OU2SL4cDs+B0BiY/A20G9XSNRNcObIUqnKh60UtXZPjFhGwBUHwG7tDc9cba5i18iBPXjuM357Ru06aA9mlfPNLOkXl1Vx0SlcGdYuvv+CqfMhaBF0vBCVh+D2SsxLmjgcVDFHd4Nz1EBbXsLK0hvSvICYF4gc1bT2PN7SGTY+Y9jh9PkR2aLm62Mog41vY9yEc/hFwQMrdMPRvRhA93sleDvOnQIdpMPk7KNoOC8+DyhyYMAOSL27e41cXw953oWQfDHwQIjs27/GOV4p2wY+jwFYCKXfByOchqK7fjOAbEbAF4QQkI7eMBZuzSMsq4cpTu5PSufGOfFprHnhvPTMWpfHQ5YO46/x+TVBTIGM2/HILlB+GU96EPjc3TbmtAYcdDnwGe96ApEkw+JGGv6jmnwGFm2H8h7DwXOh+FUz4sGFl7X0PVv7W/I4fBj2vhe5XQ1SXhpV3vOKohpU3QdoHgDLaulO/hGNpouSww5GfIW0GHPgCbMUQ2QV6XGMEwtTXzXUZ/crxrU0sO2SEtpA2cM5qCGtrtpdnwuKLIHc1jHgW+t/b9O1flg47/22059WFZpAaGmfatPtVx/Z6Nyf2Ktj6JMT0hS7nQZgfyo06ZVTAnHFQng7Jv4LU16D9FJj0KUQ0wjfGYYeSPVCwGQo2mU/xLogdAB3PgI5nQkxdhc3xjAjYgnACUG1zsDo1lwWbspi/KZMd6UUABCnQwMVju/KHC/v7FLTTc8tYsvUIMZGh9OkUTY/20UeXJdda88THm3l9Tip3n9+Pv1zeBFrPqgJYd6/RKMUPgaAwKN0PF+yqefkerzhssP9j2PoPKNppBKbyDEg4BSbMDPxFkvUzzD8dRr4I/f8Am/8Omx+F8f+Dnr8JrKzSg/D9YCNYd/uVEexyVwEKOkyFHtdCj6shOCKwct3J/MkIjKP/A0Gt0G++uhiWXA6Zc2Ho3835rn+gYW0aCFUFZjYiZ4X55K6C6iIIjTXXo8evIek0CLJMpbJXwC+3QuEW6HqJac+WHgg5bGArNRpO53doLMT08ZzeXmU01wWb4KyVED+49n5bOay83gxGe98C3a+sXbat1Gj3ky+DuP7+1zNvHWx/Hg58CjiMWUr/e43gueIGyF1p2nTMf1t25qKp2PcBrLjO/FYh5n7uerEZmPnbZ1bfDrv/a2YYupxnZlN+uQXC28NpX0G7EYHVKXc1rP0D5K83Jk9gZiljUiC6DxRshLKDZnubntDpTCNwR3qxy4/tB+FNuxBYcyECtiAch5RX2dmwL5/Vu3NZvTuXVbtyKC63ERKsGJeSyLShHZk6tAMJMeG8Pmc37/y0h/IqOxedYgTtfl1i0VqzeX8Bc9cfZs76w2w5UFjrGEEKkhPb0LtTNOGhwfyw9hA3ndGbv/96aOOdEA/9CKtuhopMGPhnGPwoFG0zGq6+d8LolxtXfkvhqDYC65Z/QkmqGTgMfhSSL4WDXxjnLm0zmrOe1/mnOdMa5k00L6ELdhtB0GGH+VPNS+vcDf4L7FrDz2dDznKYvgmie5ntRbtNvdM+NFqmrhfBqbMartmrzIPZA6DiCIz6N/S7q/48Drtpo9A4U6823SG4mRb9Kc+CRedB/gY45XXofZPVppOhYAuct9V/gcReac6zIsv6HDECcx0BscQIyYXbTD4VBHFDIHE8dJwGXc73PqhxVMOOF2DzE0ZwGv409P1982tetcPU1zkYyFlhzCsclZ7TJ06APreZgUKIi7/FL783mtBJn5p93o616VHY+k/v9UkYB2ct9++8Nz5iBrghMdD7Zuh3N0T3qNnvsMPOF2HjwyaSyehXofsVdcuxV5jBWGO0t8cCrWHOGDMQGfs2ZHwNB2cZLTFAuzEw+GFjhueNA5/B0itgwP1mNsFJ3lpYfIkx5Rn7thmA+8PBL2H5tRCeaAZH8UOh7VCIHVjTP7Q2dTw8DzLnGWWCrdh7mcFRkHI79L+/1Q+KRMAWhFaK3aHJKargSGElRwoqyCqoYOehIlbvzmXz/gJsVvSNPp1iGJuSwOlDO3DqwPYeY0znFlfy2o81gvZpg9qz+1Axh/LKCVIwum8CZw/vxLRhHamstrMns4TUw8XsOVzCnsxi0o6UctmEZJ68djhBjQlvV5kHGx6EPW9B3EAY9x4kjKnZv/p2M4177oa6Wq5jTVm6+SScUr9duL0K9v3PTM+W7jPREQY/agRV17ylB2DFb+DIYjM1Pea/9U/jZsyGRecbQbDPrbXL+n4YxKYYp0d/TE92vwarf2+O2/d3dfdrDdueho0Pwbj3odd19ZfpiZU3mvaIHwIlaWZWoj4BZdszsOHPNf9VEEQlQ3Rv82k/ueHT3q4Up8LP50D5IZj0mSnTdd/3w6D9aTDle++CXM5KWH0HlOyF6gLvx1IhEBJtzCJC2hgNb+J4I4gmjAncrrpkrxFWM+fCmNeg722B5a+PqgLIWeWmXbcG3uEJkDAe4gZY5+Q8L+u7JBVS3zTCUlhb6Hm9EbazlxoN6MAHzcCgPvI3mmO6l582E9bcAVPnQKezfJdRkgbfpRjt7Slv+vZVKNwOK66HvNXQ8SxzTY4OlrLMYAmMmcSQR823LwG/7BDsn2naIPmyxvdXf8leAfMm1L23C7cb/4J9Hxib9z63wcgXICSqdv7iPfDjSCP8nrm47vOk4oiZ8cleYvwChjzmXZOsNWz/l7mfE8bB5K8hor1/5+GwGYG+ysN9pa2Zwf0zISgc+vwOBj4AkZ38K/sYIwK2ILQiHA7Nn95fz9z1h8ktrsThdhtGhAYxrGdbxvRNYEyfBEb3bUe76HC/y88truT1ObuZtSKdwd3jOGdEZ6YN60hirP9lNIjiVNjxkjEHcVTAgAdgyON1NXaVufBtCrQdZhzOjqVtZHUxZC00WpTMeVBklmOnTQ/ocwv0urGuU5S90pzT1qeg7ICJhDD4MaON9FZ3h90IsZsfM+HJJsyEpAme02qH0epXF8H5O+q+9A58Dkt/ZWYBhj/l+/xK9sL3Q41wN3WO7/od1eRuCTyEWuZ8WHAGDPyLse3+fqhpu7FveM9TsMWcZ+fpZgq/ZK/RpJfsNZ+inVCV1/BpbyfZy2HxxYADJs+GxLF10+x8BdbeBae8Ya67O3veMYOUyM7mOkd0cPu0N1r4kOjm0cA77LDoAsj6CaYt9N53XClJM+3njrabts9ZbgTqwm0YozJlBriJE6wBwXhj11vf/ag1HFkIu1+H9C+N5l0FQYczzIAlqBERguxV8G0fM+g6c6nvuqy80QjkF6b6138dNtj+LOx+1Wi8Xa9nZAfT5qn/NX4iSZPM4LnjGTV10A6jgU19zTiparvZHhRu+kiPX5u+HdyMz9llV8OhH+CSDDMgccdeBZseNucZ2x8mfmQUAWCeY/MmGiH73PW1Nf3uZay/D3a9Yvp3yl3mfo1IrJ1m9e9h7zvQ7UoY927t2YymoGg3bHvSDBpUiFE89L/Xe71bCBGwBaEV8a8vt/HiNzu4YEwX+nSKoUN8BElx4XSIi6R9XDgd2kYSFnKcRNnQGrKXwY7nIf1rY4fb49fmQegrjvPu/xpN9qTPoNvlntPkrTN2qSl3N1zL6uTQD2ZaOmeV0ZAERxptacczzAt277uQtcA8yLteZDRASRONoLXtacu2eqzR6HQ6x/9BQc4qWH6NMf0Y9R/P2kjnlK0vu+BVt8Cet+H0n6Dj6Z7TaIex4c5fD9O31B/67agm91SY8oP/52QrMwI1ypighETC2j/CzpeNY5unUGyOapgz1swWnLfFs6ZLOyD3F6OJc5/27n0j9Pqtb+GlqhA2/tUIUG16wNQfjC2nJ7TDDBByV8P0zTUvbUe1OZfd/2ccsiZ+3HK2oFUF8OMYY3ZyzlqI6uw97fbnYf39vssLjTdhHxMnQNJ4M2sT2kjH6Iojxpk2bx2MebVp2sr5bDh9nrk/PVG0E2YPNM+GUS82/phO7BXmPtv2tDWzNQ4G/skMxFPfNDNX4UmmL/a5xVyjtA9h/0emLULjjQlK39/XCLZNRVkGfN3DmMGMfN532sz5xk67MsfMKPS7x/jC7HzZmIX5E8mlYIt5Zu7/xGjC+94O/e8zA8ollxkzj8GPGCVKc0aFKtlrlBt73zPP7th+5t7seIaZaWholKUmQgRsQWglfL82g5v+s4qrTu3OCzeOPH4XW6k4AunfGFOPvNUQ1s68VFLu8G8qz2E32syqfDh/e92pzH0z4JebjdYlONwIGHEDG1bXjO9gyaVG6Eq+3DjYJE6oK6wV7TLns+89o2UPCjUCV9JEo7F21WYFQlU+LLvGhGTrc6sRtJ1aT4fNOCOqYDh3k3ftn620pr0GP2qcFN1fLDtehnV/MNqkXjf4V7f6NLmeWP+gmRqetsBomsEIt9+lGDOPM5fWfeFufgI2Pw6nfmFs1f2hcIcRtg98agYNkV2MFr/PzbVnRbQ2dt1r7zbT/Sl3GYfG+kwzStLMQCFhtBm4VOaYmYIji4196rCnWt5xs2ALzB1n7Fqn/Vy3z2qHcdrc8YIxVejpZSAa08doNI+H8Jj2SqPFbtMDzljs+Z5behUc+g4u3Ou/WUKgddj7njEHKztgtnWYagbeXS+uex0cNiPUpn0I6bNM/qFPwIAHG6fRd2XjI0bgvTC1xq/CF5W5xgcm/StoNxry1hhBe9RLgR23cLtpB6fJRniiuc/GvtW8jsLulO439t6H58GRRWAvM8/NhFOMwD3wT561+s2MNwEbrfUJ9Rk1apQWhNbKjvRC3fu2r/W5TyzQFek/a52/uaWrFBhFqVpve07ruZO0nqG0noHW36RovetVratLAy8va7EpY+OjNdvs1Vqvvc9sn3ea1nkbtf48SevZQ7S2lQd+jENztP4oTOsfRmldme9fHlu51ns/1HrlLVpnLtDa4Qj8uO7YbVqvf9Cc19yJWpcdNtv3vGu27f+8/jLyN2v9/UiT/uMorVfcqHXOL6Z+hTu0/jhC65/PD6y+DrvWP52u9SfRWhfvqz997jqtZwZrvfKmuvtS3zF12/s/tzxrtZ4ZovXSa/yvV606OrQ+PM/qd2j9ZSett79o+lxJmtY/n2e2fz9C65zVgZW9+02Td/XdWs9KNm24b0bD6tlc7P/M1HHVbbW32yq0Xnq1Vf+7TB87Udj5ijmvw/Pr7svbYPZteKj562Gr1PrgN1oX7vQ/T2We1kuutJ5hk7UuOdAE9Sg3z8GFFwaWz+HQevfrWn8cqfUPo02faSiFu7Refr3WX/c2z+6WxFahdeZCrTf8VesfTzFt00L9H1ijPcijosEWhGNEYWkV0/+2kOLyKpZev5HYnQ+b6cSzVgQWkqq5sFeYaeaSPR52auOQUrDZ/I0fZrQ4yZcYzVpjtPDLrjFaifO3G5vWZVcZ2+i+d5ip36BQyPjeRINIuTuwyCNZC00s6ZgUo/1rDWGf9n9iYlOHtTPmByt+Y36fs8b/dsxdY+Imp800Wpy2I4ymvTzDRMYI1BmodD/MHmJMO6bN967ldNiMNrUs3Vwv9zCL2mEWySk9ABfsNOYH9kr4cbRZLW76lsZdA62N5mrL38z0dER7qC4x+4b+3UydB6px1tosgnL4B7Owz2mzoN3IhtexudjwF2O24JxpqC4yER+yFhgTgAF/OnHiPIN5Hn1jOb6esaj2uS260MwyXLSv9Yb61No4AK+5w4QmPeUN76Zw/rD3fVh5g2UiNi3w/OVZRrsbGt3wOrRm7BWNDznaQMRERBBaELtDc/1Ly1m+LYOVV3xD+5wZJi5rzjLjRHLWypYND1W4zTjPFGyynIU8vKije9U4nUX3bLpjl2XAd/2MnW3ZASO8jXnVhFRzZc09sOvfNXFb6yN7mQlV16a7cRJrTeG38jcaJ7zSNPN/yvfQ+dzAy6kqNGH3Ul83127CR9DjqobVKfUtEwXCV7g9p53vxE88hzoDyPkF5o41Dq4j/lUjGE6eDV2mN6xunjiy1JipBEfBiGfMdW4o5VnGbjvljuYxN2gKHHYzyMxaYNp/8xNQuBXGvXNsp+mPJTv/Y8x+XE2RnCudDv0HDP5ry9bPH4pTjRIhb7V5po18KXAhV2tjHuaoNIPUE2kgdQIgArYgtCBPf7GV935Yy8/n/JdOVSth0MPGPi93tVmYoe0I8xIJdATuDLe26/+MfaUzEkDiOP80hVobj/h19xqv+nHv+ie8NjVbnzIh4yI7mRX2EsfVTWOvME5y5YeMY50vLW3OL8aBLbKT0X61xqWSK3KMRiootPGrCmpt7IcbM4hwanKPLDTOZRFusWcrc2D+NKM9O+1rP6I7fGhCp62ynBPHvtXwugmGyjwTA7lkr9FGUOkRVAAAIABJREFUTvoCOp/d0rVqPuwV8E0vMwN1xkKzbf4ZZjB54d7jRxvrqIZNj5lndXg7E6HEGbml3ej6o29kL4N5k5onZKPQaETAFoQWYvaaDP7x9ld8PfFZkkIOo9wdQw58AUsvN6GOJs703wmpusSYGhz83HhSVxea1bK0w+yvJXBPMHFtXcuuyDYOMBnfmKgY495tOUHUXgV73jRafV+REgq3GXODpEkw9ce6baW1mTpefLF5kZ2xuOVXwzueKDsEswd5j/kcEg3nbas/Okl5lnF4rC4yZhfnbW58tArBULDZxB0e8oRxzjzRcTruTlsIWFFyRr4A/f/Y0jULnCNLzNoAOSugeLfZpkKMgqXDVLN6qyfFwdIrjGPfJekt4sQn+EYEbEE4xtgdmjfm7Gb+T5/z9vBniI0MRZ02y4REc2fbs7DhTzDoIRjmY4UzJyV7jRBZuBWGP2NCJyllhO681eYBnr3CxL11xsUNjTNh5hLHGwFp48Nm3/BnjO3q8RBdAEzs3dW/gxHPwYD7jF1w9lIT1i39K2NmEtXNLKLQGLOBk5XiVDMN74l2o/33F9j5ihGMps5pmM2oIIBZXv2bXkZBYK8w9v0XpraYvW2TUZFt7jNnbPLsZcZWu/+9ZlEV54C09CB809MMKFxXXRRaDSJgC8Ix5GB2KXe/tZao3Lm8N+JZgqK7E3z69yZUlie0NkJj6htmidreN3ovPPMnWHoloI2TnK/VzrQ2mpKcFTUP8oItJm/sAGsRgmGNOdVjj9Ym5N6h2Sbk3uE5ZqAQFG7awul82Vqdn04mqvLlOgiNZ8eLxowNTlwzieJUo/Q48IlZTXPQwybs6eYnYPszcMGeVrfAimAQAVsQjgFaaz5Zup9HZmxiarvV/HfwvwhqOxh1+lzz0PSFoxoWnm+cmMa+aewOXZdfDok2AviGB8wyt6d9BTG9A69kdZGJaxo/tOlX3jpWVObCDyPNuXS5wCya0PGs48cmUxAE/7GVGS12SBvPK52eSOStNSZAmT+ZGbjqIrMg1mmzWrpmghdEwBZaN1WFLb4aU2PJKarg/nfXM2f9Ye4esZM/t38M1XYYnD7Xfy1eVaFxZinc4j1N8qUw7n0RJm3lJiTbifyyFQTBULDVmFDE9m3pmhwbDs8zgnb+OmN/3mFyS9dI8II3AbuFl6gSBGDPu2Y57NPn1oRiakq0wyxXHda2SeNNa63Zl1XK0u1HWLY9m4Wbj1BZbee9Sw9zVumjqHajjCNeWLz/hYbFwdmrzLLDtlKzRLLrd2RHswz58WIv3Zwcr9p3QRACJ35QS9fg2NLpTOO7UJYObbq1dG2EBiACttCyVOaauLraZpZfPntV08T4tFdA5gLj9JbxjVnWNTwRLtjVKJvQymo7367OYMnWIyzdns2hvHIAOrWN4OyRnXhwzFa6bL/HOBNO/aFhkRNCoqD9pAbXURAEQTgBUEEiXB/HiIAttCwb/mLCy/W/D3Y8D+mzjAmELxw22PCgWaQjuE3N6lTBbYxwmrcWDn1vtL4hMdB5uomcsf4+2PhXs4hJA1i2PZsH31/PnswS2sWEMbF/Enefn8SpA9vTs0Mb1P5PYMVN5lhTvofQmAYdRxAEQRCE4xsRsIWWI2eViQna/16z1O+h781iI10u9L3c8fZ/wY4XTJxne0WNCYXdaJOJ6AA9rjExlTtMheBws710H+z8N/S6MaD4sdmFFTz+8Wa+XHGQ7klt+OAP4zl9aEeCgixNu9aw6z+w7o+QdKpZafBkt48WBEEQhJMYcXIUWgaHHeacAhWZxis8NMbEMV5yqVnxzX2ZbCf5m2DOaCM8T/qkbpn2MqPR9mSjXFUI3/WHqGQ4e2W9dsx2h+bDhft48rOtlFfZuGN6Cndf0J/IsGCXY9pg7T1mmeWuF8OEGUaLLgiCIAjCCY84OQqti9TXjXf0xI9rTCm6Xmxslzc/Dt2vqevEZq+CFdcZG+rR/1e3zKBgCPJhlhEWZxYnWXGt0Zz3ubVOEq01B3PKWL4jm/cX7GPDvnwmDUjiqeuG06eTW9nVRSYe9eEfYcCfYPhT4nwoCIIgCIII2EILUHHE2EJ3mAbdrqjZrpQxFZk/1WiEB9xXO9/Wf5ilwE/7CiISG3bsHteYJbk3/AW6XooOT+BAdhkrdmazfEcOy3dkk5HrdFwM55VbR3Pp+GSUu+Nl6X4Ts7poB5zyBvS5pWH1EQRBEAThhEMEbOHYs+FBsJfC6FfqRgzpMAU6nQ1bn4TeN9fExs5dY7b1vA66XhTwIfNLqtiYls/+I6WUZd/DrY5fMeft67hn8+8oqbABkBATzoT+idx/jmK6ep6YnK9R+b1h+VCzKEv8EPNdfhgWXwj2ShOGT5aBFgRBEATBBRGwhWNL9jLY+x4M/LP3mNTDnoIfR8L2Z2HYP4wj44rrIKIjjHo5oMOl55bx+o+7mbEojfIqOwDhIUG0HXoJVyV+zoFJVxPZeSLj+iWS0qkNat97sP4B4zTZ4zdQmWOcMfd/XLvg6F4m+H/cgICbQBAEQRCEExsRsIVjh8MGq283ToaDH/aert0I6H4V7HgRUu40EUOKtsOUH/xetGXXoSJe/X4XX6w4CMCl45K5YlJ3enWMpkNcBEH2afDdcn4X8RJMuQaKd8H82yB7CbQ/Dca8Vlt4ri6Cgi1QsMmYuPT9PUQkNaY1BEEQBEE4QREBW2h+tIbMebDtGSOgnvqFifThi6F/hwOfw/JrIGsh9L4FOp/jM0u1zcHq3bm8OS+VH9cdJiIsmOtP78VtZ/clOdEtskdQDIx8AZZdBYvOh6z5EBINY9+GXjfUdVYMjYWkCeYjCILw/+zdeXxdVdX/8c9qmqEhnZuWzhMUKDKXFmRqoUyCjDIJCqIgCDKIKFDl4YfI9CCoCA9TyySIlRksYBkFhEKRqQN0btM5HZImbeas3x/npiRphnuSc5Pm3u/79crr5pyz7z6rBX2W+1l7LxGRJijBlpYrWgjFi4La5Kx+29ZTV5XBkieDFejCWUGJxz5/CI7Ya07XnYIa7AX3wQ7DYN8/NDgsL38zb81aw9uz1vLenLUUlVTSPTudK0/YlfMnjqRPt8zG3zHk9OA0kVWvwrBzgndk9Y3/zy8iIiLSACXY0jLuwcrvpq+C68zcehsBV8K8vwTnXPfYAw54GIae9U3Tl3js8T9QvDD4rNUVcUtZJX986SumzVzJwtXFAAzo1YUTxg5i/Lf6MWGPfuyQFce/2mZw8D+CjpA99w7xhxcRERFpnBJsaZl1/wmS692vC1avC74Myj8W3P9NR8X+R8Ouj8GOE7dd3Y5Hlx3h8H/VufXFko387L6PWbSmmMN278sPJ4xg/B592bl/122P0otHRg/IUHItIiIi0VGCLS2zcHJQszz62rptwaurgrIR6wRdR0b2uupq54HXFnDz07Po3TWTqVcfzMGjVc4hIiIi2x8l2BJeRREsmxqc9FE7uYagm2K3nSN93dqCUi57aCbvzFrLMfv25w/n70uvnBClJiIiIiJtqF37OpvZMWb2tZktMLNrGng+xMzeMrNPzewLM/tOe8Qp9SybCpWbYcSPE/6q1z9bxeG/fYMZ89Zz27l7M+XnByi5FhERke1au61gm1kacA9wJLAc+NjMXnT3ObWG/QaY6u7/Z2ajgWnAsDYPVupaOAW67QZ9Dkjoa6Z9soIf3z2D0YO7c+9F+7PLwG4JfZ+IiIhIFNpzBXsssMDdF7l7OfAUUL8HtgM1WVV3YGUbxicNKZwbbHAceX7LNi7Gad7KTVz24CfsM6InL/92vJJrERER6TDaM8EeCOTVul4eu1fbDcA5ZracYPX65w1NZGYXmtlMM5uZn5+fiFilxqIpYJ2DNuIJsmlLBef/+UO6ZKTx0KXj6JKRlrB3iYiIiEStXWuw43AW8Ii7DwK+AzxuVr/FHrj7A+4+xt3H5OaqfXXCVFfA4sdg4PHQpV9iXlHtXPbgTJbmb+aBS8YxoFd2818SERER2Y60Z4K9Ahhc63pQ7F5tPwamArj7B0AW0KdNopNtrfgnlK6FkYnb3PjHl77itU9XccOZe3LgLvpHLSIiIh1PeybYHwM7m9lwM8sAzgRerDdmGXAEgJntRpBgqwakvSycDF36Q/9jEjL99M9W8b/PzeW0g4Zw/sQRCXmHiIiISKK1W4Lt7pXApcBrwFyC00Jmm9mNZnZCbNhVwAVm9jnwN+A8d/f2iTjFbVkJq6bB8HOhU/SHzyxcXcQl93/MHkN7cNu5+7SsK6OIiIjIdqBdG824+zSCzYu1711f6/c5wEFtHVdS2LwM5twO+9wGnXdo/XyLHwOvhhHnt36uego3l3P+nz8kvXMnJv/8AG1qFBERkQ5te9/kKC01726Yfw8seKD1c7kHp4fkHhJ5l8YFq4o47ndvs2hNMfdfPJbBfbSpUURERDo2JdjJyKth6d+D3+feAVVlrZsv/z0omh/55sY3vljNcTe+TcHmCv7xq0M4eHTfSOcXERERaQ9KsJPRug9gS15QL12yMijvaCl3WHA/dO4KQ74XSXjuzr3T5vGDu/7DkNxsXvmfCRygE0NEREQkSSjBTkZLn4K0LBhzN/QaA3Nug+rK8PPkvw+vHwJLnoAR50VSy11SXsWlD8zkd1Nn8d39B/LCpMNUFiIiIiJJRQl2sqmugmX/gAHHQ3pX2P1aKF4Iy56Of47COfDOiTD9YCheBPvfB/v+odWh5a3bwsm3vMNzH+Zxzamjue/isWRntus+WxEREZHIKbtJNmvfgdI1MPTM4HrQSdBtV5hzCww9A5o6/m5zHnz5P7D4UeicA3v9Hna5vNUr11XVzsNvLOSWp2fTyYxHLjuQo/bp36o5RURERLZXSrCTzdKnguR4wHeCa+sEo6+FD8+FldNg4HENfy//fXjrGKguh12ugN2vg8zerQ7n6xWbuGrKf/lk4QYm7NGP287dRyUhIiIiktSUYCeTqnLIeyZYte7c5Zv7w86CL6+H2b8PEu/6q9jrZsBbx0KXATDhVcgZ3upQyiqquPvlr/nzy1+T0yWdv1w4hlMOHKwGMiIiIpL0lGAnk9WvQ/mGb8pDanRKh92uhpmXwtp/Q7/Dvnm24b/w1tGQlQtHvAnZA1sdxpdLC7j0/o+Zt7KIUw4czP87a0/6dMts9bwiIiIiHYE2OSaTpU9BRk/Y8chtn404H7L6BrXYNTZ+AW8eCendI02uT7vtXYpLK/nrL77NPT/dX8m1iIiIpBStYCeLyhJY/jwMPR3SMrZ93rkL7HIlfH4tbPgE0rrAmxODz4lvwQ5DWx3CV8sLOeN/3yOnS2eeu1bH74mIiEhqinsF28y6ND9K2s2qV6CyaNvykNp2vjhYrf7vVfDGEcEGyCPehJwRrX79wtVFnH77e2R27sTTvz5EybWIiIikrDAlIqvM7P/MbL+ERSMtt/SpoASk7/jGx2R0h1GXBkf5eSUc/gZ0G9X6V6/dzGm3vYsDU391CMP65rR6ThEREZGOKkyC/T7wE+AjM/vMzC41sx4JikvCqCiCFS/D4NOgUzNVP7v+Akb8KEiue+ze6levWL+F025/l9LyaqZefTA7D+ja6jlFREREOrK4E2x3Pw4YClwP5AB/Blaa2RNmNiFB8Uk8VrwEVSVNl4fUyOwFB0yBnnu2+rVrCko47fZ3KdxcwVNXH8Rug7u3ek4RERGRji7UKSLuvtLdf+/uOwFHAM8CJwOvm9kCM7vOzAYkIlBpwtKnIHsQ5H67zV5ZWl7FOXf+h7WFZTx51UHsOaxnm71bREREZHvW4mP63P0tdz8H6A88AYwAfgcsMbPnzWxsRDFKU8o3wqpXYcgZwabFNnLDU18wa1kh9120P/vt1KvN3isiIiKyvWtxRmZmvc3sSoLa7HOAzcDDwIPABOA/ZnZBJFFK4/KeheqK+MpDIvLSR8t59M3F/OzYnZm4d/82e6+IiIhIRxAqwbbAMWb2D2AF8AegDPgZMMDdf+LulwBDgLeB30Ycr9S36FHoOgp6tc3hLkvWFnPVw/9lv5G9uObU1m+SFBEREUk2cTeaMbPfAecCAwlWqx8FHnD3T+qPdfdCM3sUeCSiOKUhRQsg/13Y62YwS/jryiqq+Om9H9HJjP+7eCzpndUIVERERKS+MJ0cJwGfENRZP+num5sZ/1/gxpYGJnFY9GhQdz38h23yupumzuKLJQVM+fkBaiQjIiIi0ogwCfa+7v5ZvIPdfTYwO3xIEpfqKlj8KOx4FGQPTPjrXvlkJQ9NX8hPjhzJsfvpoBgRERGRxoQ5B7tOcm1mXdQ+vR2teRO25AVNYxIsL38zV07+hD2H9eA3p38r4e8TERER6cjCbnLsa2b3mtlKoBgoNrNVsXv9EhOiNGjRw5DREwadkNDXfPD1On7wxw+oduf+n40lMz0toe8TERER6ejCbHIcDrxHcO7118CHsUe7ARcBJ5rZIe6+KPIopa7yAlj+HIz4MaRlJeQVc/MKufnp2bz++Wp27JHF/T8bx7C+OQl5l4iIiEgyCVOD/QegN3CKuz9f+4GZnQz8DbgDOCW68KRBS5+CqlIYGX15SN66Lfzvc3N4+j/L6NYlnUmn7c75E0eSnRnmXxURERGR1BUmazoCuKd+cg3g7s+Z2f8B50cWmTRu0cPQYw/ouW9kU7o7tz4zh/tenY8BFx+zM5cetws9czIie4eIiIhIKgiTYDswv4nn82JjJJEK58D6j2DfOyM9+/r9ufn8+eWvOWncIH5z+rcY2FvH8ImIiIi0RJhNju8QtEBvzHiC7o2SSIseBusMw86JdNr7X1tAn26Z3PXj/ZRci4iIiLRCmAT7CuAAM/uDmfWtuRk7WeROYFxsjCRKdQUsfhwGHg9ZuZFNO39lEa9/vpofHTGCrAydEiIiIiLSGmFKRN4AsgiS6CvMrCB2v0fscx3wptUtW3B3H9nqKCWw8lUoXRP52dcP/msBmZ078cMJIyKdV0RERCQVhUmwl6Ea6/a16GHI6gsDjo1syvVFZfzj/aV876Ah9OmWGdm8IiIiIqkq7gTb3ccnMA5pTmk+rHgJdrkcOqVHNu1jby2mtKKaC4/eKbI5RURERFJZqE6O0o6WPAFeGWl5SFlFFQ+/vpAj9uzHqAHdIptXREREJJWF7h5iZiOBE4Gagt1FwAvuvjDKwKSevGeh597QY/fIpnz+w+Xkbyrjp8fsHNmcIiIiIqkuVIJtZr8DrgHqHzVxu5nd7O7XRxaZfKOiCNZ9ALtdFdmU7s79r81n9ODuHLxbdCeSiIiIiKS6uEtEzOx8YBIwAzgJ2Dn2cxLwATDJzM5LQIyy9p2gPGTHIyOb8t05+cxdvomfHr0TFmHDGhEREZFUF2YF+xKC5Hq8u1fWur/QzKYB7wI/Bx6JLjwBYPXrkJYFuQdFNuX9r82nb/dMThw3KLI5RURERCTcJsfdgKfqJdcAxO49FRsjUVs9HXIPDZLsCHy9YhNvfrGGHx0xksx0NZYRERERiVKYBLscyGniedfYGInSlhVQOAf6R1ce8uC/FpCVkcYPJgyPbE4RERERCYRJsD8Gfmpm/eo/iLVOv5CghCRuZnaMmX1tZgvM7JoGnt9lZp/FfubV6h6ZOla/HnxGVH+dX1jK0+8v4/SDhtC7qxrLiIiIiEQtTA327wjapc81s8nAnNj93YEfEaxgnx3vZGaWBtwDHAksBz42sxfdvWZe3P3KWuN/DuwTIt7ksHp60L2xxx6RTHf3P+dRWe389GgdzSciIiKSCGE6Of7bzE4B/gLUPy9uGXCuu78b4t1jgQXuvgjAzJ4iOF97TiPjzwL+J8T8HZ97sILdbyJY63sCLV+/hUffXMQZBw9lxI5NVfuIiIiISEuFOgfb3V8ys38C+wE1BbyLgP+6e3XIdw8E8mpdLwfGNTTQzIbG3vdmyHd0bAVfQumayOqv73phLgC/OHHXSOYTERERkW3FlWCbWQ7wOXC3u/+RoB7740QGVs+ZwNPuXtVIfBcS1IAzZMiQNgwrwVZPDz53nNjqqRasKuLv7y3j/IkjGdg7u9XziYiIiEjD4qo7cPdioDdQHOG7VwCDa10Pit1ryJnA3xqbyN0fcPcx7j4mNzeJuhKung7ddoXs1p9Vfcdzc8lM78Rlx4+KIDARERERaUyYwt4PgTERvvtjYGczG25mGQRJ9Iv1B5nZrkBPgm6RqaOqFNb+O5LTQ2YtLeCFj5Zz4VE70adbNGdpi4iIiEjDwiTY1wCnm9mPLILe2rHmNJcCrwFzganuPtvMbjSzE2oNPZOgwY239p0dSv5/oKokkgT7tmfn0GOHdC46RieHiIiIiCRamE2OdwIbgYeA281sIbCl3hh39yPindDdpwHT6t27vt71DSFiTB6rp4N1hn7jWzXNR/PX8/rnq5l02u503yEjmthEREREpFFhEuwRgBMcyQewTcMZidDq16HPAZDetcVTuDs3/2MWfbtncv7EkREGJyIiIiKNCXMO9rAExiG1la2HDZ/AHje0apq3Z61lxrz13HzOXmRnhjqRUURERERaKO4abDMbYmZdmnjexcyS6Iy8drTmTcBbVX/t7tzy9GwG98nm7PHDm/+CiIiIiEQizCbHxcDJTTw/ITZGWmvVdEjvDr33b/EUr3++mi+XFvDLk3Yjo3Pru0CKiIiISHzCZF7NnRzSiaBGW1rDPdjg2G8CdGp5Wcff31tK766ZnHzA4OYHi4iIiEhkwi5tNpVA7wYUtCIWASheCJuXtKo8pHBzOdM/W81JBwwiXavXIiIiIm2qySVSMzsXOLfWrd+Y2QUNDO0FfAt4LsLYUlME7dFfnrmC8spqvnegVq9FRERE2lpzNQg9gJodcg7kAtn1xjhBC/UpwKRIo0tFq6ZD9hDo2vKmMM/8J4+RO+aw1/CeEQYmIiIiIvFoMsF29z8BfwIws2rgCnd/si0CS0mVW2D1v2DYOdDCZpnL12/hg6/X8atTRhNBw00RERERCSnMOdgq5k20Va9B5WYYclqLp3jugzwATtHmRhEREZF2oaR5e7LsacjsDX0Pa9HX3Z2n/7OM/XfuzdC+O0QcnIiIiIjEI1SCbWZnmtn7ZrbWzKoa+KlMVKBJr6oUVrwEg05u8fF8s5cVMm9lEadqc6OIiIhIu4k7kzOzq4FbgfXAh7FPicqq6VBZBIO/1+Ipnvkgj/Q047tjB0YYmIiIiIiEEWap9BJgBnCEu5ckKJ7Ulfc0ZPSEHQ9v0derqp3nPszj8D13pFdOZsTBiYiIiEi8wpSI7Aj8Vcl1AlSVw/IXYNCJ0Cm9RVO8PzefNQWlfO/bQyIOTkRERETCCJNgLyA4F1uituYNqChsXXnIf5bRtUtnJu61Y4SBiYiIiEhYYRLsPwA/NrOcRAWTspY9DendWty9cUtZJf/8ZCXf3X8gWRlpEQcnIiIiImGEqcGuAtYCX5nZFGBx7F4d7v5YRLGlhuoKWP48DDwB0lpWO/3ap6vYXFrJqQeqPERERESkvYVJsB+p9ftvGhnjgBLsMNa8DeUbYEjrykMG9OrCAbv0iS4uEREREWmRMAn2hIRFkcrynobOObDjUS36+rpNpbw9ay0XH7MznTqpNbqIiIhIewvTKv2dRAaSkqorIe85GHg8dO7Soimen7Gcqmrn1G+ruYyIiIjI9qBFrdLNLNPMBppZRtQBpZS1/4ayfBhyWoun+Pt7S/nW0O7sOqh7hIGJiIiISEuFbZW+r5m9CRQBy4CDY/f7mtkbZtayYzBSVd7TkJYN/Y9p0de/XFrArKWFfP+QYdHGJSIiIiItFneCbWZ7A+8CI6m3kdHd1wJdgHMjjS6ZVVdB3rMw8DjonN2iKZ769xIyO3fipANUHiIiIiKyvQizgn0jsBLYHbgGqL+j7g1gbERxJb9170PpmhY3lyktr+LZD/M4dr8B9MxRpY6IiIjI9iJMgn0I8KC7FxMcx1ffMmBAJFGlgmVPQ1oWDPhOi77+2qerKNhcwZmHDI04MBERERFpjTAJdhZQ2MTzbq2MJbUsfz6ovU5vWWPMv727hIG9u3DI6L4RByYiIiIirREmwV4I7NfE88OBOa0LJ0VUbIItedDngBZ9ffn6Lfx79lrOPHiozr4WERER2c6ESbCfBH5Q76QQBzCzq4BjgMcjjC15FS0MPnNGtujrU99bijuccbDKQ0RERES2N2E6Od4BHAm8BnxFkFzfZWa5wI7AdODeyCNMRsWxBLvrTqG/Wl3t/P29pRwyOpfBuTtEHJiIiIiItFbcK9juXk6QYP8SKAFKgVHAOuBXwPHuXp2IIJNOcctXsD/4eh3L8rdwps6+FhEREdkuhVnBxt0rgbtiP9JSRQshMxfSu4b+6t/+vYRuXdI5dj8d2CIiIiKyPWpRq/T6zCwzinlSRvHCFq1eb9pSwT9nruDkAwfRJSMtAYGJiIiISGuF6eR4rJndUO/ez8xsE7DZzJ40s/SoA0xKxQuha/gE+7kP8yitqFZ5iIiIiMh2LMwK9tXArjUXZrYb8CeC7o7TgTOASyKNLhlVlQdH9LVgBfupd5ey26Bu7DWsRwICExEREZEohEmwdwNm1ro+g2Cz41h3Pxb4O3BuhLElp81LwKtDJ9hz8wr5bPFGzjxkGGY6+1pERERkexUmwe5JcGJIjYnAm+6+KXb9NjA8oriS19Yj+sIl2FPfX0Z6mnHqtwcnICgRERERiUqYBHsdMBTAzLoC+wPv1nqeDmjnXXOKFgSfIVew35m1hgN3zaV3V+0nFREREdmehTmm7wPgIjObDRwb++4rtZ7vBKyKMLbkVLwQOu8AWf3i/krB5nK+WrGJ4/cfmMDARERERCQKYRLs/wHeAqbGrh919zkAFhQFnxx7Lk0pWgg5IyBEHfXH89fjDgeM6pPAwEREREQkCnEn2O4+J3ZyyEFAobv/u9bjHgTNZ96ONrxNEtRGAAAgAElEQVQkVLwQuu3a/LhaZsxbT3qasc/IXgkKSkRERESiEqrRjLtvcPeX6iXXuPtGd/+Tu38eZj4zO8bMvjazBWZ2TSNjTjezOWY228yeDDP/dseroXhR6A2OM+atY6/hPdVcRkRERKQDCNNopndsBbv2veFmdreZPWFmR4d5sZmlAfcQ1HOPBs4ys9H1xuwMXAsc5O67A1eEecd2p2QlVJeF2uBYUl7F54s3Mk7lISIiIiIdQpga7D8Bo4CxAGaWQ3CKyIDY8zPM7PD6q9tNGAsscPdFsfmeAk4E5tQacwFwj7tvBHD3tSHi3f4UxY7oC5Fgf7pwAxVVzrhRvRMUlIiIiIhEKUyJyIHAtFrXZxAk19+Jfc4FfhVivoFAXq3r5bF7tY0CRpnZ+2b2oZkd09BEZnahmc00s5n5+fkhQmhjLTgD+8N56zCD/XdWgi0iIiLSEYRJsPtRNyE+Fpjp7q+6+2rgEWCfCGODYIV9Z2A8cBbwoJlt0yfc3R9w9zHuPiY3NzfiECJUvBCsM2QPifsrM+atZ9eB3eixQ0YCAxMRERGRqIRJsCuALrWuDwPeqXVdAIRZZl0B1G5LOCh2r7blwIvuXuHui4F5BAl3x1S0EHYYCp3iq8yprKrmk4UbVH8tIiIi0oGESbDnAada4ASgF/BGreeDgQ0h5vsY2Dm2UTIDOBN4sd6Y5wlWrzGzPgQlI4tCvGP7UrwwVP31rGWFbC6tVP21iIiISAcSJsG+h2DVeiPwNEGiWzvBPgT4Mt7J3L0SuBR4jaB+e6q7zzazG2MJPLFn681sDkETm6vdfX2ImLcvxQtD1V/PmLcOgHG7aAVbREREpKMI02jmMTNz4CSgELjZ3SsgOMKPoNnMvWFe7u7TqLtxEne/vtbvDvwi9tOxlW2A8o2hVrBnzFvPkNxs+vfs0vxgEREREdkuhDmmD3d/HHi8gfvrgf2iCiopFYc7os/d+Wjeeg7fs18CgxIRERGRqIVKsGvEVqyHxy4Xd+iyjbZScwZ2153iGr5gVTHri8o4QBscRURERDqUUK3SzWwvM3sHWAvMiP2sNbO3zWzPRASYNLauYI+Ia/g39dfa4CgiIiLSkcS9gm1m3wLeA7KAF4DZsUe7A98F3jWzb7v77EamSG3FC6FLf+icHdfwGfPW06dbJiP65SQ4MBERERGJUpgSkRsJzsI+yN2/qP0glnz/Ozbm1OjCSyIhj+j78Ot1jBvVGzNLYFAiIiIiErUwJSKHAvfUT64B3H0WwQkih0UVWNIpij/BXrF+C8vXb1GDGREREZEOKEyCvQOwuonnq2JjpL7KEihZEXeCPWNesGdUDWZEREREOp4wCfYi4Pgmnh9PR+6ymEibFwefcTaZmTFvHTlZndl9SI8EBiUiIiIiiRAmwX4MONrMnjSz3c0sLfbzLTN7AjgKeCQhUXZ0ReHOwJ4xbz1jdupFWifVX4uIiIh0NGE2Od4B7AucCZwBVMfudwIMmAr8IdLokkWIJjMbisv4esUmTho3KMFBiYiIiEgihGmVXgWcYWYPEbRLr2k0swh43t1fT0B8yaFoAaR3g8zma6o/nh+rv95FGxxFREREOqK4Emwz2wG4Cpjh7q8B0xMaVbKpOaIvjiP3Zny9nozOndhneM82CExEREREohZXDba7bwauAwYnNpwkVbww7hbpHy9Yz17De5KVkZbgoEREREQkEcJsclwI7JioQJJWdRVsXhJX/XV1tTN7WSF7DtPpISIiIiIdVZgE+17gAjPT4cxhbMmD6oq4Euyl+ZspKa9i98Hd2yAwEREREUmEMKeIFAEbgK/N7FFgPrCl/iB3fyyi2JJDzQkicZyBPSevEIDdlGCLiIiIdFhhEuxHav1+ZSNjnOC8bKkR4oi+uXmFdDIYNaBrgoMSERERkUQJk2BPSFgUyaxoIXTKgC4Dmx06Z/kmhvfLITszzD8WEREREdmehDkH+51EBpK0ihdCznDo1PypIHPzCtljqDY4ioiIiHRkzW5yNLNdzWzX1o5JWTVnYDdjc2klS9ZuVv21iIiISAfXZIJtZmOA2cDRzcxzNDDLzPaMKrCk4B6UiMSRYH+1fBMAowd3S3RUIiIiIpJAza1gXwAsBu5uZtzdBC3TL4oiqKRRvgEqiyBnRLND5ywPThAZPUgr2CIiIiIdWXMJ9njgGXevbmpQ7PkzaCNkXWXrg8/M3GaHzs0rJCerM4P6ZCc4KBERERFJpOYS7MHAvDjnWgAMbV04Saa8IPjMaH7j4py8QnYb3B0zS3BQIiIiIpJIzSXY1cR/0kjn2HipURFfgu3uzM3bpPprERERkSTQXIKdB+wd51x7A8tbF06SqVnBTm86wV6xoYRNJRXspvprERERkQ6vuQT7LeAsM+vX1KDY87OAN6IKLCnEuYI9N9YifbSO6BMRERHp8JpLsO8CugCvmdkuDQ0ws1HAK0AW8Mdow+vg4qzBnhNLsHcdpBIRERERkY6uyfpqd59vZj8D7gdmm9l7wGfAJqArsA9wEGDABe4+P8HxdizlBWCdIa3pk0Hm5m1iSG42Xbukt1FgIiIiIpIozW5gdPfJZrYUuA04NPZT26fAr9399QTE17FVFASr182cDDJneaHqr0VERESSRFwnhMSS5/3MbBjwLaAbwSr2LHdfkqjgOrzygmY3OJaWV7FwVRHHjxnYRkGJiIiISCLFewQfALFkeklCIklG5QXN1l/PW7mJatcGRxEREZFk0dwmR2mNiuYT7Ll5mwDYTWdgi4iIiCQFJdiJFEeJyJzlhWRlpDGsb04bBSUiIiIiiaQEO5HiWsEuZNeB3UjrpBbpIiIiIslACXYiNVOD7e7MzitUi3QRERGRJKIEO1GqyqCqpMkSkfzCMjYUlbObNjiKiIiIJA0l2IlSEXRnbGoFe87yWIt0nYEtIiIikjQaPabPzIa0ZEJ3X9bycJJIeSzBbmIFe25Ni3SViIiIiIgkjabOwV4CeAvmTGtZKEmmoiD4bGoFO28T/Xtm0Ssns42CEhEREZFEayrBvpGWJdhxM7NjgD8RJOUPufut9Z6fB/wvsCJ26y/u/lAiY4pMefMJ9ty8QtVfi4iIiCSZRhNsd78hkS82szTgHuBIYDnwsZm96O5z6g39u7tfmshYEqJmBbuREpGKymrmrdzEhD36tWFQIiIiIpJo7bnJcSywwN0XuXs58BRwYjvGE61mVrAXri6iosq1gi0iIiKSZJoqEWmUmeUAPWggQQ+xyXEgkFfrejkwroFxp5rZocA84Ep3z2tgzPanmQR7TqxFus7AFhEREUkuoVawzexMM5sFFAJLgcUN/ETpJWCYu+8JTAcebSSuC81sppnNzM/PjziEFqooAOsMadkNPp6bV0h6mjFyx65tHJiIiIiIJFLcCbaZnQQ8SbDqfT9gwN+AfwAVwCcEGyPjtQIYXOt6EN9sZgTA3de7e1ns8iFgv4YmcvcH3H2Mu4/Jzc0NEUIC1XRxtIZboM9ZXsioAd1I76yjyEVERESSSZjs7pfAXGBv4PrYvSnufiYwBtgF+CzEfB8DO5vZcDPLAM4EXqw9wMz617o8Ifb+jqG8oMkzsL9avoldB6k8RERERCTZhEmw9wQedfdSoDp2Lw3A3WcBDwDXxjuZu1cClwKvESTOU919tpndaGYnxIZdZmazzexz4DLgvBDxtq+Kgkbrryurqlm1sYRhfXdo46BEREREJNHCbHJMA9bHfi+JfdY+AuNr4OIwL3f3acC0eveur/X7tYRI2rcr5Y0n2PmbynCHvj2y2jgoEREREUm0MCvYy4GhAO5eAqylbk30LsDm6ELr4CoaLxFZU1AKQD8l2CIiIiJJJ8wK9n+AiXxTf/0icIWZlRAk6pcQnPoh0OQK9tqaBLu7EmwRERGRZBMmwb4XONnMusRWsCcRNIu5IfZ8NsFGSIHYJseGm8isLQwS7Fwl2CIiIiJJJ+4E290/Jjj5o+Y6H9jbzPYEqoC57l7d2PdTSlU5VG1pfAVbCbaIiIhI0mpRJ8fa3P2LKAJJKhWFwWcTNdi9umaQoTOwRURERJJOmEYzE83sliae32JmE6IJq4Nrpk36moJS1V+LiIiIJKkwS6i/AnZq4vlw4NetCydJVDSdYOcXlqo8RERERCRJhUmw9wI+bOL5jNgYqVnBbqxEpLBUR/SJiIiIJKkwCXZ3mj7nugTo2bpwkkQTK9juTn5hmUpERERERJJUmAR7BXUby9S3H7C6deEkiSZqsDduLqe8slpdHEVERESSVJgE+5/AuWY2sf4DMzsCOJd6bc9TVhMlIvmFZQD01Qq2iIiISFIKc0zf74FTgdfM7BXgs9j9vYFjCVavfxdteB1URQFYGnTeYZtHNW3StYItIiIikpzCNJpZY2bfBv6PIKH+Ts0j4BXgUndfFX2IHVBNm3SzbR6tUZt0ERERkaQWqtGMuy8FvmNmPfnmyL4F7r4x8sg6svKCRk8QqeniqFNERERERJJTizo5xhLqj5sdmKoqCppsk56dmcYOWa1uoikiIiIi2yH16k6EplawC3QGtoiIiEgya3QZ1cyqgWog293LY9fezHzu7lqarSiALv0bfLSmoFQniIiIiIgksaaS4ccIEuqqetfSnPKmS0R2H9K9jQMSERERkbbSaILt7uc1dS1NaGaT44Tu/do4IBERERFpK3HVYJvZDmZ2vZkdneiAOryqcqja0uAK9paySopKKlUiIiIiIpLE4kqw3X0zcB0wOLHhJIGKwuCzgRVsHdEnIiIikvzCnCKyENgxUYEkjZo26Q2sYKuLo4iIiEjyC5Ng3wtcYGa9ExVMUqhoPMHOLywD1MVRREREJJmFOVKvCNgAfG1mjwLzgS31B7n7YxHF1jHVrGA3UCJSs4KdqwRbREREJGmFSbAfqfX7lY2McYLj/FJXEyvYawpL6Jxm9MrJaOOgRERERKSthEmwJyQsimTSRA322liTmU6drI2DEhEREZG2EneC7e7vJDKQpNFEicjawjId0SciIiKS5MJscqzDzPqYWZ8og0kKFQVgadB5h20eBSvYme0QlIiIiIi0lVAJtpkNMLNHzawAWAOsMbONZvaImQ1MTIgdTE2bdNu2DGRNYamO6BMRERFJcnGXiJjZEOBDgrOwPwNmxx6NBn4IHGlmB7h7XuRRdiSNtEmvrKpmfVGZjugTERERSXJhNjn+DugJHO/u02o/MLNjgWdjY86LLLqOqKKgwQ2O6zaV4a4mMyIiIiLJLkyJyFHAvfWTawB3fwX4P+CYqALrsBpZwV4Ta5OuTY4iIiIiyS1Mgt2ToLlMY+YD22aWqaaRFey1sSYz/bSCLSIiIpLUwiTYy4HxTTw/NDYmtZU3nGDXdHHUCraIiIhIcguTYP8DOM3MbjGz7jU3zaybmd0MnA78PeoAO5zyAkjvvs3ttYVqky4iIiKSCsJucjwE+DXwSzNbGbs/AEgD3gduija8DqaqHKq2NNJkppSeORlkdG7x0eMiIiIi0gHEne25+xaCEpGfAv8CNsd+XgMuBCa4e0kCYuw4KgqDz0ZKRFR/LSIiIpL8wqxg4+6VwIOxH6mvpk16I5scVX8tIiIikvxUrxClmhXsBktEyrSCLSIiIpICwnRyvL6ZIQ6UAMuAt919bWsC65AqGl7BdnfWFmoFW0RERCQVhCkRuYEgiQawes/q368wszvcfVIrYut4GikRKdhcQXlltRJsERERkRQQpkTkW8B/gQ+AM4C9Yz9nAh8CM4EDgNNiv19jZj9takIzO8bMvjazBWZ2TRPjTjUzN7MxIeJtezUJdr0SkZoj+lQiIiIiIpL8wiTYFwClwGHu/g93/yL2MxU4DKgAznT3Z2LXXxKcONIgM0sD7gGOBUYDZ5nZ6AbGdQUuB2aEiLV9NFIiUpNg91WCLSIiIpL0wiTYZwJT3b2q/oPY6SJTY2NqX+/SxHxjgQXuvsjdy4GngBMbGPc74DaC5H77Vl4A1gk659S5/U0Xx8z2iEpERERE2lCYBLt77Kep57WXbtfxTW12QwYCebWul8fubWVm+wKD3f2fTQVmZhea2Uwzm5mfn9/U0MQqLwjKQ6xuifraWILdTzXYIiIiIkkvTIL9OfAzMxta/4GZDQN+BnxW6/YuwKqWBmZmnYA7gauaG+vuD7j7GHcfk5ub29JXtl5FQcNNZgpLyc5MI6dLejsEJSIiIiJtKcwpItcQdG2ca2bPA/Ni93chKO3oBJwFYGaZwNnAy03MtwIYXOt6UOxeja4EGyvftmBFeEfgRTM7wd1nhoi77dSsYNeTX6gujiIiIiKpIu4E293fMbOJBKvKZ9Z7PBP4pbv/Oza2LLbSXdHElB8DO5vZcILE+kzg+7XeVwj0qbk2s7dj79g+k2tofAVbXRxFREREUkbYVunvAWPNrC8wPHZ7ibuvaWBsWTNzVZrZpQSr4mnAFHefbWY3AjPd/cUwsW0Xygug27b7OtcUlDJ6cFPl6yIiIiKSLEIl2DViXRpb3anR3acB0+rda7BjpLuPb+37Eq6REpG1haWM36NfOwQkIiIiIm0tzCZHzCzNzH5oZn81s+lmtk/sfs/Y/YHNzZHUGigR2VJWSVFJpU4QEREREUkRca9gm1k28C/g28BmIBvoGXu8CbgVmAL8JuIYO4bqCqjcvM0Kdn5hUCmjTY4iIiIiqSHMCvYNwBjgZGAEsPWw51jzmWeBo6MMrkMpLww+661gr4l1cczVCraIiIhISgiTYJ8GPODuLwDVDTxfAAyLIqgOqbE26TVNZrSCLSIiIpISwiTYAwiazTRmC8HZ1ampPJZg1ysRWVtY0yZdCbaIiIhIKgiTYK+nXivzenYHVrYunA6skRXsNQWldE4zeuVktENQIiIiItLWwiTYbwA/im12rCPWLOZ84NWoAutwyhspESksJbdbJp06WQNfEhEREZFkEybB/n8Ep4Z8DFwMOHCMmd0C/BcoA26JPMKOopESkTUFpfRV/bWIiIhIyog7wXb3BcARQCVwI8EpIr8Efg3kAUe4e14iguwQGikRyS8s1RnYIiIiIikkbKv0T4C9zOxbwG4ESfZ8d/80EcF1KOUFYJ2gc06d22sKStl7RM9GviQiIiIiySZMo5lDgbnunu/us4BZ9Z73AUa7+78jjrFjqGmTbt/UWldWVbOuqEwniIiIiIikkDA12G8BRzbx/IjYmNTUQJv0DUXluOuIPhEREZFUEibBbu4YjDQabkCTGmpWsGspKq0AoFt2entEJCIiIiLtIEyCDcHJIY35NrCuFbF0bA2sYBeVVALQNStUqbuIiIiIdGBNZn5mdjlwea1bfzSz3zcwtCfQDZgSYWwdS3kBdNulzq3ikmAFO6eLVrBFREREUkVzS6sFwNLY78MIujmuqTfGCTY8fgjcFWVwHUp5AaR3r3NrUyzB7tpFK9giIiIiqaLJzM/dHwUeBTCzxcA17v5iWwTW4VRsW4NdXFMiohVsERERkZQR99Kquw9PZCAdWnUFVG5utAY7RyvYIiIiIikj7CZHaUh5YfC5TYIdq8HO0gq2iIiISKoIlWCb2UFm9rKZ5ZtZpZlV1fupTFSg27WaNun1S0RKK8lK70RGZ/3vGBEREZFUEXfmF+vk+BYwDpgR++5bwMcEZ2TPAh5PQIzbv/JYgt3ACrZOEBERERFJLWGWVicBq4DRwHmxeze7+wHAMcBw4KFIo+soqssha0fI7F3ndlFJpU4QEREREUkxYRLsscBD7p7PNx0bOwG4+78IVq9/F214HUTut+GUVZB7UJ3bxSUVOkFEREREJMWESbAzgRWx38tin11rPf8M2C+KoJJFUWmlEmwRERGRFBMmwV4FDAJw980ETWi+Vev5ICA1Nzk2omhLBTlqky4iIiKSUsJkfx8DtWsg/gVcaWZLCRL1Swk2P0pMUalKRERERERSTZgV7MnAOjPrEru+DigBHgGmEJSN/CrS6Do4bXIUERERST1hOjlOB6bXul5kZqOAI4Aq4D13L4w+xI7J3SkuqVAXRxEREZEU06rsL1aL/WJEsSSVsopqKqqcruriKCIiIpJSmiwRMbM0M7vVzC5qZtzFZnazmVm04XVcxaVBm3SViIiIiIikluZqsM8BribY4NiUj4BfA2dFEVQyKCoJDlRRJ0cRERGR1NJcgn068Lq7f9LUoNjz11CCvVVRiVawRURERFJRcwn2fsDrcc71FjCmdeEkj+LYCraO6RMRERFJLc0l2L2AtXHOlR8bL8CmrSvYSrBFREREUklzCXYR0CfOuXoDxa0LJ3kUbV3BVomIiIiISCppLsGeDRwV51xHxsYLUBxbwc7RMX0iIiIiKaW5BPtZYKKZndjUIDM7gSDBfiaqwDq6olKtYIuIiIikouYS7PuBBcBUM/u9mQ2r/dDMhpnZTcBUYF5svBCcIpLRuROZ6WntHYqIiIiItKEml1fdvcTMjgNeBq4FrjGzTQS12V2BboABXwPHu3tpguPtMIpLKtUmXURERCQFNbeCjbsvAPYGLgfeA6qAHWOf78bu7+vuCxMYZ4dTVFKhNukiIiIiKSiuJdbYyvTdsZ/ImNkxwJ+ANOAhd7+13vOLgEsIkvli4EJ3nxNlDIlSXFqp+msRERGRFNTsCnaimFkacA9wLDAaOMvMRtcb9qS77+HuewO3A3e2cZgtVlRSoTOwRURERFJQuyXYwFhggbsvcvdy4Cmgzmkl7r6p1uUOgLdhfK1SVKIVbBEREZFU1J4Z4EAgr9b1cmBc/UFmdgnwCyADOLxtQmu9opIKdh7Qtb3DEBEREZE21p4r2HFx93vcfSTwa+A3DY0xswvNbKaZzczPz2/bABuhFWwRERGR1NSeCfYKYHCt60Gxe415CjipoQfu/oC7j3H3Mbm5uRGG2HLFOkVEREREJCW1Z4L9MbCzmQ03swzgTODF2gPMbOdal8cB89swvhYrq6iirLJa52CLiIiIpKB2ywDdvdLMLgVeIzimb4q7zzazG4GZ7v4icKmZTQQqgI3Aue0VbxjFW9ukawVbREREJNW06xKru08DptW7d32t3y9v86AiUFwSJNhawRYRERFJPdv9JseOqKikAkA12CIiIiIpSAl2AhRtLRHRCraIiIhIqlGCnQDFNSvY2VrBFhEREUk1SrATYNMWlYiIiIiIpCol2AlQrBIRERERkZSlBDsBajY55uiYPhEREZGUowQ7AYpKKumcZmSl669XREREJNUoA0yAmjbpZtbeoYiIiIhIG1OCnQBFpZVqMiMiIiKSopRgJ0BRSYXapIuIiIikKCXYCVBcohVsERERkVSlBDsBikor6JqlBFtEREQkFSnBToCiLZV0UxdHERERkZSkBDsBikoqyFEXRxEREZGUpAQ7AYpKK9XFUURERCRFKcGOWEVlNaXlVeriKCIiIpKilGBHrLi0EkAr2CIiIiIpSgl2xIpLKgDoqhpsERERkZSkBDtiRbEVbJ2DLSIiIpKalGBHrKhmBVs12CIiIiIpSQl2xIpLVIMtIiIiksqUYEesZgVb52CLiIiIpCYl2BHbFEuwu2VrBVtEREQkFSnBjtg3JSJawRYRERFJRUqwI1ZUUkEngy4Zae0dioiIiIi0A9UxRCxok56OmbV3KCIi0o4KCwtZt24d5eXl7R2KiMQpLS2Nrl270qtXLzIzM1s8jxLsiBWXVOgMbBGRFFdaWsqaNWsYNGgQXbp00aKLSAfg7lRUVLBp0yaWLVvGkCFDWpxkq0QkYkUllaq/FhFJcfn5+eTm5pKdna3kWqSDMDMyMjLo06cPPXv2ZMOGDS2eSwl2xIpLK+mapRVsEZFUVlpaSk5OTnuHISIt1K1bN4qKilr8fSXYESsqqSBHK9giIimtsrKSzp212CLSUaWnp1NVVdXi7yvBjlhQIqL/UhURSXUqDRHpuFr7n18l2BErKqlQF0cRERGRFKYEO2JFJRV0y1aCLSIiIpKqlGBHqKra2VJWpRIRERGRiC1ZsgQz44YbbmjxHOedd55Kd6RNKMGOUHFJBYBKREREJOmZWdw/S5Ysae9wt1vjxo3DzPjxj3/c3qFIhLTUGqGi0koArWCLiEjSe/zxx+tcv/vuuzzwwANceOGFHHLIIXWe5ebmtvp9Q4cOpaSkpFWnszz44IPcd999rY4lKrNmzeKjjz5i5MiRTJ06lT//+c/ssMMO7R2WRECZYIRqVrDVaEZERJLdOeecU+e6srKSBx54gAMPPHCbZ/UVFRXRtWvXUO8zM7KyskLHWVt6ejrp6dvP/42ePHkyXbt25a9//SsHHnggU6dO5Uc/+lF7h9WslvzzSzUqEYlQUUmwgq1W6SIiIoFhw4Yxfvx4Pv30U44++mi6d+/OnnvuCQSJ2m9+8xvGjRtHnz59yMzMZKedduKaa65hy5YtdeZpqAa79r2XX36Z/fffn6ysLPr378/VV19NZWVlnTkaqsGuuVdYWMjFF19M3759ycrK4qCDDmLGjBnb/HnWr1/P+eefT+/evcnJyeHwww/n008/Zfz48QwbNizuv5fy8nL++te/8r3vfY8DDjiAffbZh8mTJzc6/plnnmH8+PH06NGD7OxsdtllFy677DLKy8u3jnF3HnzwQcaNG0dOTg45OTnsscceXH/99VvH3HDDDY2W7dT8s6rNzDjvvPN44403OPjgg8nJyeG73/0uACtXruSqq65i7733pmfPnmRlZTF69Ghuu+22Bs+QLi8v5/bbb2fvvfcmOzub7t27M2bMGP7yl78AcNddd2FmTJ8+fZvvlpWV0bt3bw4//PAm/163F8oEI1RUs4KtGmwREZGtli1bxuGHH85pp53GqaeeSnFxMQArVqzgoYce4tRTT+X73/8+nTt35p133uH222/n008/5bXXXotr/mnTpnHvvfdy0UUXcf755/PCCy9wxx130LNnT6677rq45j9fjmAAACAASURBVDj66KPJzc3l+uuvZ/369dx5550cd9xxLF68eOtqbVlZGRMnTuSzzz7jvPPOY+zYsXzxxRdMnDiRXr16hfo7eeGFF1i3bh3nnnsuECT6l19+OV9//TW77LJLnbGTJk3i5ptvZvTo0Vx55ZX079+fhQsX8swzz3DjjTeSkZEBwA9+8AOeeOIJxo0bx6RJk+jRowdfffUVTz/9NDfeeGOo+GqbOXMmzzzzDBdccMHWeAG++OILnn32WU4++WRGjhxJRUUFr776Ktdccw2LFi3i/vvv3zq2vLyco48+mrfffpujjjqKc845h6ysLL788kueffZZLr30Un74wx9y7bXXMmXKFI488sg6MTz33HNs2LCBn/zkJy3+c7QlJdgRKi7VCraIiDTut098zuxlhe0dRh27D+nO787eK6HvWLx4MQ8++OA2ydGIESPIy8urU7ZxySWX8Nvf/pabbrqJjz76iLFjxzY7/+zZs5k9e/bWFeSLLrqIPfbYg7vvvjvuBHvffffl3nvv3Xo9evRoTj/9dJ588kl++tOfAkFJx2effcZNN93EpEmTto7dY489uOSSSxg6dGhc7wKYMmUKw4YN49BDDwXg+9//Pr/85S+ZMmUKt91229ZxH330ETfffDMTJkxg2rRpdcpkbr311q2/T506lSeeeIJzzjmHRx99lE6dvilSqK6ujjuuhsyePZvp06czceLEOvcPO+wwFi1aVOf/K3DFFVfwgx/8gIceeogbbriB/v37A/DHP/6Rt99+m2uvvZabb765zjw18fXu3ZtTTjmFZ599lg0bNtT5Hy2TJ0+mZ8+enHLKKa36s7QVlYhEaOsKthJsERGRrXr16tVgbXFGRsbW5LqyspKNGzeybt26rYlcQyUaDTnppJPqlGeYGRMmTGD16tVbV8ubc+WVV9a5rilFmD9//tZ7L730EmlpaVx++eV1xv7kJz+he/fucb0HIC8vj3/961/88Ic/3Jqc9unTh+OOO47HHnusTmnLE088AcAtt9yyTQ16zSkttcfdcccddZJrYJvrsPbaa69tkmuALl26bH1/eXk5GzZsYN26dRx99NFUV1czc+bMOn+Onj171ilXaSi+Cy+8kLKysq1/HghKgd544w3OPvvsVtfht5V2zQTN7BjgT0Aa8JC731rv+S+AnwCVQD5wvrsvbfNA41S0JfgPRDdtchQRkQYkeqV4ezVy5EjS0tIafHbvvfdy3333MXv27G1WWjdu3BjX/CNGjNjmXu/evYGgZjonJyf0HLW/X2Px4sUMGDBgm/kyMjIYPnx43PE+8sgjVFdXc9BBB7FgwYKt9w8//HCef/55pk2bxgknnAAECb6ZsddeTf+7M3/+fPr370+/fv3iiiGMUaNGNXi/srKSW2+9lccee4wFCxbg7nWe1/77mD9/PnvvvXezCfL48eMZNWoUkydP5uc//zkADz/8MO7eYcpDoB0TbDNLA+4BjgSWAx+b2YvuPqfWsE+BMe6+xcwuBm4Hzmj7aONTVFqBGWRnagVbRESkRnZ2doP377zzTq666iqOOuooLrvsMgYMGEBGRgYrVqzgvPPOi7u0obHkHdgm6Qs7R7zfj5e78/DDDwNB3XdDpkyZsjXBhror1a3V1Dz1N4XWaOyf3y9+8QvuvvtuzjjjDCZNmkTfvn1JT0/nv//9L7/+9a9bXJpywQUXcPXVV/PJJ5+wzz778MgjjzBmzJhm/0fG9qQ9M8GxwAJ3XwRgZk8BJwJbE2x3f6vW+A+Bps/9aWdFJZXkZHWmUyd1iRIREWnO448/zrBhw3jllVfqlAm8+uqr7RhV44YNG8brr79OcXFxnVXsiooKFi9eTI8ePZqd46233mLx4sVcccUVHHTQQds8/9vf/saLL77ImjVr6NevH6NGjeKVV17h888/b7IefdSoUbzwwgtbv9eYmrrmDRs21CmrKS0tZdWqVey0007N/hlqPP744xx66KE89dRTde7XXpWvHd9XX31FWVkZmZmZTc573nnnMWnSJCZPnsyJJ57IsmXLuPbaa+OOa3vQnjXYA4G8WtfLY/ca82PglYRG1ErFJRU6A1tERCROaWlpmFmdVeKasoPt0Xe/+12qqqr405/+VOf+gw8+SGFhfJtXJ0+eTFpaGtdddx3f+973tvm57LLLqKys5LHHHgOCzY8A1113XZ0j+WrU/N2dffbZAPzqV7/aZuW49t9vTbnH66+/XmfMXXfdFXrFOS0tbZsV/s2bN3PXXXdtM/bss89m48aN3HTTTY3+GWr06dOHk046iSeffJK//OUvZGdnb/176Cg6RC2DmZ0DjAEOa+T5hcCFAEOGDGnDyOqqWcEWEfn/7d15fFTl2f/xz0VCFiTsiBRBI4uCqKyiFMEfxbjUUqvwQgUBBWIRFWsLyPJTFB4VfootBQQ1IGslUhHkUUFF9PGhroCWJQIKWhVZgyElLAn37485SSeZCQaYOYHM9/16zSsz99wz133lzDm5cuaee0Tk5/Xo0YORI0dy/fXXc/PNN5OTk8OCBQtOqy+DCTZw4EBmzJjBmDFj2Lp1a9EyfZmZmTRp0qTUKRaF9u/fzyuvvMJVV11V6rdbXnXVVZx99tnMnDmTYcOGcfnllzNixAgmTJhAmzZt6NWrF+eccw7btm1j0aJFfPzxx9SoUYOePXvSq1cv5syZw5YtW+jevTs1a9Zk8+bNLF++nPXr1wPQrVs3LrzwwqLlCFNTU/nggw/48MMPqVOnzgn9Pnr06MGMGTPo1asX3bp1Y+fOncycObNo/nqwoUOH8tprrzF+/Hg++eQT0tLSSEpKYsOGDXz55ZchBX96ejqZmZksW7aMfv36Ua1atRMaW3krz2rwe6Bh0O1zvbZizKwbMBro4pw7HO6JnHPPAc8BtGvXLrKTpU7AgUM6gy0iIlJWw4YNwzlHRkYGQ4cO5ZxzzqFXr17ceeedtGjRoryHFyIxMZF33nmHYcOGsWTJEjIzM+nQoQPvvPMOAwcODPlynJLmz5/PoUOHjrvUXKVKlbjpppt47rnnWL16NR07duTJJ5/ksssuY8qUKUycOJFjx47RsGFDbrjhhmLzoxcsWMBVV11FRkYGjz32GHFxcaSmptKzZ8+iPnFxcSxdupT777+fv/71ryQkJJCWlsZ7770XdsrK8UyaNImUlBQyMzNZsmQJDRs2JD09nfbt24esOpKQkMCKFSt4+umnWbBgAaNGjSIpKYmmTZuGXWGma9euNGnShK1btzJgwIATGtfpwCI9eb/Mgc3igc3ArwgU1p8AtzvnNgT1aQ0sAq5zzm0J+0QltGvXzgUvC+OnG8etompyPC/9qVO5xBcRkdPDpk2baN68eXkPQ3xSUFBAnTp16NChw2k7f/xMdPHFF1NQUEBWVla5xC/Lfmxmnznn2pVsL7c52M65fOBeYDmwCch0zm0ws8fMrPCjs/8PqAq8bGbrzGxpOQ23TA7kHdW3OIqIiFRgeXl5IW3Tp09n//79Id8+KCdv5cqVbNy4kUGDBpX3UE5KuU4Yds69Drxeou3hoOuhq5qfxnIP5etLZkRERCqwQYMGcejQITp27EhiYiL/+Mc/WLBgAU2aNCE9Pb28h3fGW7lyJV999RVPPPEEdevWVYEtkHPwKFU1B1tERKTCSktLY+rUqYwbN47c3Fzq1avHwIEDGTduHCkpKeU9vDPeY489xgcffECLFi2YPXv2GffhxkIqsCPk2DFH7qF8qukMtoiISIXVt29f+vbtW97DqLBWrVpV3kOIiPJcB7tC+ffhwNI8OoMtIiIiEttUYEfIgbyjAJqDLSIiIhLjVGBHyIG8wBlsrYMtIiIiEttUYEdIrldg65scRURERGKbCuwIOXCocIqIzmCLiIiIxDIV2BGSWzRFRGewRURERGKZCuwIKfyQo1YREREREYltKrAjJKdwFRHNwRYRERGJaSqwI6ToQ446gy0iInJKtm/fjpkxduzYYu1mRv/+/cv0HGPHjsXM2L59e8TH9+KLL2JmFeZLUSTyVGBHyIG8o5yVFE9cJSvvoYiIiERdz549MTPWrVtXah/nHKmpqdSoUYO8vDwfR3fqVq1axdixY9m/f395D+VnFRQU0KBBA8yMcePGlfdwBBXYEXMgL1/TQ0REJGYMGDAAgFmzZpXa591332X79u3ceuutJCcnn3LMvLw8nn/++VN+nrJYtWoVjz76aNgC+4477iAvL4/OnTv7Mpaf88Ybb/DDDz/QuHFjXnzxRZxz5T2kmKcCO0JyDx3V9BAREYkZaWlpNGzYkPnz53PkyJGwfQqL78Ji/FQlJSVRuXL5/62Ni4sjKSmJSpVOjzIqIyODxo0bM2nSJL7++uszZurKgQMHynsIUXN6vDIqgAN5+VqiT0REYkalSpXo378/e/fuZenSpSH35+Tk8Pe//52WLVvSvn17Dhw4wJgxY+jQoQN16tQhMTGRJk2a8NBDD3Hw4MEyxQw3B/vYsWM88cQTpKamkpSURMuWLZk/f37Yx2dlZXHPPfdw8cUXk5KSQpUqVWjbti0vvPBCsX79+/fn0UcfBSA1NRUzKzYnvLQ52Hv27GHIkCE0bNiQhIQEGjZsyJAhQ9i7d2+xfoWPX7lyJU899RSNGzcmMTGRZs2aMXv27DL9Lgrt3LmTZcuW0bdvX2644QbOPvtsMjIywvZ1zvH888/ToUMHqlatStWqVbnkkkt4+OGHi/U7cuQIEydOpFWrVlSpUoXq1avTrl07pkyZUux3ZBZ+WmzJ7RQ8p37hwoW0bduW5ORk7rvvPqDs26VQTk4Oo0ePpnnz5iQlJVG7dm06derESy+9BMDQoUMxM7Zs2RLy2B07dhAfH89dd91V+i81AlQRRkhu3lF9yYyIiMSUO++8k/HjxzNr1ix69OhR7L6XXnqJvLy8orPX33//PS+88AK33HILt99+O/Hx8bz33ntMnDiRtWvXsnz58pMaw4MPPshf/vIXOnfuzB/+8Ad27drFkCFDuOCCC0L6rlq1ivfff58bb7yR1NRU/v3vf/Pyyy8zaNAgdu/ezciRIwG4++67ycnJYfHixTzzzDPUqVMHgEsvvbTUcfz000907NiRrVu3ctddd9GmTRvWrl3Ls88+y8qVK/n4449JSUkp9phRo0aRl5fH3XffTWJiIs8++yz9+/enSZMm/PKXvyxT/nPmzKGgoIC+ffsSHx9P7969mT59Oj/99BPVq1cv1veOO+5g/vz5dOjQgdGjR1OjRg2ysrJYtGgRjz32GBAorq+99lpWrVpFWloaffr0ISkpiX/+85+88sor3HvvvWUaVzivvvoqkydPZvDgwfz+97+nWrVqQNm3C8D+/fvp1KkTGzZsoEePHgwePJiCggLWrl3LsmXLuPXWWxk0aBCTJ09m5syZPPHEE8XGMHv2bAoKChg4cOBJ51EmzrkKdWnbtq0rD1ePfsvdNfkf5RJbREROLxs3bgx/x6dDnXury+l1+XToKeXatWtXFxcX53744Ydi7VdccYVLSEhwu3fvds45d/jwYXfkyJGQx48ZM8YB7qOPPipq27ZtmwPcI488Uqwv4Pr161d0Oysry5mZ69q1q8vPzy9q/+yzz5yZOcBt27atqD03NzckfkFBgevSpYurVq1asfE98sgjIY8vNGvWLAe4d999t6ht1KhRDnBTp04t1nfKlCkOcGPGjAl5fKtWrdzhw4eL2r/77juXkJDgbr311pCYpbnoootcly5dim6vW7fOAW7atGnF+i1cuNABrk+fPq6goCDkd1BowoQJDnAjR44MiRXcr1+/fi5QRoYquZ0Kt2d8fHzYfeNEtsvgwYMd4GbMmHHc8V155ZWufv36xV4XzjnXtGlT17x587DjLqnU/TgI8KkLU49qikiEHMg7qikiIiIScwYMGEBBQQFz5swpasvKyuLDDz+ke/fuRWd/ExISiuZP5+fnk52dzZ49e+jWrRsAH3300QnHXrJkCc45HnzwQeLi4ora27RpwzXXXBPS/6yzziq6fujQIfbu3cu+fftIS0sjJyeHrKysEx5DocWLF1O3bl3S09OLtd99993UrVuXxYsXhzzmnnvuISEhoeh2gwYNaNasWdipDeGsXr2arKws+vXrV9R22WWX0apVK2bOnFmsb+G0maeeeipk7njw7fnz51OzZs2QaSMl+52MX//61zRv3jykvazb5dixY7z00ks0b9485Pdccnzp6ens2LGD119/vajt/fffZ8uWLRH7TMDxqCKMkNy8fH3IUUREjq/tn8t7BBF38803U6NGDWbNmsWIESMAioq7kvNcp02bxvTp09mwYQPHjh0rdl92dvYJx/76668BuOiii0Lua9GiBStWrCjWlpuby9ixY8nMzORf//pXyGNOZgyFtm3bRrt27YiPL15axcfH06xZM9asWRPymHDTWGrXrs0333xTppgZGRlUrlyZ1q1bs3Xr1qL2a6+9lgkTJvDFF18UTWvZsmUL9evXp169esd9zi1bttCqVSuSkpLKNIYT0axZs7DtZd0ue/bsITs7m+uuu+5nY/Xq1YsHHniAjIwMfvOb3wCB31dCQgJ9+/Y9hSzKRgV2BDjnAmewtUyfiIjEmKSkJG6//XamTZvG6tWr6dChA3PnzuXcc8/l2muvLeo3adIk/vjHP5KWlsb999/PL37xCxISEvj+++/p379/SMEdDbfffjvLli0jPT2dzp07U7t2beLi4nj99dd55plnfBlDsOCz7sFcGZbZy83NJTMzk6NHj9K6deuwfWbOnMmf/xydf+pK+4Bjfn5+qY+pUqVK2PZobJfk5GT69OnDjBkz2LlzJ8nJySxatIju3btTt27dE36+E6WKMAIOHi7gmEMfchQRkZg0YMAApk2bxqxZs9i3bx8//vgjo0ePLvaW/dy5czn//PN54403irW/+eabJx238AxwVlYWjRs3Lnbfxo0bi93ev38/y5Yt44477mD69OnF7nv77bdDnru0AvJ4Y/nyyy/Jz88vdhY7Pz+fzZs3hz1bfSoyMzPJzc3l8ccfp2nTpiH3T548mXnz5jFx4kQSEhJo1qwZS5YsYefOncc9i92sWTOysrI4fPgwiYmJpfarVasWAPv27Su6Dv95V6GsTmS71KlTh5o1a/L555+X6bnT09OZOnUqs2fPpnr16hw8eNCX6SGgZfoi4kDeUQBSqqjAFhGR2NOmTRtatWrFwoULmTp1KmYWMj0kLi4OMyt2djY/P58nn3zypON2794dM2PSpEkUFBQUta9ZsyakOCs8W1zy7PCOHTvCLgdXtWpVIFBAlsVNN93E7t27Q57r+eefZ/fu3fzud78r0/OUVUZGBrVq1WLYsGH06NEj5DJgwAD27t3LkiVLAOjduzcAw4cPDzkjHPw76d27N9nZ2YwfPz4kZnC/wukeJX/PTz/99AnlcSLbpVKlStx2221s3Lgx7FKEJZ/j0ksv5fLLL2fmzJlkZGTQqFEj0tLSTmh8J0tnsCPgQF7g7RBNERERkVg1YMAA7rvvPt58802uvvrqkDO2PXr0YOTIkVx//fXcfPPN5OTksGDBglP64piLLrqIIUOGMGXKFLp27cott9zCrl27mDJlCpdddhlr164t6puSkkJaWhrz5s0jOTmZ9u3b88033zBjxgxSU1ND1qq+4oorABgxYgS9e/cuWmO7ZcuWYccyfPhwXn75ZYYMGcKaNWto3bo1a9euJSMjgwsvvJDhw4efdJ4lZWVlsXr1avr37x8y57tQ9+7dqVy5MhkZGfTs2ZOePXvSq1cv5syZw5YtW+jevTs1a9Zk8+bNLF++nPXr1wOBNaRfe+01xo8fzyeffEJaWhpJSUls2LCBL7/8sqigvu222xg1ahTp6elkZWVRq1Yt3nzzTfbs2XNCuZzodhk/fjwrV65k4MCBrFixgk6dOuGcY+3ateTn5zN37txi/dPT04uW5HvkkUf8+3KgcEuLnMmX8limb81Xe905/f7u3l63w/fYIiJy+inL8l4Vzb59+1xSUpID3Jw5c0Luz8/Pd48//rhr3LixS0hIcI0aNXLDhg1zGzduDFmSr6zL9DkXWJpt/PjxrlGjRi4hIcFdfPHFbt68eWGX2du9e7cbMGCAq1+/vktMTHQtW7Z0zz33XNhl95wLLFmXmprq4uPji42ntP67du1ygwcPdg0aNHDx8fGuQYMG7p577ilaqrBQaY93zrkuXbq48847L8xv+D/+9Kc/OcAtXbr0uP3S0tJcpUqV3Lffflv0u5oyZYpr3bq1S05OdlWrVnWXXHKJGzt2bLHH5eXlufHjx7sWLVq4xMREV716ddeuXbuQJQg//PBD17FjR5eYmOhq167tBg0a5LKzs0tdpq/k9ix0otslOzvbDRs2zDVu3NhVrlzZ1apVy3Xq1MktXLgw5Llzc3NdtWrVXKVKldz27duP+/sq6VSW6TNXhon0Z5J27dq5Tz/91NeYX2zPZuScdTzetxWXnV/T19giInL62bRpU9jlyETEX4cPH6Z+/fq0b9/+hL/MqCz7sZl95pxrV7Jdcxoi4NLza/LfD/+f8h6GiIiIiASZP38+2dnZYdfNjiYV2CIiIiJSobz22mt88803jB07lhYtWnDTTTf5Gl8FtoiIiIhUKPfddx8//PADbdu25YUXXih1zfFoUYEtIiIiIhXK9u3byzW+1sEWEREREYkgFdgiIiIiIhGkAltERCQKKtoyuCKx5FT3XxXYIiIiERYfH09+fn55D0NETtLRo0dP6YORKrBFREQiLCkpidzc3PIehoicpJycHFJSUk768SqwRUREIqxu3brs3r2bgwcPaqqIyBnCOceRI0fYs2cP2dnZ1KpV66SfS8v0iYiIRFhSUhL16tXjxx9/5PDhw+U9HBEpo7i4OFJSUmjUqBGJiYkn/TwqsEVERKKgevXqVK9evbyHISLlQFNEREREREQiSAW2iIiIiEgEqcAWEREREYkgFdgiIiIiIhGkAltEREREJIJUYIuIiIiIRJAKbBERERGRCLKK9g1TZrYb+KacwtcB9sRQ3FiNHYs5x2rsWMw5VmPHYs6xGjsWc47l2NF2nnOubsnGCldglycz+9Q51y5W4sZq7FjMOVZjx2LOsRo7FnOO1dixmHMsxy4vmiIiIiIiIhJBKrBFRERERCJIBXZkPRdjcWM1dizmHKuxYzHnWI0diznHauxYzDmWY5cLzcEWEREREYkgncEWEREREYkgFdgRYGbXmdmXZrbVzB7yOfZ2M/unma0zs0+jHGumme0ys/VBbbXM7C0z2+L9rOlT3LFm9r2X9zozuyHScb04Dc3sXTPbaGYbzGyo1+5H3qXFjmruZpZkZh+b2ede3Ee99lQz+8h7nS80s4RIxv2Z2C+a2bagnFtFOnbQGOLMbK2ZLfNuRz3vUuL6knO4Y4gfr+/jxPZr365hZovMLMvMNpnZlT7mHS52tPfrC4Oee52Z5ZjZAz4dy0qL7de2/oN3PFlvZn/zjjN+HM/CxfVrvx7qxd1gZg94bX69vsPF9mVbn1acc7qcwgWIA74CLgASgM+BFj7G3w7U8SlWZ6ANsD6obSLwkHf9IWCCT3HHAn/yIef6QBvvegqwGWjhU96lxY5q7oABVb3rlYGPgCuATOBWr306MNjH2C8CPaK9vb24DwILgGXe7ajnXUpcX3IOdwzx4/V9nNh+7duzgYHe9QSgho95h4vtS95ezDjgR+A8v3IuJXbUcwYaANuAZO92JtA/2vv1ceJGfb8GWgLrgSpAPPA20MSPbX2c2L69vk+Xi85gn7rLga3Oua+dc0eAl4DflvOYosI59z6wr0Tzbwn8scD7eZNPcX3hnNvhnFvjXT8AbCJw4PQj79JiR5ULyPVuVvYuDugKLPLao5VzabF9YWbnAr8GXvBuGz7kXTLuaSDqr+/yZGbVCfzjngHgnDvinNuPD3kfJ7affgV85Zz7Bv+3dXBsv8QDyWYWT6Dw24EP+3WYuD9EIUY4zYGPnHMHnXP5wHvAzfizrUuLHXNUYJ+6BsC/gm5/hw9FUBAHrDCzz8ws3ce4heo553Z4138E6vkY+14z+8ICU0ii8lZXMDM7H2hN4Kyqr3mXiA1Rzt2brrAO2AW8ReBdmv3eAROi+DovGds5V5jzf3k5P2NmidGIDfwZGA4c827Xxp+8S8Yt5EfO4Y4hfr2+Szt+RXvfTgV2A7MsMC3nBTM7C3/yLi02+HdMuxX4m3fd72N4cGyIcs7Oue+Bp4BvCRTWPwGfEeX9Olxc59wK7+5o79frgavMrLaZVQFuABriz7YuLTb4/De7vKnAPvN1cs61Aa4HhphZ5/IaiAu8P+TX2cZngcZAKwIHr6ejGczMqgJ/Bx5wzuUE3xftvMPEjnruzrkC51wr4FwC79JcFOkYZY1tZi2Bkd4Y2gO1gBGRjmtmNwK7nHOfRfq5TzJu1HP2HPcYEuXXd7jYfuzb8QSmnT3rnGsN/JvAW+ZFoph3abF9OaZ5c427Ay+XvM+HY1nJ2FHP2SvkfkvgH5tfAGcB10U6TlnimlkffNivnXObgAnACuBNYB1QUKJPVLb1cWL7+jf7dKAC+9R9z3/+O4NAUfC9X8G9/5Jxzu0CFhMohvy008zqA3g/d/kR1Dm30yvEjgHPE8W8zawygQJ3vnPuFa/Zl7zDxfYzd++t63eBK4Ea3lud4MPrPCj2dd50GeecOwzMIjo5/xLobmbbCUz16gr8hejnHRLXzOb5lHNpxxBfXt/hYvv0+v4O+C7o3ZFFBIpeP/IOG9vH/fp6YI1zbqd3289jeLHYPuXcDdjmnNvtnDsKvEJgn4v2fh0ubkcf9+sM51xb51xnIJvAZ3j82q9DYvv5d+t0oQL71H0CNPU+kZxA4O2vpX4ENrOzzCyl8DqQRuDtGT8tBfp51/sBS/wI/1t6SgAABRpJREFUWniQ8PyOKOXtzcHNADY55yYF3RX1vEuLHe3czayumdXwricD1xCY//0u0MPrFq2cw8XOCvqjYATmDUZ8ezvnRjrnznXOnU9gP17pnOtNlPMuJW4fP3I+zjHEj9d32Nh+7NvOuR+Bf5nZhV7Tr4CN+JB3abH9OqYBt1F8ioafx/BisX3K+VvgCjOr4u1Lhds62sezcHE3+bFfe89/tvezEYE50AvwaVuHi+3j6/v04U6DT1qe6RcCc4w2E5inOtrHuBcQWLXkc2BDtGMTODDuAI4SOAszgMAc1XeALQQ+LVzLp7hzgX8CXxA4aNSPUs6dCLyN9gWBt7rWedvbj7xLix3V3IFLgbXe868HHg56vX0MbCXwFm9iFHIuLfZKL+f1wDy8lUai+Fq/mv+s5hH1vEuJG/WcSzuG+PT6Li22X/t2K+BTL86rQE0/8j5O7KjnTWB6xF6gelCbXzmHi+3Xtn4UyPL2pblAok/Hs3BxfTmWAf9D4B+Jz4Ff+bytw8X2ZVufThd9k6OIiIiISARpioiIiIiISASpwBYRERERiSAV2CIiIiIiEaQCW0REREQkglRgi4iIiIhEkApsERGJCDNb5X1hjohITFOBLSJyGjOzq83MHeeSX95jFBGR4uJ/vouIiJwG/ga8Hqb9mN8DERGR41OBLSJyZljjnJtX3oMQEZGfpykiIiIVgJmd700ZGWtmt5nZF2Z2yMy+9dpCTqiY2aVmttjM9np9N5rZcDOLC9P3HDObbGZfm9lhM9tlZm+Z2TVh+v7CzP5mZtlmdtDMlptZs2jlLiJyutEZbBGRM0MVM6sTpv2Icy4n6HZ34AJgKvCjd/sR4DzgzsJOZtYOeA84GtT3N8AE4DKgd1Df84H/BeoBc4BPgbOAK4BuwFtB8c8C3gc+BEYBqcBQYImZtXTOFZxM8iIiZxJzzpX3GEREpBRmdjXw7nG6/Ldz7kavCN5GYE52e+fcGu/xBrwC3ARc6Zz70Gv/X6AD0MY590VQ34VAT6Cbc+4dr/114HrgOufc8hLjq+ScO+ZdXwV0AUY45yYG9RkGTAz3eBGRikhTREREzgzPAdeEuYwu0e+twuIawAXOohQWu78DMLOzgY7A0sLiOqjvf5XoWwu4DngzXHFcWFwHOQZMLtG20vvZ9GezFBGpADRFRETkzLDFOfd2GfptCtO20ft5gfcz1fu5oZTHHwvq2wQwYG0Zx/mDc+5Qiba93s/aZXwOEZEzms5gi4hIJB1vjrX5NgoRkXKkAltEpGJpHqathffza+/nNu/nxWH6XkTgb0Nh362AA1pFaoAiIhWdCmwRkYrlGjNrU3jD++DicO/mqwDOuV3AauA3ZtayRN+R3s3FXt99wBvA9WbWrWQw7zEiIhJEc7BFRM4MbcysTyn3vRp0/XNgpZlNBXYAvyWwlN5c59w/gvoNJbBM3/94fX8EbgSuBRYUriDiuZdAQf6Gmc0GPgOSCaxCsh0YcYq5iYhUKCqwRUTODLd5l3CaAvne9aXAlwTORF8I7ALGeZcizrlPzawj8ChwD4H1q78mUCw/XaLvNm/d7P8L3AD0BbIJFPPPnWpiIiIVjdbBFhGpAILWwX7UOTe2XAcjIhLjNAdbRERERCSCVGCLiIiIiESQCmwRERERkQjSHGwRERERkQjSGWwRERERkQhSgS0iIiIiEkEqsEVEREREIkgFtoiIiIhIBKnAFhERERGJIBXYIiIiIiIR9P8BlYniQPZviAQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uy15XOm2TnA"
      },
      "source": [
        "accuracy=pd.DataFrame(accuracy, columns=['accuracy'])\n",
        "proj_implemented=pd.DataFrame(proj_implemented, columns=['projection'])\n",
        "results=pd.concat([accuracy,proj_implemented],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "kGgwlc6o2T8b",
        "outputId": "e04df104-dabb-43ab-fabb-447aa8ebdf0c"
      },
      "source": [
        "results.groupby('projection').mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>projection</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>linear</th>\n",
              "      <td>0.803544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>none</th>\n",
              "      <td>0.836717</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            accuracy\n",
              "projection          \n",
              "linear      0.803544\n",
              "none        0.836717"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnQkWOYxFIc8"
      },
      "source": [
        "import keras\n",
        "\n",
        "y_prob = model.predict(X_test)\n",
        "y_classes = y_prob.argmax(axis=-1)\n",
        "\n",
        "res_list = y_classes.tolist()\n",
        "label_mapping = {0:'Aayush',1:'Kanishk',2:'Kayan',3:'Rohit'}#clarify\n",
        "\n",
        "\n",
        "# for i in range(len(res_list)):\n",
        "#   print(\"prediction \",i,\" \",label_mapping[res_list[i]])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ep-JoBYAXfI0",
        "outputId": "a99c36dc-b44c-4ac8-b4ce-ef9a13cd3057"
      },
      "source": [
        "model.evaluate(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "57/57 [==============================] - 0s 4ms/step - loss: 0.6682 - accuracy: 0.8433\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6681956052780151, 0.8433333039283752]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    }
  ]
}