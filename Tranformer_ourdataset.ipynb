{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tranformer_ourdataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNRdWviMgbeab7JSBeadMhA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VRB01/capstone/blob/main/Tranformer_ourdataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "la_pE8SZtRHO",
        "outputId": "66bfe9cc-084b-405c-c04a-3f8f3ea0fdd2"
      },
      "source": [
        "import IPython.display as ipd\n",
        "# % pylab inline\n",
        "import os\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import glob \n",
        "import librosa.display\n",
        "import random\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn import metrics \n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout \n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from keras import regularizers\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "import os\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.datasets import imdb\n",
        "from keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import os\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from sklearn.metrics import label_ranking_average_precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import zipfile\n",
        "\n",
        "tqdm.pandas()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tUYi9u-tXnw",
        "outputId": "aece32e4-5cc3-4689-995e-a8d5d934aeea"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFFrVhQLtdQk"
      },
      "source": [
        "Directory = 'gdrive/MyDrive/Voice Inputs'\n",
        "Dataset = os.listdir(Directory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mjz8VWmRtdbI"
      },
      "source": [
        "audio_list = []\n",
        "speakers = []\n",
        "for speaker in Dataset:\n",
        "  audios = os.listdir(Directory+'/'+speaker)\n",
        "  for audio in audios:\n",
        "    if(audio.endswith('.wav')):\n",
        "      audio_list.append(Directory+'/'+speaker+'/'+audio)\n",
        "      speakers.append(audio.split('_')[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TK_u_tXNtdj3",
        "outputId": "5b32acf3-94ee-43dc-a4cf-6758101ab926"
      },
      "source": [
        "audio_list = pd.DataFrame(audio_list)\n",
        "audio_list = audio_list.rename(columns={0:'file'})\n",
        "#len(audio_list)\n",
        "len(speakers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "242"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "OO896Lzttdrs",
        "outputId": "d899aa0f-2e8d-4233-a2ad-cc6526d4ccab"
      },
      "source": [
        "audio_list['speaker'] = speakers\n",
        "df = audio_list.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "df = df[:12000]\n",
        "df_train = df[:8000] #19984:\n",
        "df_validation = df[8000:11000] #19984:25694\n",
        "df_test = df[11000:12000] #25694:\n",
        "labels = df['speaker']\n",
        "Counter = 1\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>speaker</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gdrive/MyDrive/Voice Inputs/Kanishk/Kanishk_13...</td>\n",
              "      <td>Kanishk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gdrive/MyDrive/Voice Inputs/Kanishk/Kanishk_39...</td>\n",
              "      <td>Kanishk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gdrive/MyDrive/Voice Inputs/Kayan/Kayan_3822.wav</td>\n",
              "      <td>Kayan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gdrive/MyDrive/Voice Inputs/Rohit/Rohit_6461.wav</td>\n",
              "      <td>Rohit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gdrive/MyDrive/Voice Inputs/Rohit/Rohit_3700.wav</td>\n",
              "      <td>Rohit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237</th>\n",
              "      <td>gdrive/MyDrive/Voice Inputs/Aayush/Aayush_3959...</td>\n",
              "      <td>Aayush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>238</th>\n",
              "      <td>gdrive/MyDrive/Voice Inputs/Kanishk/Kanishk_87...</td>\n",
              "      <td>Kanishk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>gdrive/MyDrive/Voice Inputs/Aayush/Aayush_203.wav</td>\n",
              "      <td>Aayush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>gdrive/MyDrive/Voice Inputs/Kayan/Kayan_5745.wav</td>\n",
              "      <td>Kayan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>gdrive/MyDrive/Voice Inputs/Aayush/Aayush_4931...</td>\n",
              "      <td>Aayush</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>242 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  file  speaker\n",
              "0    gdrive/MyDrive/Voice Inputs/Kanishk/Kanishk_13...  Kanishk\n",
              "1    gdrive/MyDrive/Voice Inputs/Kanishk/Kanishk_39...  Kanishk\n",
              "2     gdrive/MyDrive/Voice Inputs/Kayan/Kayan_3822.wav    Kayan\n",
              "3     gdrive/MyDrive/Voice Inputs/Rohit/Rohit_6461.wav    Rohit\n",
              "4     gdrive/MyDrive/Voice Inputs/Rohit/Rohit_3700.wav    Rohit\n",
              "..                                                 ...      ...\n",
              "237  gdrive/MyDrive/Voice Inputs/Aayush/Aayush_3959...   Aayush\n",
              "238  gdrive/MyDrive/Voice Inputs/Kanishk/Kanishk_87...  Kanishk\n",
              "239  gdrive/MyDrive/Voice Inputs/Aayush/Aayush_203.wav   Aayush\n",
              "240   gdrive/MyDrive/Voice Inputs/Kayan/Kayan_5745.wav    Kayan\n",
              "241  gdrive/MyDrive/Voice Inputs/Aayush/Aayush_4931...   Aayush\n",
              "\n",
              "[242 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-7hFvf9vHX9"
      },
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask): #Query and Key are . to produce dynamically attended weights\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "  #Scaled is just a normalisation of the DPA to get the values [0,1]\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth) #To avoid a large magnitude of numbers with large dimensions\n",
        "\n",
        "  # add the mask zero out padding tokens.\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  return tf.matmul(attention_weights, value)# mul with value to get context vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6aq_FFsvHt7"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "#Like you have several kernels in CNN, we can have several self attended layers in a transformer model\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # linear layers\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "  #Concat each of the encodings and reduce their dimension to keep a track of less/more important features\n",
        "  #Like a projection layer\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kmbAMQsvHzX"
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "#How do we keep a track of the sequence -> dogs chase cat, cat chase dog\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "    #Positional encodings typically encode the position of the tokens and they can be summed with the same dimensional token\n",
        "    #Effectively injecting the posiitonal encodings\n",
        "    # apply sin to even index in the array\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # apply cos to odd index in the array\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OdY44ExvH31"
      },
      "source": [
        "# This allows to the transformer to know where there is real data and where it is padded\n",
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "  \n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tcr0t0ivH9C"
      },
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout,name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,d_model ), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmymY4MmvboM"
      },
      "source": [
        "def encoder(time_steps,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            projection,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "  \n",
        "  if projection=='linear':\n",
        "    ## We implement a linear projection based on Very Deep Self-Attention Networks for End-to-End Speech Recognition. Retrieved from https://arxiv.org/abs/1904.13377\n",
        "    projection=tf.keras.layers.Dense( d_model,use_bias=True, activation='linear')(inputs)\n",
        "    print('linear')\n",
        "  \n",
        "  else:\n",
        "    projection=tf.identity(inputs)\n",
        "    print('none')\n",
        "   \n",
        "  projection *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  projection = PositionalEncoding(time_steps, d_model)(projection)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(projection)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        " \n",
        " \n",
        "  \n",
        "\n",
        " \n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xER6o2uIvbq6"
      },
      "source": [
        "def transformer(time_steps,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                output_size,\n",
        "                projection,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,d_model), name=\"inputs\")\n",
        "  \n",
        "  \n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(tf.dtypes.cast(\n",
        "          \n",
        "    #Like our input has a dimension of length X d_model but the masking is applied to a vector\n",
        "    # We get the sum for each row and result is a vector. So, if result is 0 it is because in that position was masked      \n",
        "    tf.math.reduce_sum(\n",
        "    inputs,\n",
        "    axis=2,\n",
        "    keepdims=False,\n",
        "    name=None\n",
        "), tf.int32))\n",
        "  \n",
        "\n",
        "  enc_outputs = encoder(\n",
        "      time_steps=time_steps,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "      projection=projection,\n",
        "      name='encoder'\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  #We reshape for feeding our FC in the next step\n",
        "  outputs=tf.reshape(enc_outputs,(-1,time_steps*d_model))\n",
        "  \n",
        "  #We predict our class\n",
        "  outputs = tf.keras.layers.Dense(units=output_size,use_bias=True,activation='softmax', name=\"outputs\")(outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs], outputs=outputs, name='audio_class')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgTvkyLuvbtl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsO8XZFKtdzB"
      },
      "source": [
        "def extract_features(files):\n",
        "    \n",
        "    # Sets the name to be the path to where the file is in my computer\n",
        "    file_name = os.path.join(str(files.file))\n",
        "    global Counter\n",
        "    if(Counter%10==0):\n",
        "      print(Counter)\n",
        "    Counter+=1\n",
        "\n",
        "    # Loads the audio file as a floating point time series and assigns the default sample rate\n",
        "    # Sample rate is set to 22050 by default\n",
        "    X, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
        "\n",
        "    # Generate Mel-frequency cepstral coefficients (MFCCs) from a time series \n",
        "    #mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
        "\n",
        "    # Generates a Short-time Fourier transform (STFT) to use in the chroma_stft\n",
        "    #stft = np.abs(librosa.stft(X))\n",
        "\n",
        "    # Computes a chromagram from a waveform or power spectrogram.\n",
        "    #chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "\n",
        "    # Computes a mel-scaled spectrogram.\n",
        "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
        "\n",
        "    # Computes spectral contrast\n",
        "    #contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
        "\n",
        "    # Computes the tonal centroid features (tonnetz)\n",
        "    #tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n",
        "    #sr=sample_rate).T,axis=0)\n",
        "        \n",
        "    \n",
        "    # We add also the classes of each file as a label at the end\n",
        "    #label = files.label\n",
        "\n",
        "    return mel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXrv2HkXtd5n",
        "outputId": "13866c15-53a4-4242-a03c-9acc64852dd3"
      },
      "source": [
        "startTime = datetime.now()\n",
        "# Applying the function to the train data by accessing each row of the dataframe\n",
        "features_label = df.apply(extract_features, axis=1)\n",
        "print(datetime.now() - startTime)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "20\n",
            "30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "40\n",
            "50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "70\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "80\n",
            "90\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100\n",
            "110\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "120\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "130\n",
            "140\n",
            "150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "160\n",
            "170\n",
            "180\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "190\n",
            "200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "210\n",
            "220\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "230\n",
            "240\n",
            "0:01:13.794563\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Quhf-QKGtyoW"
      },
      "source": [
        "# Saving the numpy array because it takes a long time to extract the features\n",
        "np.save('features_label', features_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt9_9gomtyrG",
        "outputId": "9abcc3af-a88f-428b-d37b-ff079a3b5667"
      },
      "source": [
        "# loading the features\n",
        "features_label = np.load('features_label.npy', allow_pickle=True)\n",
        "features_label.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(242,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Moh4UluKtyth",
        "outputId": "c55a12d6-bbf4-4d1f-c6cd-eee6c42f13cf"
      },
      "source": [
        "trial_features=[]\n",
        "for i in range(0,len(features_label)):\n",
        "  a=[]\n",
        "  a.append(features_label[i])\n",
        "  #a.append(features_label[i][1])\n",
        "  trial_features.append(a)\n",
        "xxx = np.array(trial_features)\n",
        "xxx.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(242, 1, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Zzm3hHktyvj",
        "outputId": "91aeedad-a1fb-4e00-d646-4f69defc8b3b"
      },
      "source": [
        "X = xxx\n",
        "y = np.array(labels)\n",
        "lb = LabelEncoder()\n",
        "y = to_categorical(lb.fit_transform(y))\n",
        "X.shape\n",
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(242, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upbVoetAzjd5"
      },
      "source": [
        "limit_1 = int(X.shape[0]*0.5)\n",
        "limit_2 = int(X.shape[0]*0.85)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5edl7tbzmIu"
      },
      "source": [
        "X_train = X[:limit_1]\n",
        "Y_train = y[:limit_1]\n",
        "\n",
        "X_val = X[limit_1:limit_2]\n",
        "Y_val = y[limit_1:limit_2]\n",
        "\n",
        "X_test = X[limit_2:]\n",
        "Y_test = y[limit_2:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuaiS22vtyyt"
      },
      "source": [
        "# #We get our train and test set\n",
        "# X_train,X_test, Y_train, Y_test =train_test_split(X,y, test_size=0.2, random_state=27)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNv05hSI1_mP"
      },
      "source": [
        "projection=['linear','none']\n",
        "accuracy=[]\n",
        "proj_implemented=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djj5V3UBuMQs",
        "outputId": "c961922e-5f29-4cf6-df5d-82ce67f14079"
      },
      "source": [
        "for i in projection:\n",
        "  NUM_LAYERS = 2\n",
        "  D_MODEL = X.shape[2]\n",
        "  NUM_HEADS = 4\n",
        "  UNITS = 1024\n",
        "  DROPOUT = 0.1\n",
        "  TIME_STEPS= X.shape[1]\n",
        "  OUTPUT_SIZE=4\n",
        "  EPOCHS = 100\n",
        "  EXPERIMENTS=1\n",
        "\n",
        "  \n",
        "  for j in range(EXPERIMENTS):\n",
        "    \n",
        "    \n",
        "    model = transformer(time_steps=TIME_STEPS,\n",
        "      num_layers=NUM_LAYERS,\n",
        "      units=UNITS,\n",
        "      d_model=D_MODEL,\n",
        "      num_heads=NUM_HEADS,\n",
        "      dropout=DROPOUT,\n",
        "      output_size=OUTPUT_SIZE,  \n",
        "      projection=i)\n",
        "    \n",
        "    #model.compile(optimizer=tf.keras.optimizers.Adam(0.000001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "    early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')\n",
        "    #history=model.fit(X_train,Y_train, epochs=EPOCHS, validation_data=(X_test, Y_test))\n",
        "    history = model.fit(X_train, Y_train, batch_size=64, epochs=100, validation_data=(X_val, Y_val),callbacks=[early_stop])\n",
        "    \n",
        "    \n",
        "    accuracy.append(sum(history.history['val_accuracy'])/len(history.history['val_accuracy']))\n",
        "      \n",
        "    proj_implemented.append(i)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "linear\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 2.1923 - accuracy: 0.2841 - val_loss: 1.0555 - val_accuracy: 0.7738\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.6337 - accuracy: 0.8322 - val_loss: 0.6274 - val_accuracy: 0.7857\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.3534 - accuracy: 0.8487 - val_loss: 0.4704 - val_accuracy: 0.8333\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.1736 - accuracy: 0.9568 - val_loss: 0.2133 - val_accuracy: 0.9643\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.1040 - accuracy: 0.9835 - val_loss: 0.2163 - val_accuracy: 0.9643\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1894 - accuracy: 0.9195 - val_loss: 0.1769 - val_accuracy: 0.9881\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0409 - accuracy: 0.9838 - val_loss: 0.2254 - val_accuracy: 0.9643\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0420 - accuracy: 0.9838 - val_loss: 0.2514 - val_accuracy: 0.9643\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0443 - accuracy: 0.9838 - val_loss: 0.2166 - val_accuracy: 0.9643\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0248 - accuracy: 0.9893 - val_loss: 0.1747 - val_accuracy: 0.9881\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1636 - val_accuracy: 0.9881\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1662 - val_accuracy: 0.9881\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 0.9762\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0176 - accuracy: 0.9893 - val_loss: 0.1671 - val_accuracy: 0.9881\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9881\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1638 - val_accuracy: 0.9881\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1631 - val_accuracy: 0.9881\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 5.5638e-04 - accuracy: 1.0000 - val_loss: 0.1629 - val_accuracy: 0.9881\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 5.3083e-04 - accuracy: 1.0000 - val_loss: 0.1630 - val_accuracy: 0.9881\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 6.6652e-04 - accuracy: 1.0000 - val_loss: 0.1632 - val_accuracy: 0.9881\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 3.5467e-04 - accuracy: 1.0000 - val_loss: 0.1634 - val_accuracy: 0.9881\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 8.5582e-04 - accuracy: 1.0000 - val_loss: 0.1636 - val_accuracy: 0.9881\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 7.8991e-04 - accuracy: 1.0000 - val_loss: 0.1639 - val_accuracy: 0.9881\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 4.2367e-04 - accuracy: 1.0000 - val_loss: 0.1641 - val_accuracy: 0.9881\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 4.9438e-04 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 0.9881\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 3.3773e-04 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 0.9881\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 4.3788e-04 - accuracy: 1.0000 - val_loss: 0.1644 - val_accuracy: 0.9881\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1648 - val_accuracy: 0.9881\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 5.8774e-04 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9881\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 1.9939e-04 - accuracy: 1.0000 - val_loss: 0.1654 - val_accuracy: 0.9881\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 2.8480e-04 - accuracy: 1.0000 - val_loss: 0.1656 - val_accuracy: 0.9881\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 1.3475e-04 - accuracy: 1.0000 - val_loss: 0.1658 - val_accuracy: 0.9881\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 2.0615e-04 - accuracy: 1.0000 - val_loss: 0.1660 - val_accuracy: 0.9881\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 3.3080e-04 - accuracy: 1.0000 - val_loss: 0.1662 - val_accuracy: 0.9881\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 1.6898e-04 - accuracy: 1.0000 - val_loss: 0.1664 - val_accuracy: 0.9881\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 1.3077e-04 - accuracy: 1.0000 - val_loss: 0.1665 - val_accuracy: 0.9881\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 2.2950e-04 - accuracy: 1.0000 - val_loss: 0.1667 - val_accuracy: 0.9881\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1.2884e-04 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9881\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 1.4956e-04 - accuracy: 1.0000 - val_loss: 0.1669 - val_accuracy: 0.9881\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 2.8423e-04 - accuracy: 1.0000 - val_loss: 0.1672 - val_accuracy: 0.9881\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 9.9079e-05 - accuracy: 1.0000 - val_loss: 0.1675 - val_accuracy: 0.9881\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 1.1504e-04 - accuracy: 1.0000 - val_loss: 0.1677 - val_accuracy: 0.9881\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 1.6304e-04 - accuracy: 1.0000 - val_loss: 0.1679 - val_accuracy: 0.9881\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 1.2856e-04 - accuracy: 1.0000 - val_loss: 0.1681 - val_accuracy: 0.9881\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 9.3079e-05 - accuracy: 1.0000 - val_loss: 0.1683 - val_accuracy: 0.9881\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 1.0495e-04 - accuracy: 1.0000 - val_loss: 0.1684 - val_accuracy: 0.9881\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 6.9199e-04 - accuracy: 1.0000 - val_loss: 0.1685 - val_accuracy: 0.9881\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 8.4210e-05 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9881\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 1.2471e-04 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9881\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1.3804e-04 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9881\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 1.1711e-04 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9881\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 1.2996e-04 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9881\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 1.5499e-04 - accuracy: 1.0000 - val_loss: 0.1687 - val_accuracy: 0.9881\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 8.7454e-05 - accuracy: 1.0000 - val_loss: 0.1687 - val_accuracy: 0.9881\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 2.2890e-04 - accuracy: 1.0000 - val_loss: 0.1687 - val_accuracy: 0.9881\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 9.7733e-05 - accuracy: 1.0000 - val_loss: 0.1688 - val_accuracy: 0.9881\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 1.0131e-04 - accuracy: 1.0000 - val_loss: 0.1688 - val_accuracy: 0.9881\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 7.4095e-05 - accuracy: 1.0000 - val_loss: 0.1688 - val_accuracy: 0.9881\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 9.5059e-05 - accuracy: 1.0000 - val_loss: 0.1689 - val_accuracy: 0.9881\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 1.0378e-04 - accuracy: 1.0000 - val_loss: 0.1690 - val_accuracy: 0.9881\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 6.3967e-05 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9881\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 7.4728e-05 - accuracy: 1.0000 - val_loss: 0.1692 - val_accuracy: 0.9881\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 7.5582e-05 - accuracy: 1.0000 - val_loss: 0.1692 - val_accuracy: 0.9881\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 9.3955e-05 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 0.9881\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 6.2686e-05 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 0.9881\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 9.6537e-05 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 0.9881\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 9.9772e-05 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 0.9881\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 1.1332e-04 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 0.9881\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 1.1758e-04 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 0.9881\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 7.1135e-05 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.9881\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 7.3985e-05 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.9881\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 9.0956e-05 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 0.9881\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 7.4630e-05 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 0.9881\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 1.1142e-04 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 0.9881\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 5.4954e-05 - accuracy: 1.0000 - val_loss: 0.1700 - val_accuracy: 0.9881\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 1.1617e-04 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 0.9881\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 5.5808e-05 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 0.9881\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 8.7054e-05 - accuracy: 1.0000 - val_loss: 0.1703 - val_accuracy: 0.9881\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 7.4905e-05 - accuracy: 1.0000 - val_loss: 0.1704 - val_accuracy: 0.9881\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 1.2018e-04 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 0.9881\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1.1561e-04 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 0.9881\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 6.0927e-05 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 0.9881\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 6.2218e-05 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 0.9881\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 1.9014e-04 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9881\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 5.3242e-05 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9881\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 7.8428e-05 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 0.9881\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 7.3268e-05 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 0.9881\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 5.7988e-05 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 0.9881\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 0.9881\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 6.6564e-05 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 0.9881\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 8.0242e-05 - accuracy: 1.0000 - val_loss: 0.1715 - val_accuracy: 0.9881\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 5.9355e-05 - accuracy: 1.0000 - val_loss: 0.1716 - val_accuracy: 0.9881\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 3.8197e-04 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 0.9881\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 2.0882e-04 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 0.9881\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 1.5395e-04 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 0.9881\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1714 - val_accuracy: 0.9881\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 2.7218e-04 - accuracy: 1.0000 - val_loss: 0.1712 - val_accuracy: 0.9881\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 3.4604e-04 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 0.9881\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 9.0929e-05 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9881\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 5.7667e-05 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 0.9881\n",
            "none\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 3s 690ms/step - loss: 1.7466 - accuracy: 0.3258 - val_loss: 0.5198 - val_accuracy: 0.8452\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.4540 - accuracy: 0.8598 - val_loss: 0.7432 - val_accuracy: 0.7738\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.4200 - accuracy: 0.8598 - val_loss: 0.3602 - val_accuracy: 0.9167\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.1503 - accuracy: 0.9244 - val_loss: 0.2742 - val_accuracy: 0.9643\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.1551 - accuracy: 0.9403 - val_loss: 0.3106 - val_accuracy: 0.9405\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0700 - accuracy: 0.9893 - val_loss: 0.2897 - val_accuracy: 0.9286\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0812 - accuracy: 0.9783 - val_loss: 0.2452 - val_accuracy: 0.9762\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0730 - accuracy: 0.9783 - val_loss: 0.2225 - val_accuracy: 0.9881\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0516 - accuracy: 0.9786 - val_loss: 0.2194 - val_accuracy: 0.9881\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0652 - accuracy: 0.9728 - val_loss: 0.2262 - val_accuracy: 0.9762\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0531 - accuracy: 0.9838 - val_loss: 0.2258 - val_accuracy: 0.9881\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2276 - val_accuracy: 0.9881\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.9881\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0235 - accuracy: 0.9893 - val_loss: 0.2307 - val_accuracy: 0.9881\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9881\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.2345 - val_accuracy: 0.9881\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9762\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0580 - accuracy: 0.9890 - val_loss: 0.2320 - val_accuracy: 0.9881\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.2258 - val_accuracy: 0.9881\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2237 - val_accuracy: 0.9881\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.9881\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0585 - accuracy: 0.9731 - val_loss: 0.2216 - val_accuracy: 0.9881\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2205 - val_accuracy: 0.9881\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9881\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0933 - accuracy: 0.9786 - val_loss: 0.2194 - val_accuracy: 0.9881\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9881\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.2192 - val_accuracy: 0.9881\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 3.3970e-04 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 0.9881\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9881\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.0237 - accuracy: 0.9945 - val_loss: 0.2221 - val_accuracy: 0.9881\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2216 - val_accuracy: 0.9881\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2209 - val_accuracy: 0.9881\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9881\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9881\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 6.5669e-04 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9881\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 3.0827e-04 - accuracy: 1.0000 - val_loss: 0.2173 - val_accuracy: 0.9881\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.2177 - val_accuracy: 0.9881\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0153 - accuracy: 0.9838 - val_loss: 0.2187 - val_accuracy: 0.9881\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 8.1876e-04 - accuracy: 1.0000 - val_loss: 0.2194 - val_accuracy: 0.9881\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2191 - val_accuracy: 0.9881\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0257 - accuracy: 0.9893 - val_loss: 0.2179 - val_accuracy: 0.9881\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.0083 - accuracy: 0.9945 - val_loss: 0.2158 - val_accuracy: 0.9881\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0044 - accuracy: 0.9945 - val_loss: 0.2142 - val_accuracy: 0.9881\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.9881\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9881\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 6.5676e-04 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9881\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0418 - accuracy: 0.9678 - val_loss: 0.2147 - val_accuracy: 0.9881\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 8.2031e-04 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9881\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0261 - accuracy: 0.9945 - val_loss: 0.2166 - val_accuracy: 0.9881\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2148 - val_accuracy: 0.9881\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9881\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9881\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9881\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 8.3672e-04 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.9881\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 9.4998e-04 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 0.9881\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0178 - accuracy: 0.9893 - val_loss: 0.1948 - val_accuracy: 0.9881\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0131 - accuracy: 0.9893 - val_loss: 0.1923 - val_accuracy: 0.9881\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9881\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0277 - accuracy: 0.9945 - val_loss: 0.1937 - val_accuracy: 0.9881\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0072 - accuracy: 0.9945 - val_loss: 0.1955 - val_accuracy: 0.9881\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9881\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 7.3231e-04 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.9881\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0445 - accuracy: 0.9893 - val_loss: 0.1937 - val_accuracy: 0.9881\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 6.5914e-04 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9881\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9881\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.0154 - accuracy: 0.9945 - val_loss: 0.1884 - val_accuracy: 0.9881\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.1876 - val_accuracy: 0.9881\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 8.0718e-04 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.9881\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0207 - accuracy: 0.9893 - val_loss: 0.1912 - val_accuracy: 0.9881\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.9881\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.9881\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 0.9881\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2064 - val_accuracy: 0.9881\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9881\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 4.5717e-04 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9881\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9881\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 3.3987e-04 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9881\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 3.1635e-04 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9881\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 2.6583e-04 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9881\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9881\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 9.1166e-04 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.9881\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 7.3525e-04 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 0.9881\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.9881\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 5.6109e-04 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9881\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 5.6318e-04 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9881\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9881\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 1.2223e-04 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 0.9881\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 2.2827e-04 - accuracy: 1.0000 - val_loss: 0.2062 - val_accuracy: 0.9881\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 5.9235e-04 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9881\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 1.1757e-04 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9881\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 1.7024e-04 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9881\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 5.6137e-04 - accuracy: 1.0000 - val_loss: 0.2078 - val_accuracy: 0.9881\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 3.7247e-04 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9881\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 1.3823e-04 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.9881\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0400 - accuracy: 0.9945 - val_loss: 0.2047 - val_accuracy: 0.9881\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 4.3960e-04 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.9881\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0078 - accuracy: 0.9893 - val_loss: 0.1923 - val_accuracy: 0.9881\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1874 - val_accuracy: 0.9881\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 1.9361e-04 - accuracy: 1.0000 - val_loss: 0.1830 - val_accuracy: 0.9881\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 2.4182e-04 - accuracy: 1.0000 - val_loss: 0.1794 - val_accuracy: 0.9881\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "4A1ouHsfzFZz",
        "outputId": "a5aa6f9f-fcbe-4ad4-eda3-65a598e266d7"
      },
      "source": [
        "# Check out our train accuracy and validation accuracy over epochs.\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "import matplotlib.pyplot as plt\n",
        "# Set figure size.\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Generate line plot of training, testing loss over epochs.\n",
        "plt.plot(train_accuracy, label='Training Accuracy', color='#185fad')\n",
        "plt.plot(val_accuracy, label='Validation Accuracy', color='orange')\n",
        "\n",
        "# Set title\n",
        "plt.title('Training and Validation Accuracy by Epoch', fontsize = 25)\n",
        "plt.xlabel('Epoch', fontsize = 18)\n",
        "plt.ylabel('Categorical Crossentropy', fontsize = 18)\n",
        "plt.xticks(range(0,100,5), range(0,100,5))\n",
        "\n",
        "plt.legend(fontsize = 18);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uy15XOm2TnA"
      },
      "source": [
        "accuracy=pd.DataFrame(accuracy, columns=['accuracy'])\n",
        "proj_implemented=pd.DataFrame(proj_implemented, columns=['projection'])\n",
        "results=pd.concat([accuracy,proj_implemented],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "kGgwlc6o2T8b",
        "outputId": "3c34ca1a-6699-4a54-f88b-9b61a52c0aaf"
      },
      "source": [
        "results.groupby('projection').mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>projection</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>linear</th>\n",
              "      <td>0.981071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>none</th>\n",
              "      <td>0.982143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            accuracy\n",
              "projection          \n",
              "linear      0.981071\n",
              "none        0.982143"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnQkWOYxFIc8",
        "outputId": "27573c4b-f99c-4a59-b5d3-9be348a7924a"
      },
      "source": [
        "import keras\n",
        "\n",
        "y_prob = model.predict(X_test)\n",
        "y_classes = y_prob.argmax(axis=-1)\n",
        "\n",
        "res_list = y_classes.tolist()\n",
        "label_mapping = {0:'Aayush',1:'Kanishk',2:'Kayan',3:'Rohit'}#clarify\n",
        "\n",
        "\n",
        "for i in range(len(res_list)):\n",
        "  print(\"prediction \",i,\" \",label_mapping[res_list[i]])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prediction  0   Kanishk\n",
            "prediction  1   Kanishk\n",
            "prediction  2   Aayush\n",
            "prediction  3   Kanishk\n",
            "prediction  4   Kanishk\n",
            "prediction  5   Rohit\n",
            "prediction  6   Kayan\n",
            "prediction  7   Rohit\n",
            "prediction  8   Kayan\n",
            "prediction  9   Kayan\n",
            "prediction  10   Aayush\n",
            "prediction  11   Kanishk\n",
            "prediction  12   Kayan\n",
            "prediction  13   Rohit\n",
            "prediction  14   Kanishk\n",
            "prediction  15   Kanishk\n",
            "prediction  16   Kayan\n",
            "prediction  17   Aayush\n",
            "prediction  18   Kayan\n",
            "prediction  19   Aayush\n",
            "prediction  20   Aayush\n",
            "prediction  21   Aayush\n",
            "prediction  22   Kayan\n",
            "prediction  23   Rohit\n",
            "prediction  24   Kanishk\n",
            "prediction  25   Rohit\n",
            "prediction  26   Rohit\n",
            "prediction  27   Aayush\n",
            "prediction  28   Rohit\n",
            "prediction  29   Kanishk\n",
            "prediction  30   Kayan\n",
            "prediction  31   Kanishk\n",
            "prediction  32   Aayush\n",
            "prediction  33   Kanishk\n",
            "prediction  34   Kanishk\n",
            "prediction  35   Kayan\n",
            "prediction  36   Aayush\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ep-JoBYAXfI0",
        "outputId": "fa0e9317-f6e7-4a33-b4f2-05e65bfe533a"
      },
      "source": [
        "model.evaluate(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3979 - accuracy: 0.9459\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3979407548904419, 0.9459459185600281]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}